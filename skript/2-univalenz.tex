\subsection{Äquivalenzen}
\label{sub:aequivalenzen}

In diesem Abschnitt werden wir drei verschiedene Definitionen von Äquivalenzen einführen und zeigen,
dass es sich um den selben Begriff handelt. Einen haben wir bereits eingeführt - Funktionen mit kontrahierbaren Fasern heißen Äquivalenz.
Von einem Äquivalenzbegriff erwarten wir, dass es sich beim entsprechenden Typ $\isEquiv(f)$ um eine Aussage handelt.
Das hat zur Folge, dass wir es als eine Eigenschaft von Funktionen anssehen können eine Äquivalenz zu sein.
Damit ist dann auch der Typ der Äquivalenzen zwischen $A$ und $B$ eine Untertyp von $A\to B$, d.h. die Vergiß-Abbildung
\begin{mathpar}
  \pi_1:\left(\sum_{f:A\to B}\isEquiv(f)\right)\to (A\to B)
\end{mathpar}
ist injektiv.

Zur Vorbereitung beschäftigen wir uns noch etwas mit Homotopien.
\begin{bemerkung}
  Seien $A,B:\mU$ und $f,g:A\to B$.
  \begin{enumerate}
  \item Sei $H:f\sim g$. Für $\varphi:A'\to A$ gibt es eine Homotopie $H_{\varphi(\_)}:f\circ \varphi\sim g\circ \varphi$ und für $\psi:B\to B'$ gibt es eine Homotopie $\psi(H):\psi\circ f\sim \psi\circ g$. Diese Operationen nennt man \begriff{whiskering}.
  \item Sei $H:f\sim g$. Homotopien sind natürlich in folgendem Sinn: Für $p:x=_A y$ gilt:
    \begin{mathpar}
      H_x\kon g(p) = f(p)\kon H_{y}
    \end{mathpar}
  \item Für eine Homotopie $H:f\sim\id$ gilt $f(H_x)=H_{f(x)}$.
  \end{enumerate}
\end{bemerkung}


Wir beginnen mit einer scheinbar unbedeutenden Variation des Begriffs Quasi-Inverse und legen dabei mehr Notation für Äquivalenzen fest:

\begin{definition}
  Seien $A,B:\mU$ und $f:A\to B$.
  \begin{enumerate}
  \item $f$ hat eine \begriff{Linksinverse}, wenn es ein $g:B\to A$ gibt und $g\circ f\sim\id_A$.
  \item $f$ hat eine \begriff{Rechtsinverse} oder einen \begriff{Schnitt}, wenn es ein $h:B\to A$ gibt und $f\circ h\sim \id_B$.
  \item $f$ ist eine \begriff{Äquivalenz} oder eine Funktion mit \begriff{Links- und Rechtsinversen}, wenn
    \begin{mathpar}
      \isEquiv(f)\colonequiv\mathrm{LRInv}(f)\colonequiv  \left(\sum_{g:B\to A}g\circ f\sim\id_A\right)\times\left(\sum_{h:B\to A}f\circ h\sim\id_B\right)
    \end{mathpar}
  \item Wenn es eine Äquivanz zwischen $A$ und $B$ gibt, dann sagen wir $A$ ist \begriff{äquivalent} zu $B$.
  \item Für den Typ der Äquivalenzen zwischen $A$ und $B$ schreiben wir:
    \begin{mathpar}
      A\simeq B\colonequiv\sum_{f:A\to B}\isEquiv(f)
    \end{mathpar}
  \end{enumerate}
\end{definition}

Es wird sich herausstellen, dass $\mathrm{LRInv}(f)$ und $\mathrm{qinv}(f)$ für manche Funktionen keine äquivalenten Typen sind.
Insbesondere werden wir noch sehen, dass immer $\mathrm{LRInv}(f)$ eine Aussage ist, $\qinv(f)$ aber keine Aussage mehr sein muss, wenn $A$ und $B$ komplizierte Gleichheitstypen haben.
Die beiden Begriffe sind aber logisch äquivalent, d.h. es gibt für jedes $f:A\to B$ Abbildungen $\mathrm{LRInv}(f)\to \qinv(f)$ und $\qinv(f)\to\mathrm{LRInv}(f)$.
Zunächst halten wir die Vokabel ``logisch äquivalent'' fest:

\begin{definition}
  Zwei Typen $A$ und $B$ heißen \begriff{logisch äquivalent}, wenn es Funktionen $f:A\to B$ und $g:B\to A$ gibt.
\end{definition}

Bei Aussagen reicht die logische Äquivalenz bereits, damit die Typen äquivalent sind.
Damit werden die verschiedenen Varianten des Typs ``$\isEquiv(f)$'', die wir in diesem Abschnitt kennenlernen, äquivalente Typen sein,
wenn wir logische Äquivalenz gezeigt haben und dass es sich jeweils um Aussagen handelt. Letzteres werden wir allerdings noch aufschieben.

\begin{bemerkung}
  \label{bem:lrinv-qinv}
  Seien $A,B:\mU$ und $f:A\to B$. Die Typen $\mathrm{LRInv}(f)$ und $\qinv(f)$ sind logisch äquivalent.
\end{bemerkung}
\begin{beweis}
  Nehmen wir zünachst an, es gibt eine Quasi-Inverse $g:B\to A$ mit $H:g\circ f\sim\id_A$ und $K:f\circ g\sim\id_B$. Dann ist
  \begin{mathpar}
    ((g,H),(g,K)):\mathrm{LRInv}(f)
  \end{mathpar}
  Seien nun andererseits $g,h:B\to A$ links- und rechtsinvers zu $f$. Wir zeigen, dass $g$ und $h$ homotop sind. Damit können wir dann zeigen, dass $g$ auch rechtsinvers ist.
  Durch Whiskering erhalten wir:
  \begin{mathpar}
    g\sim g\circ (f\circ h) \sim (g\circ f)\circ h  \sim h
  \end{mathpar}
  Also ist $g$ rechtsinvers:
  \begin{mathpar}
    f\circ g\sim f\circ h\sim \id_B
  \end{mathpar}
\end{beweis}

Wenn wir also zu einer Funktion $f:A\to B$ eine beidseitige Inverse konstruieren, dann ist $f$ eine Äquivalenz (im Sinn einer Funktion mit Links- und Rechtsinversen).
Äquivalenzen haben die Operationen, die wir bereits von Gleichheiten kennen:

\begin{bemerkung}
  \begin{enumerate}
  \item Die Identität ist eine Äquivalenz.
  \item Eine Inverse einer Äquivalenz ist eine Äquivalenz.
  \item Seien $A,B,C:\mU$. Wenn $f:A\to B$ und $g:B\to C$ Äquivalenzen sind, dann ist $g\circ f:A\to C$ eine Äquivalenz.
  \end{enumerate}
\end{bemerkung}
\begin{beweis}
  Wir zeigen die Aussagen für den Äquivalenzbegriff der Funktion mit Links- und Rechtsinversen.
  Mit \cref{thm:aequivalenzen} gilt damit das gleiche für die anderen Äquivalenzbegriffe.
  \begin{enumerate}
  \item Die Identität ist ihre eigene Links- und Rechtsinverse. Die nötigen Homotopien gelten schon als urteilsmäßige von Funktionen.
  \item Wenn $f:A\to B$ eine Linksinverse $g:B\to A$ und eine Rechtsinverse $h:B\to A$ hat, dann ist bekommen wir mit Bemerkung \labelcref{bem:lrinv-qinv} eine Quasi-Inverse $f^{-1}:B\to A$.
    Und $f^{-1}$ ist eine Äquivalenz mit Linksinverser $f$ und Rechtsinverser $f$.
  \item Auf Übungsblatt 4 wird das für Quasi-Inversen gezeigt. Zusammen mit Bemerkung \labelcref{bem:lrinv-qinv} gilt das also auch für Äquivalenzen.
  \end{enumerate}
\end{beweis}

\begin{beispiel}[Transport ist Äquivalenz]
  \label{bsp:transp-aequiv}
  Für $A:\mU$, $B:A\to\mU$, $x,y:A$ und jedes $p:x=y$ ist $\transp_B(p):B(x)\to B(y)$ eine Äquivalenz mit Inverser $\transp_B(p^{-1}):B(y)\to B(x)$.
\end{beispiel}

Wir wollen nun den Äquivalenzbegriff der Links- und Rechtsinvertierbarkeit mit dem der kontrahierbaren Fasern in Zusammenhang bringen.
Wir werden allerdings erstmal eine Implikation klären und für die zweite einen dritten Äquivalenzbegriff einführen.

\begin{bemerkung}
  \label{bem:isContr-lrinv}
  Seien $A,B:\mU$ und $f:A\to B$. Wenn alle Fasern von $f$ kontrahierbar sind, dann hat $f$ Links- und Rechtsinverse, es gibt also eine Funktion:
  \begin{mathpar}
    \left(\prod_{y:B}\isContr(f^{-1}(y))\right) \to \mathrm{LRInv}(f)
  \end{mathpar}
\end{bemerkung}

\begin{beweis}
  Sei $k:\prod_{y:B}\isContr(f^{-1}(y))$.
  Wir konstruieren eine beidseitige Inverse $g:B\to A$ indem wir $y:B$ auf das Kontraktionszentrum der Faser $f^{-1}(y)$ abbilden:
  Für $\pi_1(k_y)$ ist ein Element von $f^{-1}(y)$, besteht also aus $x:A$ und $p:f(x)=y$, also können wir festlegen
  \begin{mathpar}
    g(y)\colonequiv x
  \end{mathpar}
  Dann ist $f(g(y))=f(x)=y$, also $g$ Rechtsinverse von $f$. Für $x:A$ sei $x'\colonequiv g(f(x))$.
  Es müssen $x:A$ und $x':A$ beide in $f^{-1}(f(x))$ liegen und da diese Faser kontrahierbar ist, gibt es eine Gleichheit $q:x=x'=g(f(x))$.
  Genauer haben wir durch die Kontrahierbarkeit eine Gleichheit $q':(x,\refl_{f(x)})=(x',p')$ in der Faser $f^{-1}(f(x))$.
  Diese Gleichheit können wir mit $\pi_1:f^{-1}(f(x))\to A$ abbilden, also $q\colonequiv \pi_1(q')$ setzen.
\end{beweis}

Die Umkehrung dieser Aussage ist komplizierter zu zeigen und wir werden zunächst zeigen, dass sich Links- Rechtsinverse in eine sogenannte kohärente Inverse überstzen lassen.
Kohärente Inverse $g:B\to A$ einer Funktion $f:A\to B$ haben eine Kompatiblität zwischen den beiden Homotopien $f\circ g\sim \id$ und $g\circ f\sim \id$.
Für eine Funktion $f:A\to B$ mit Inverser $g:B\to A$ besagt diese Kohärenz, dass die beiden Möglichkeiten eine Homotopie $f\circ g\circ f\sim f$ zu konstruieren punktweise gleich sind.

\begin{definition}
  Seien $A,B:\mU$ und $f:A\to B$.
  Eine Funktion $g:B\to A$ heißt \begriff{kohärente Inverse} von $f$, wenn es Homotopien $H:g\circ f\sim \id$ und $K:f\circ g \sim \id$ gibt und
  \begin{mathpar}
    \mathrm{koh} : \prod_{x:A}f(H_x)=K_{f(x)}
  \end{mathpar}
  Wir schreiben $\mathrm{CohInv}(f)$ für den Typ der \begriff{kohärenten Inversen} von $f$.
\end{definition}

Wir wollen direkt einsehen, dass wir von dieser Sorte Äquivalenz die Kontrahierbarkeit der Fasern beweisen können:

\begin{bemerkung}
  \label{bem:qinv-equiv}
  Seien $A,B:\mU$ und $f:A\to B$. Wenn $f$ eine kohärente Inverse hat, dann sind die Fasern von $f$ kontrahierbar.
\end{bemerkung}
Vor dem Beweis noch ein Hilfslemma, das wir auch sonst noch wiederverwenden können:
\begin{lemma}
  \label{lem:gleichheit-in-faser}
  Seien $A,B$ Typen, $f:A\to B$ und $y:B$. Für $(x,q),(x',q'):f^{-1}(y)$ gibt es eine Funktion:
  \begin{mathpar}
    \prod_{p:x=_A x'}f(p)^{-1}\kon q=q'\to (x,q)=(x',q')
  \end{mathpar}
\end{lemma}
\begin{beweis}[von \cref{lem:gleichheit-in-faser}]
  Induktion über $p$ und $\sum_=$.
\end{beweis}

\begin{beweis}[von \labelcref{bem:qinv-equiv}]
  Habe also $f:A\to B$ eine kohärente Inverse, gebe es also $g:B\to A$, $H:g\circ f\sim \id$, $K:f\circ g \sim \id$ und $\mathrm{koh} : \prod_{x:A}f(H_x)=K_{f(x)}$.
  Wir müssen nun für jede Faser von $f$ eine Kontraktion angeben.
  Als Kontraktionszentrum für die Faser über $y:B$ wählen wir
  \begin{mathpar}
    k_y\colonequiv (g(y), K_y) : f^{-1}(y)
  \end{mathpar}
  Seien nun also $(x,q),(x',q'):f^{-1}(y)$. Damit haben wir auch $q\kon q'^{-1}:f(x)=f(x')$ und damit:
  \begin{mathpar}
    H_x^{-1}\kon g(q\kon q'^{-1}) \kon H_x':x=x'
  \end{mathpar}
  Darauf wenden wir jetzt $f$ an:
  \begin{mathpar}
    f(H_x^{-1}\kon g(q\kon q'^{-1}) \kon H_x'):f(x)=f(x')
  \end{mathpar}
  und berechnen mit Natürlichkeit von Homotopien, der Kohärenz und den Gruppoidgesetzen:
  \begin{align*}
    f(H_x^{-1}\kon g(q\kon q'^{-1}) \kon H_x')&=f(H_x^{-1})\kon f(g(q\kon q'^{-1})) \kon f(H_x') \\
                                              &=f(H_x^{-1})\kon K_{f(x)}\kon q\kon q'^{-1}\kon K_{f(x')}^{-1} \kon f(H_x') \\
                                              &=q\kon q'^{-1}
  \end{align*}
  Mit dem Lemma haben wir also die gewünschte Gleichheit.
\end{beweis}

\begin{bemerkung}
  Seien $A,B:\mU$ und $f:A\to B$ habe eine beidseitige Inverse $g:B\to A$.
  Dann ist $g$ auch eine kohärente Inverse von $f$.
\end{bemerkung}
\begin{beweis}
  Seien $g:B\to A$ und $H:g\circ f\sim\id$, $K:f\circ g\sim \id$. Setze für $y:B$:
  \begin{mathpar}
    K'(y) \colonequiv K_{f(g(y))}^{-1}\kon f(H_{g(y)})\kon K_{y}
  \end{mathpar}
  und rechne nach dass für $x:A$ gilt: $f(H_x)=K'_{f(x)}$.
\end{beweis}

\begin{theorem}
  \label{thm:aequivalenzen}
  Seien $A,B:\mU$ und $f:A\to B$, dann sind die folgenden Äquivalenzbegriffe logisch äquivalent:
  \begin{enumerate}
  \item Alle Fasern von $f$ sind kontrahierbar:
    \begin{mathpar}
      \isEquiv(f)\colonequiv\prod_{y:B}\isContr(f^{-1}(y))
    \end{mathpar}
  \item $f$ hat eine Linksinverse und eine Rechtsinverse:
    \begin{mathpar}
      \isEquiv(f)\colonequiv\mathrm{LRInv}\equiv  \left(\sum_{g:B\to A}g\circ f\sim\id_A\right)\times\left(\sum_{h:B\to A}f\circ h\sim\id_B\right)
    \end{mathpar}
  \item $f$ hat eine kohärente Inverse:
    \begin{mathpar}
      \isEquiv(f)\colonequiv\mathrm{CohInv}(f)\colonequiv \sum_{g:B\to A} \sum_{H:g\circ f\sim\id}\sum_{K:f\circ g\sim\id} \prod_{x:A}f(H_x)=K_{f(x)}
    \end{mathpar}
  \end{enumerate}
  Wir schreiben für alle drei Begriffe $\isEquiv(f)$, weil sich noch rausstellen wird, dass alle diese Typen Aussagen sind und damit alle drei Typen äquivalent sind.
\end{theorem}
\begin{beweis}
  Die Bemerkungen dieses Abschnitts beweisen per Ringschluss die logische Äquivalenz.
\end{beweis}

\subsection{Univalenz}
In diesem Abschnitt werden wir uns mit den Universen und ihren Gleichheitstypen beschäftigen.
Eine historisch wichtige Idee von Vladimir Voevodsky ist das \begriff{Univalenzaxiom},
das die Gleichheitstypen im Universum mit den Äquivalenzen von Typen identifiziert.
Dieses Axiom werden wir kennenlernen und Konsequenzen daraus ziehen.
Davor wollen wir aber noch allgemeine Konsequenzen aus der Existenz von Universen ziehen.

Mit Universen sind wir in der Lage Ungleichheit von Elementen eines Typs zu beweisen.
Diese definieren wir zunächst als Negation der Gleichheit:
\begin{definition}
  Seien $A:\mU$ und $x,y:A$. Dann ist $x$ \begriff{ungleich} $y$, wenn
  \begin{mathpar}
    x\not= y\colonequiv (x=y\to \leer).
  \end{mathpar}
\end{definition}
Man beachte, dass es sich bei diesem Typ stets um eine Aussage handelt.
Es sind also in $x\not= y$ keine so interessanten Dinge zu finden, wie im Gleichheitstyp und wir werden uns auch wenig mit Ungleichheiten beschäftigen.
\begin{bemerkung}
  Es gilt $1_\zwei \not= 0_\zwei$.
\end{bemerkung}
\begin{beweis}
  Per Rekursion können wir uns den folgenden abhängigen Typen definieren:
  \begin{align*}
    B&:\zwei\to\mU \\
    B(0_\zwei)&\colonequiv \leer \\
    B(1_\zwei)&\colonequiv \eins
  \end{align*}
  Um die Ungleichheit zu zeigen, dürfen wir $p:1_\zwei = 0_\zwei$ annehmen und müssen ein Element in $\leer$ konstruieren.
  Sei also $p:1_\zwei = 0_\zwei$. Damit haben wir auch eine Abbildung:
  \begin{mathpar}
    \transp_B(p):B(1_\zwei)\to B(0_\zwei)
  \end{mathpar}
  Und wegen $\ast:B(1_\zwei)\equiv \eins$ haben wir auch ein Element, das wir in diese Abbildung einsetzen können.
  Es ist also $\transp_B(p)(\ast):B(0_\zwei)\equiv \leer$.
\end{beweis}
Dieser Trick lässt sich auf alle Elemente induktiver Typen übertragen, für die wir ``verschiedene'' Werte vorgeben können.
Für einzelne natürliche Zahlen etwa:
\begin{bemerkung}
  Es gilt $0_{\N}\not= 1_{\N}\colonequiv \sucN(0_{\N})$.
\end{bemerkung}
\begin{beweis}
  Sei
  \begin{align*}
    B&:\N\to \mU \\
    B(0_{\N})&\colonequiv \leer \\
    B(1_{\N})&\colonequiv \eins
  \end{align*}
  womit für $p:0_{\N}=1_{\N}$ ein Element $\transp_B(p^{-1})(\ast):\leer$ gegeben ist.
\end{beweis}
Typischerweise interessiert man sich für eine vollständige Charakterisierung der Gleichheitstypen eines Typs.
Für die natürlichen Zahlen wäre das ein in $n,k:\N$ abhängiger Typ $B(n,k)$ sodass $B(n,k)\simeq (n=_\N k)$.
Das wird unser Ziel in \cref{sec:zahlen-gleichheit} sein.

Ohne Weiteres können wir bereits für $A,B:\mU_i$ den Typ $A=_{\mU_i}B$ der Gleichheiten zwischen $A$ und $B$ formen.
Dieser liegt allerdings im nächsthöheren Universum $\mU_{i+1}$, da wir in der Formierungsregel für Gleichheitstypen ``X ist ein Typ'' durch ``$X : \mU_i$'' ersetzen und dafür nur ``$\mU_i : \mU_{i+1}$'' in Frage kommt:
\begin{mathpar}
  \inferrule{\Gamma\yields \mU_i:\mU_{i+1}\and \Gamma\yields A,B:\mU_i}{\Gamma\yields A=_{\mU_i}B:\mU_{i+1}}{=\mathrm{F}}
\end{mathpar}

Damit lässt sich zeigen, dass gleiche Typen äquivalent sind.
\begin{bemerkung}
  Für $A,B:\mU$ gibt es eine Funktion
  \begin{mathpar}
    \transp_{\id_\mU}:A=_{\mU} B\to (A\simeq B)
  \end{mathpar}
  den \begriff{Universentransport}.
\end{bemerkung}
\begin{beweis}
  Seien $A,B:\mU_i$. Dann gibt es einen abhängigen Typ $X:\mU_i\to\mU_{i+1}$ und damit
  \begin{mathpar}
    \transp_{\id_\mU}\colonequiv\transp_{X}:A=_{\mU_i}B\to A\simeq B
  \end{mathpar}
  Nach Beispiel \labelcref{bsp:transp-aequiv} sind Transporte immer Äquivalenzen.
\end{beweis}

Es ist also möglich, aus einer Gleichheit von Typen eine Äquivalenz zu kontruieren.
Die Umkehrung, aus einer Äquivalenz auch eine Gleichheit konstruieren zu können, nennt man das Univalenzaxiom.
\begin{axiom}[Univalenzaxiom]
  Wir nehmen von nun an an, dass das \begriff{Univalenzaxiom} gilt: Für $A,B:\mU$ ist die Funktion
  \begin{mathpar}
    \transp_{\id_\mU}:A=_{\mU}B\to A\simeq B
  \end{mathpar}
  eine Äquivalenz ist. Die Inverse von $\transp_{\id_\mU}$ bezeichnen wir mit $\ua$\index{$\ua$}:
  \begin{mathpar}
    \ua:A\simeq B\to A=_{\mU}B
  \end{mathpar}
  Wir nehmen an, dass das Univalenzaxiom für jedes Universum gilt.
\end{axiom}

Mit Univalenz ergibt sich, dass es tatsächlich verschiedene Gleichheiten zwischen Elementen geben kann.
Um dafür ein Beispiel zu bekommen, wollen wir zunächst einen Typ von Äquivalenzen weit genug dafür verstehen:
\begin{bemerkung}
  Es gilt $\zwei\simeq (\zwei\simeq \zwei)$ (mit Funktionsextensionalität).
\end{bemerkung}
\begin{beweis}
  Zunächst geben wir der Äquivalenz, die die beiden Elemente von $\zwei$ vertauscht den Namen $s$:
  \begin{align*}
    s:&\zwei\simeq\zwei \\
    s(0_\zwei)&\colonequiv 1_\zwei \\
    s(1_\zwei)&\colonequiv 0_\zwei
  \end{align*}
  Damit können wir Elemente von $\zwei$ auf Äquivalenzen abbilden:
  \begin{align*}
    \varphi:&\zwei\to (\zwei\simeq\zwei) \\
    \varphi(0_\zwei)&\colonequiv \id_\zwei \\
    \varphi(1_\zwei)&\colonequiv s
  \end{align*}
  Für die Umkehrabbildung wählen wir:
  \begin{align*}
    \psi:&(\zwei\simeq\zwei)\to\zwei \\
    \psi&\colonequiv f\mapsto f(0_\zwei) \\
  \end{align*}
  Es gilt per $\ind{\zwei}$ durch die Urteilsgleichheiten $\psi\varphi(0_\zwei)\equiv 0_\zwei$ und $\psi\varphi(1_\zwei)\equiv 1_\zwei$ bereits $\psi\circ\varphi\sim \id$.
  Also ist noch zu zeigen:
  \begin{mathpar}
    \prod_{f:\zwei\simeq \zwei} \varphi(\psi(f))=f
  \end{mathpar}
  Oder nach auswerten von $\psi$ und mit Funktionsextensionalität:
  \begin{mathpar}
    \prod_{f:\zwei\simeq \zwei}\prod_{x:\zwei} \varphi(f(0_\zwei))(x)=f(x)
  \end{mathpar}
  Aus Beispiel \labelcref{bsp:einheit-kontrahierbar} wissen wir, dass:
  \begin{mathpar}
    t:\prod_{x:\zwei}(x=0_\zwei)\sqcup(x=1_\zwei)
  \end{mathpar}
  womit wir die Fallunterscheidung ``$f(0)$ ist $1_\zwei$ oder $0_\zwei$'' umsetzen können:
  \begin{mathpar}
    f\mapsto x\mapsto t_{f(0_\zwei)} : \prod_{f:\zwei\simeq\zwei}\prod_{x:\zwei}(f(0_\zwei)=0_\zwei)\sqcup(f(0_\zwei)=1_\zwei)
  \end{mathpar}
  Die beiden Fälle können wir abarbeiten, indem wir Funktionen auf den einzelnen Faktoren, in unseren Zieltyp angeben, wobei wir gleichzeitig mit $\ind{\zwei}$ eine Fallunterscheidung über $x$ machen.
  Insgesamt müssen wir also noch konstruieren:
  \begin{align*}
    F_{00}& : f(0_\zwei)=0_\zwei \to \varphi(f(0_\zwei))(0_\zwei)=f(0_\zwei) \\
    F_{01}& : f(0_\zwei)=0_\zwei \to \varphi(f(0_\zwei))(1_\zwei)=f(1_\zwei) \\
    F_{10}& : f(0_\zwei)=1_\zwei \to  \varphi(f(0_\zwei))(0_\zwei)=f(0_\zwei) \\
    F_{11}& : f(0_\zwei)=1_\zwei \to  \varphi(f(0_\zwei))(1_\zwei)=f(1_\zwei)
  \end{align*}
  Denn damit haben wir dann:
  \begin{mathpar}
    f\mapsto \ind{\zwei}(\dots,\ind{\sqcup}(\dots,F_{00},F_{10})(t_{f(0_\zwei)}),\ind{\sqcup}(\dots,F_{01},F_{11})(t_{f(0_\zwei)})): \prod_{f:\zwei\simeq \zwei}\prod_{x:\zwei} \varphi(f(0_\zwei))(x)=f(x)
  \end{mathpar}
  Die Funktionen $F_{00}$ und $F_{10}$ können mit Gruppoidgestzen konstruiert werden.
  Für die übrigen müssen wir verwenden, dass $0_\zwei\not=1_\zwei$.
  Etwa für $F_{01}$ nehmen wir also $p:f(0_\zwei)=0_\zwei$ an und verwenden wieder die Fallunterscheidung für die Gleichheit in $\zwei$:
  \begin{mathpar}
    (f(1_\zwei)=0_\zwei)\sqcup(f(1_\zwei)=1_\zwei)
  \end{mathpar}
  Es geht also wieder darum, zwei Funktionen zu konstruieren. Für $f(1_\zwei)=1_\zwei)$ geht das wieder mit den üblichen Methoden, für die andere Gleichheit, können wir zusammen mit $p$ zeigen:
  \begin{mathpar}
    f(1_\zwei)=f(0_\zwei)
  \end{mathpar}
  und darauf die Inverse von $f$ anwenden um $1_\zwei=0_\zwei$ zu erhalten. Nun ist $0_\zwei\not=1_\zwei$ eine Abbildung von $1_\zwei=0_\zwei$ nach $\emptyset$.
  Da es von $\emptyset$ eine Abbildung in jeden beliebigen Typ gibt, haben wir insgesamt auch eine Abbildung von $1_\zwei=0_\zwei$ in die zu zeigende Behauptung.
  Das beweist den Fall $F_{01}$ und $F_{11}$ lässt sich analog zeigen.
\end{beweis}

\begin{beispiel}
  Mit $\zwei\simeq(\zwei\simeq\zwei)$ und per Univalenz gilt:
  \begin{mathpar}
    f:\zwei\simeq (\zwei=_{\mU}\zwei)
  \end{mathpar}
  Also: $f(0_\zwei)\not=f(1_\zwei)$.
\end{beispiel}

\begin{bemerkung}
  Seien $A,B,C:\mU$, $f:A\simeq B$ und $g:B\simeq C$. Es gelten:
  \begin{enumerate}
  \item $\ua(\id_A)=\refl_A$
  \item $\ua(f\circ g)=\ua(f)\kon \ua(g)$
  \item $\ua(f^{-1})=\ua(f)^{-1}$
  \end{enumerate}
\end{bemerkung}
\begin{beweis}
  \begin{enumerate}
  \item Es gilt $\transp_{\id_\mU}(\refl_A)=\id_A$ und damit $\ua(\id_A)=\ua(\transp_{\id_\mU}(\refl_A))=\refl_A$.
  \item Seien $p\colonequiv\ua(f)$ und $q\colonequiv\ua(g)$. Dann gilt $\transp_{\id_\mU}(p)=f$ und $\transp_{\id_\mU}(q)=g$ und damit:
    \begin{mathpar}
      \ua(f\circ g)=\ua(\transp_{\id_\mU}(p)\circ \transp_{\id_\mU}(q))=\ua(\transp_{\id_\mU}(p\kon q))=p\kon q=\ua(f)\kon\ua(g)
    \end{mathpar}
  \item Sei $p\colonequiv\ua(f)$, dann gilt:
    \begin{mathpar}
      \ua(f^{-1})=\ua(\transp_{\id_\mU}(p)^{-1})=\ua(\transp_{\id_\mU}(p^{-1}))=p^{-1}=\ua(f)^{-1}
    \end{mathpar}
  \end{enumerate}
\end{beweis}

Da wir nun wissen, dass Gleichheiten und Äquivalenzen dasselbe sind, können wir auch die Gleichheitsinduktion auf Äquivalenzen übertragen:
\begin{lemma}[Äquivalenzinduktion]
  Für $C:\prod_{A,B:\mU}A\simeq B\to \mU$ gibt es:
  \begin{mathpar}
    \ind{\simeq}:\left(\prod_{A:\mU}C(A,A,\id_A)\right)\to \prod_{A,B:\mU}\prod_{f:A\simeq B}C(A,B,f)
  \end{mathpar}
\end{lemma}
\begin{beweis}
  Durch Gleichheitsinduktion ergibt sich:
  \begin{mathpar}
    \ind{=}:\left(\prod_{A:\mU}C(A,A,\transp_{\id_\mU}(\refl_A))\right)\to\prod_{A,B:\mU}\prod_{p:A=_{\mU}B}C(A,B,\transp_{\id_\mU}(p))
  \end{mathpar}
\end{beweis}

Wir importieren die folgende Aussage (findet man im HoTT-Book am Ende von Kapitel 4): 
\begin{fakt}
  Univalenz impliziert Funktionsextensionalität.
\end{fakt}
Im nächsten Kapitel ergibt sich ein einfacher Beweis einer stärkeren Version von Funktionsextensionalität.
Wir verzichten daher im folgenden darauf, auf Verwendung von Funktionsextensionalität hinzuweisen.

\subsection{Faserungen und Gleichheitssätze}
Zunächst halten wir fest, dass abhängige Summen und abhängige Produkte mit äquivalenten Eingangsdaten äquivalente Typen produzieren:
\begin{bemerkung}
  \label{bem:ap-univalenz-sigma-prod}
  Seien $A:\mU$ und $B,B':A\to\mU$. Wenn $B$ und $B'$ punktweise äquivalent sind, also gilt $\prod_{x:A}B(x)\simeq B'(x)$, dann gilt auch:
  \begin{mathpar}
    \left(\sum_{x:A}B(x)\right)\simeq \left(\sum_{x:A}B'(x)\right)\text{ und }\left(\prod_{x:A}B(x)\right)\simeq \left(\prod_{x:A}B'(x)\right)
  \end{mathpar}
\end{bemerkung}
\begin{beweis}
  Aus der punktweisen Äquivalenz $\prod_{x:A}B(x)\simeq B'(x)$ machen wir durch punktweises Anwenden von $\ua$ eine punktweise Gleichheit $\prod_{x:A}B(x)=B'(x)$ und daraus mit Funktionsextensionalität eine Gleichheit $p:B=B'$.
  Dann ist aber auch
  \begin{mathpar}
    \mathrm{ap}(\prod,p):\left(\prod_{x:A}B(x)\right)=\left(\prod_{x:A}B'(x)\right)
  \end{mathpar}
  und damit $\simeq_=(\mathrm{ap}(\prod,p)):\left(\prod_{x:A}B(x)\right)\simeq\left(\prod_{x:A}B'(x)\right)$.
  Mit dem gleichen Argument können wir die entsprechende Aussage für abhängige Summen zeigen.
\end{beweis}
Mit Univalenz lässt sich auch die Gleichheit von abhängigen Typen konkretisieren:
\begin{bemerkung}
  Für $A:\mU$ und $B,B':A\to \mU$ gibt es eine Äquivalenz:
  \begin{mathpar}
    (B=B') \simeq \left(\prod_{x:A}B(x)\simeq B'(x)\right)
  \end{mathpar}
\end{bemerkung}
\begin{beweis}
  Mit Univalenz, Bemerkung \labelcref{bem:ap-univalenz-sigma-prod} und Funktionsextensionalität:
  \begin{mathpar}
    \left(\prod_{x:A}B(x)\simeq B'(x)\right)\simeq \left(\prod_{x:A}B(x)= B'(x)\right)\simeq (B=B')
  \end{mathpar}
\end{beweis}

\begin{definition}
  Sei $A:\mU$ und $B,B':A\to\mU$ zwei abhängige Typen.
  \begin{enumerate}
  \item Eine \begriff{faserweise Abbildung} ist ein Term
    \begin{mathpar}
      f:\prod_{x:A}\left(B(x)\to B'(x)\right)
    \end{mathpar}
  \item Für eine faserweise Abbildung gibt es eine induzierte Abbildung
    \begin{mathpar}
      \sum f:\left(\sum_{x:A}B(x)\right)\to \left(\sum_{x:A} B'(x)\right)
    \end{mathpar}
    gegeben durch $\sum f(x,b_x)\colonequiv (x,f_x(b_x))$.
  \end{enumerate}
\end{definition}

\begin{lemma}
  \label{lem:faser-equiv}
  Seien $A:\mU$ und $B:A\to\mU$. Dann gilt
  \begin{mathpar}
     \prod_{x:A} \pi_1^{-1}(x)\simeq B(x)
  \end{mathpar}
\end{lemma}
\begin{beweis}
  Später.
\end{beweis}

Mit Univalenz können wir folgern, dass für jeden Typ $A$ die abhängigen Typen auf $A$ dasselbe sind, wie Funktionen nach $A$.
\begin{theorem}[Objektklassifikation]
  \label{lem:objektklassifizierer}
  Sei $B:\mU$. Dann gilt:
  \begin{mathpar}
    \left(\sum_{B:\mU}(B\to A)\right)\simeq (A\to \mU)
  \end{mathpar}
\end{theorem}

\begin{beweis}
  Einen abhängigen Typ $B:A\to\mU$ bilden wir auf die Funktion
  \begin{mathpar}
    \pi_1:\left(\sum_{x:A}B(x)\right)\to A
  \end{mathpar}
  ab. Und eine Funktion $f:B\to A$ bilden wir auf den abhängigen Typ ihrer Fasern ab:
  \begin{mathpar}
    \mathrm{fib}_f\equiv \left((x:A)\mapsto f^{-1}(x)\right):A\to \mU
  \end{mathpar}
  Nach \cref{lem:faser-equiv} ist also bereits diese Konstruktion linksinvers zur vorangegangenen.
  Es ist also noch zu zeigen, dass die Fasern einer Abbildung sich zur Domäne aufsummieren, bzw. dass für alle
  $f:A\to B$ gilt:
  \begin{mathpar}
    e:\left(\sum_{y:B}(f^{-1}(y))\right) \simeq A
  \end{mathpar}
  und $f\circ e=\pi_1$ gilt. Wir können mit \cref{lem:pfade-kontrahierbar} berechnen:
  \begin{align*}
    \left(\sum_{y:B}(f^{-1}(y))\right) &\simeq \sum_{y:B}\sum_{x:A}f(x)=y \\
                                       &\simeq \sum_{x:A}\sum_{y:B}f(x)=y\\
                                       &\simeq \sum_{x:A}\eins\\
                                       &\simeq A
  \end{align*}
\end{beweis}


\begin{lemma}
  \label{lem:faser-summe}
  Seien $A:\mU$, $B,B':A\to\mU$ und $f:\prod_{x:A}B(x)\to B'(x)$. Für alle $y:\sum_{x:A}B'(x)$ gilt:
  \begin{mathpar}
    \left((\sum f)^{-1}(y)\right)\simeq f_{\pi_1(y)}^{-1}(\pi_2(y))
  \end{mathpar}
\end{lemma}
\begin{beweis}
  Unser erstes Ziel ist es, Abbildungen in beide Richtungen durch Gleichheitsinduktion zu definieren.
  Sei dazu zunächst:
  \begin{mathpar}
    X:\prod_{z:\sum_{x:A}B(x)}\prod_{y:\sum_{x:A}B'(x)}\prod_{p:(\sum f) (z) = y} f_{\pi_1(y)}^{-1}(\pi_2(y))
  \end{mathpar}
  gegeben durch $X(z,(\sum f) (z), \refl_{(\sum f) (z)})\colonequiv(\pi_1(z),\refl_{f_{\pi_1(z)}(\pi_2(z))})$. Damit ist
  \begin{align*}
    &\varphi:\prod_{y:\sum_{x:A}B'(x)}\left((\sum f)^{-1}(y)\right)\to f_{\pi_1(y)}^{-1}(\pi_2(y)) \\
    &\varphi(y,(z,p))\colonequiv X(z,y,p)
  \end{align*}
  und mit der gleichen Vorgehensweise lässt sich
  \begin{mathpar}
    \psi:\prod_{y:\sum_{x:A}B'(x)}f_{\pi_1(y)}^{-1}(\pi_2(y)) \to \left((\sum f)^{-1}(y)\right)
  \end{mathpar}
  definieren und Homotopien, die zeigen dass $\varphi$ und $\psi$ zueinander invers sind.
\end{beweis}

\begin{lemma}
  Für $f:\prod_{x:A}B(x)\to B'(x)$ gilt: $f$ ist genau dann faserweise Äquivalenz, wenn $\sum f$ Äquivalenz ist.
\end{lemma}
\begin{beweis}
  Nach \cref{lem:faser-summe} sind alle Fasern aller $f_x$ genau dann kontrahierbar, wenn die Fasern von $\sum f$ kontrahierbar sind.
\end{beweis}

\begin{theorem}[Fundamentaler Gleichheitssatz]\index{Fundamentaler Gleichheitssatz}
  \label{thm:fundamental-gleichheit}
  Seien $A:\mU$ und $a:A$. Für $B:A\to \mU$ und eine faserweise Abbildung $f:\prod_{x:A}(a=x)\to B(x)$, dann ist $f$ genau dann eine faserweise Äquivalenz, wenn
  \begin{mathpar}
    \sum_{x:A}B(x)
  \end{mathpar}
  kontrahierbar ist.
\end{theorem}
\begin{beweis}
  Mit dem vorangegangenen Lemma wissen wir, dass $f$ genau dann eine faserweise Äquivalenz ist, wenn
  \begin{mathpar}
    \sum f:\left(\sum_{x:A}a=x\right)\to \left(\sum_{x:A}B(x)\right)
  \end{mathpar}
  eine Äquivalenz ist. In \cref{lem:pfade-kontrahierbar} haben wir gesehen, dass der linke Typ kontrahierbar ist, also gilt:
  \begin{mathpar}
    \left(\sum_{x:A}a=x\right)\simeq \eins
  \end{mathpar}
  Wenn nun auch $\eins\simeq \sum_{x:A}B(x)$ gilt, dann ist die Abbildung $\sum f$ bereits eine Äquivalenz, also auch $f$ eine faserweise Äquivalenz.
\end{beweis}

\begin{beispiel}
  Sei $\Eq{\zwei}:\zwei\to\zwei\to\mU$ gegeben durch Rekursion in beiden Argumenten:
  \begin{align*}
    \Eq{\zwei}(0_\zwei,0_\zwei)&\colonequiv\eins \\
    \Eq{\zwei}(0_\zwei,1_\zwei)&\colonequiv\leer \\
    \Eq{\zwei}(1_\zwei,0_\zwei)&\colonequiv\leer \\
    \Eq{\zwei}(1_\zwei,1_\zwei)&\colonequiv\eins 
  \end{align*}
  Mit \cref{thm:fundamental-gleichheit} können wir zeigen, dass
  \begin{mathpar}
    \prod_{x,y:\zwei}(x=_\zwei y)\simeq \Eq{\zwei}(x,y)
  \end{mathpar}
  indem wir für jedes $x:\zwei$ zeigen, dass $\sum_{y:\zwei}\Eq{\zwei}(x,y)$ kontrahierbar ist.
  Per $\zwei$-Induktion reicht es das für $x\equiv 0_\zwei,1_\zwei$ zu zeigen.
  Für
  \begin{mathpar}
    \sum_{y:\zwei}\Eq{\zwei}(0_\zwei,y)
  \end{mathpar}
  wählen wir als Kontraktionszentrum $(0_\zwei,\ast)$. Nun müssen wir zeigen, dass jeder andere Punkt gleich diesem Kontraktionszentrum ist, also mit $\sum$-Induktion:
  \begin{mathpar}
    \prod_{y:\zwei}\prod_{e:\Eq{\zwei}(0_\zwei,y)}(0_\zwei,\ast)=(y,e)
  \end{mathpar}
  Mit Anwenden von $\zwei$-Induktion auf $y$ reicht es also, die beiden Fälle $\prod_{e:\Eq{\zwei}(0_\zwei,0_\zwei)}(0_\zwei,\ast)=(0_\zwei,e)$ und $\prod_{e:\Eq{\zwei}(0_\zwei,1_\zwei)}(0_\zwei,\ast)=(1_\zwei,e)$ abzuhandeln.
  Im ersten Fall kann $\eins$-Induktion angewandt werden und $\refl_{(0_\zwei,\ast)}$ ist eine Lösung. Im zweiten Fall ist $\leer$-Induktion eine Lösung. \\
  Analog lässt sich zeigen, dass $\sum_{y:\zwei}\Eq{\zwei}(1_\zwei,y)$, was den Beweis beendet.
\end{beispiel}

Es ist also insbesondere $\zwei$ ein 0-Typ bzw. eine Menge.


Wir wollen nun noch \cref{lem:faser-equiv} beweisen. Dazu brauchen wir das folgende alternative Induktionsprinzip für Gleichheit:

\begin{lemma}[Pfadinduktion mit Basispunkt]\index{Gleichheitsinduktion mit Basispunkt}\index{Pfadinduktion mit Basispunkt}
  Seien $A:\mU$ und $x:A$ fest gewählt. Für einen abhängigen Typen $C:\prod_{y:A}x=y \to\mU$ reicht es dann $c:C(x,\refl_x)$ zu konstruieren, um eine abhängige Funktion $\prod_{y:A}\prod_{p:x=y}C(y,p)$ zu erhalten.
\end{lemma}
\begin{beweis}
  Sei $c:C(x,\refl_x)$. Dann gibt es den abhängigen Typen
  \begin{mathpar}
    C'\colonequiv(z:\sum_{y:A}x=y)\mapsto C(\pi_1(z),\pi_2(z))
  \end{mathpar}
  Wir wissen, dass die Basis $\sum_{y:A}x=y$ kontrahierbar ist, also gibt es Gleichheiten $q_{y,p}:(x,\refl_x)=(y,p)$, für alle $y:A$ und $p:x=y$ und damit
  \begin{mathpar}
    \transp(q_{y,p}):C(x,\refl_x)\to C(y,p)
  \end{mathpar}
  Also
  \begin{mathpar}
    y\mapsto (p:x=y)\mapsto \transp(q_{y,p}):\prod_{y:A}\prod_{p:x=y}C(y,p)
  \end{mathpar}
\end{beweis}

Damit können wir zeigen:

\begin{lemma}
  Seien $A:\mU$ und $B:A\to\mU$. Für $C:\left(\sum_{x:A}B(x)\right)\to\mU$ gilt:
  \begin{mathpar}
    \left(\sum_{y:\sum_{x:A}B(x)}C(y)\right)\simeq \sum_{x:A}\sum_{b:B(x)}C((x,b))
  \end{mathpar}
\end{lemma}
\begin{beweis}
  Aus Übungsaufgabe 1 von Blatt 6 wissen wir, dass es einen Term gibt (mit $p_{(x,b)}\equiv\refl_{(x,b)}$):
  \begin{mathpar}
    p:\prod_{z:\sum_{x:A}B(x)}z=(\pi_1(z),\pi_2(z))
  \end{mathpar}
  Es gibt die beiden folgenden Kandidaten für zueinander inversen Abbildungen:
  \begin{align*}
    \varphi&:\left(\sum_{y:\sum_{x:A}B(x)}C(y)\right)\to \sum_{x:A}\sum_{b:B(x)}C((x,b))\\
    \varphi((y,c))&\colonequiv (\pi_1(y),(\pi_2(y),\transp_C(p_y)(c))) \\
    \psi&: \left(\sum_{x:A}\sum_{b:B(x)}C((x,b))\right)\to\left(\sum_{y:\sum_{x:A}B(x)}C(y)\right) \\
    \psi((x,(b,c)))&\colonequiv((x,b),c)
  \end{align*}
  Damit gilt $\varphi\circ\psi\sim\id$ bereits punktweise urteilsmäßig, es ist also noch zu zeigen, dass auch $\psi\circ\varphi\sim\id$ gilt.
  Für $y:\sum_{x:A}B(x)$ und $c:C(y)$ gilt:
  \begin{align*}
    \psi(\varphi(y,c))&=\psi(\pi_1(y),(\pi_2(y),\transp_{C}(p_y)(c))) \\
    &=((\pi_1(y),\pi_2(y)), \transp_{C}(p_y)(c))
  \end{align*}
  Letzteres ist allerdings mit $\sum_=$ und $p_y$ gleich zu $(y,c)$.
\end{beweis}

Damit können wir nun \cref{lem:faser-equiv} beweisen:

\begin{beweis}[von \cref{lem:faser-equiv}]
  Seien $A:\mU$, $B:A\to\mU$ und $x:A$. Für $\pi_1:\sum_{x:A}B(x)\to A$ gilt:
  \begin{align*}
    \pi_1^{-1}(x)&\equiv \sum_{y:\sum_{x':A}B(x')}\pi_1(y)=x\\
                 &\simeq \sum_{x':A}\sum_{b:B(x')}\pi_1((x',b))=x \\
                 &\equiv \sum_{x':A}\sum_{b:B(x')} x'=x \\
                 &\simeq \sum_{x':A}\sum_{p:x'=x}B(x')\\
                 &\simeq B(x)
  \end{align*}
\end{beweis}


\subsection{Gleichheit natürlicher Zahlen}
\label{sec:zahlen-gleichheit}
\begin{definition}
  $\Eq{\N}:\N\to\N\to\mU$ definieren wir durch doppelte Rekursion wie folgt:
  \begin{align*}
    \Eq{\N}(0_\N,    0_\N)     &\colonequiv\einheit \\
    \Eq{\N}(0_\N,    \sucN(k)) &\colonequiv\leer \\
    \Eq{\N}(\sucN(n),0_\N)     &\colonequiv\leer \\
    \Eq{\N}(\sucN(n),\sucN(k)) &\colonequiv\Eq{\N}(n,k) 
  \end{align*}
\end{definition}

\begin{theorem}[Gleichheit natürlicher Zahlen]
  \label{thm:gleichheit-nat}
  Die faserweise Abbildung
  \begin{mathpar}
    \prod_{n,l:\N}n=l\to \Eq{\N}(n,l)
  \end{mathpar}
  gegeben durch $\refl_n\mapsto \ast$ ist eine faserweise Äquivalenz.
\end{theorem}
\begin{beweis}
  Nach \cref{thm:fundamental-gleichheit} reicht es zu zeigen, dass für jedes $n:\N$ der Typ
  \begin{mathpar}
    \sum_{l:\N}\Eq{\N}(n,l)
  \end{mathpar}
  kontrahierbar ist. Als Kontraktionszentrum wählen wir $(n,\ast)$.
  Nach Induktion über $n$,$l$ und Ausschluss aller Fälle mit leerer Domäne bleiben noch zu konstruieren:
  \begin{align*}
    &\prod_{e:\Eq{\N}(0,0)}(0,e)=(0,\ast) \\
    &\prod_{e:\Eq{\N}(\sucN(n),\sucN(l))}(\sucN(l),e)=(\sucN(n),\ast)
  \end{align*}
  Im ersten Fall lässt sich die Gleichheit stets durch die kontrahierbarkeit von $\eins$ konstruieren.
  Im zweiten Fall dürfen wir die Induktionshypothese verwenden:
  \begin{mathpar}
    \mathrm{IH}:\prod_{e:\Eq{\N}(n,l)}(l,e)=(n,\ast)
  \end{mathpar}
  Um etwas damit anfangen zu können, definieren wir uns folgenden Funktion:
  \begin{align*}
    f&:\left(\sum_{n:\N}\Eq{\N}(n,l)\right)\to \left(\sum_{n:\N}\Eq{\N}(n,\sucN(l))\right) \\
    f((n,e))&\colonequiv (n+1,e)
  \end{align*}
  Damit gilt dann für $e:\Eq{\N}(\sucN(n),\sucN(l))$:
  \begin{mathpar}
    f(\mathrm{IH}_e):\left(f((l,e))=f((n,\ast))\right)\equiv \left((\sucN(l),e)=(\sucN(n),\ast)\right)
  \end{mathpar}
\end{beweis}

\begin{bemerkung}
  $\N$ ist ein 0-Typ.
\end{bemerkung}
\begin{beweis}
  Wir wissen dass die Typen $\leer$ und $\eins$ Aussagen sind durch \cref{bsp:leer-eins-hlevel} und \cref{bem:kontrahierbar-folgt-aussage}.
  Mit $\N$-Induktion ist also $\Eq{\N}(n,k)$ für alle $n,k\in\N$ eine Aussage.
  Nach Definition ist ein Typ ein 0-Typ oder eine Menge, wenn alle Gleichheitstypen Aussagen sind, also sind wir mit \cref{thm:gleichheit-nat} fertig.
\end{beweis}

\subsection{Gleichheit algebraischer Strukturen}

Wir wollen in diesem Abschnitt am Beispiel der Halbgruppen sehen, dass Gleichheiten zwischen algebraischen Objekten genau den Isomorphismen entsprechen.
Da es sich etwa beim Typ der Halbgruppen um eine abhängige Summe handeln wird und wir die Gleichheitstypen vollständig verstehen wollen,
werden wir zunächst die Chrakterisierung von Gleichheitstypen in abhängigen Summen abschließen.

\begin{lemma}[Gleichheit in abhängigen Summen]
  \label{lem:gleichheit-summe}
  Seien $A:\mU$ und $B:A\to \mU$. Für $a,a':A$ und $b:B(a), b':B(a')$ gilt:
  \begin{mathpar}
    \left((a,b)=(a',b')\right)\simeq \sum_{p:a=a'}\transp_B(p)(b)=b'
  \end{mathpar}
\end{lemma}
\begin{beweis}
  Wir verwenden den Gleichheitssatz, \cref{thm:fundamental-gleichheit}.
  Sei dazu der abhängige Typ $\Eq{\sum}:\left(\sum_{x:A}B(x)\right)\to\left(\sum_{x:A}B(x)\right)\to\mU$ gegeben durch $\sum$-Induktion, also für $a,a':A$ und $b:B(a),b':B(a')$:
  \begin{align*}
    \Eq{\sum}((a,b),(a',b'))\colonequiv \sum_{p:a=a'}\transp_B(p)(b)=b'
  \end{align*}
  und weiter $r:\prod_{x:\sum_{a:A}B(a)}\Eq{\sum}(x,x)$ gegeben durch:
  \begin{mathpar}
    r((a,b))\colonequiv (\refl_a, \refl_b)
  \end{mathpar}
  Damit gibt es eine durch Gleichheitsinduktion definierte Funktion
  \begin{mathpar}
    f:\prod_{x,y:\sum_{a:A}B(a)}x=y\to \Eq{\sum}(x,y)
  \end{mathpar}
  Nach dem Gleichheitssatz reicht es nun also zu zeigen, dass für $x:\sum_{a:A}B(a)$ der Typ
  \begin{mathpar}
    \sum_{y:\sum_{a:A}B(a)}\Eq{\sum}(x,y)
  \end{mathpar}
  kontrahierbar ist. Es gilt für $x\equiv(a,b)$:
  \begin{align*}
    \sum_{y:\sum_{a:A}B(a)}\Eq{\sum}((a,b),y)&\simeq \sum_{a':A}\sum_{b':B(a')}\Eq{\sum}((a,b),(a',b')) \\
                                             &\equiv \sum_{a':A}\sum_{b':B(a')} \sum_{p:a=a'}\transp_B(p)(b)=b' \\
                                             &\simeq \sum_{a':A}\sum_{p:a=a'} \sum_{b':B(a')} \transp_B(p)(b)=b' \\
                                             &\simeq \sum_{a':A}\sum_{p:a=a'} \eins \\
                                             &\simeq \eins
  \end{align*}
\end{beweis}

\begin{definition}
  $\mathrm{Set}\colonequiv\sum_{A:\mU}\isSet(A)$
\end{definition}

\begin{definition}
  Sei $A:\mU$. Der Typ der \begriff{Halbgruppenstrukturen} auf $A$ ist gegeben durch:
  \begin{mathpar}
    \mathrm{HalbGrp}(A)\colonequiv \sum_{\_\cdot\_:A\to A\to A}\prod_{x,y,z:A} (x \cdot y) \cdot z = x \cdot (y \cdot z)
  \end{mathpar}
  Die Elemente $H:\sum_{A:\mathrm{Set}}\mathrm{HalbGrp}(A)$, heißen \begriff{Halbgruppen}.
\end{definition}

\begin{definition}
  Ein \begriff{Isomorphismus} von Halbgruppen $(H, \mathrm{str}) \to (H',\mathrm{str}')$ ist eine Äquivalenz $f:H\to H'$, sodass für alle $x,y:H$ gilt:
  \begin{mathpar}
    f(x \cdot y) = f(x) \cdot' f(y)
  \end{mathpar}
  wobei $\cdot$ die Multiplikation auf $H$ und $\cdot'$ die auf $H'$ ist.
  Wir bezeichnen mit $\mathrm{Isom}((H, \mathrm{str}), (H',\mathrm{str}'))$ den Typ der Isomorphismen zwischen zwei Halbgruppen.
\end{definition}

\begin{theorem}[Gleichheit von Halbgruppen]
  Seien $(H,\mathrm{str}),(H',\mathrm{str}):\sum_{A:\mU}\mathrm{HalbGrp}(A)$. Es gilt:
  \begin{mathpar}
    \left((H,\mathrm{str})=(H',\mathrm{str})\right)\simeq\mathrm{Isom}((H, \mathrm{str}), (H',\mathrm{str}'))
  \end{mathpar}
\end{theorem}
\begin{beweis}
  Mit \cref{lem:gleichheit-summe} folgt:
  \begin{mathpar}
    \left((H,\mathrm{str})=(H',\mathrm{str}')\right)\simeq \sum_{p:H=H'}\transp_{\mathrm{HalbGrp}}(p)(\mathrm{str})=\mathrm{str}'
  \end{mathpar}
  Das heißt, wir müssen nur noch klären, dass diese Summe äquivalent zum Typ der Isomorphismen ist.
  Dazu berechnen wir den Transport in $\mathrm{HalbGrp}$.
  Sei also $e:A\simeq B$ und $p\colonequiv\ua(e)$, dann erhalten wir eine Äquivalenz
  \begin{mathpar}
    \transp_{\mathrm{HalbGrp}}(p):\mathrm{HalbGrp}(A) \to \mathrm{HalbGrp}(B)
  \end{mathpar}
  und wir können durch Raten und anschließendem bestätigen durch Gleichheitsinduktion berechnen, was dieser Transport macht.
  Sei $(\_\cdot\_, \cdot\mathrm{assoc}):\mathrm{HalbGrp}(A)$.
  Wir raten zunächst, dass die Multiplikation mit $e$ prä- und postkomponiert wird, die Multiplikation des Bildes also für $x,y:B$ gegeben ist durch:
  \begin{mathpar}
    x \cdot' y \colonequiv e(e^{-1}(x) \cdot e^{-1}(y))
  \end{mathpar}
  Als Assoziativitätszeugen $\cdot'\mathrm{assoc}$ nehmen wir die Ergebnisgleichheit der folgenden Rechnung:
  \begin{align*}
    (x \cdot' y) \cdot' z & = e(e^{-1}e(e^{-1}(x)\cdot e^{-1}(y)) \cdot e^{-1}(z)) \\
                          & = e((e^{-1}(x)\cdot e^{-1}(y)) \cdot e^{-1}(z)) \\
                          & = e (e^{-1}(x)\cdot (e^{-1}(y) \cdot e^{-1}(z))) \\
                          & = e (e^{-1}(x)\cdot e^{-1}(e(e^{-1}(y) \cdot e^{-1}(z)))) \\
                          & =x \cdot' (y \cdot' z)
  \end{align*}
  Die Abbildung $e$ ist damit ein Isomorphismus.
  Nun können wir für diese Konstruktion sehen:
  \begin{mathpar}
    \transp_{\mathrm{HalbGrp}}(\ua(\id))((\_\cdot\_,\cdot\mathrm{assoc}))=(\_\cdot'\_,\cdot'\mathrm{assoc})
  \end{mathpar}
\end{beweis}
