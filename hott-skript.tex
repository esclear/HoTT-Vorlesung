% latexmk -pdflatex='xelatex %O %S' -pvc -pdf hott-skript.tex
\documentclass[a4paper,12pt]{article}

\usepackage[lmargin=2.5cm,rmargin=2.5cm,tmargin=2.5cm,bmargin=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage[linkcolor=black, colorlinks=true, citecolor=black]{hyperref}

\usepackage{polyglossia}
\setdefaultlanguage{german}

\usepackage{tikz}
\usetikzlibrary{cd}
\usetikzlibrary{arrows}

% für tabellen
\usepackage{booktabs}

\usepackage{mathpartir}

\usepackage{enumitem}
\setitemize{topsep=0pt,itemsep=0ex,partopsep=1ex,parsep=1ex}
\setenumerate{topsep=0pt,itemsep=1ex,partopsep=1ex,parsep=1ex}

\usepackage{ntheorem}
\theorembodyfont{}
\theoremstyle{break}
    \newtheorem{theorem}{Theorem}[subsection]
    \newtheorem{definition}[theorem]{Definition}
    \newtheorem{bemerkung}[theorem]{Bemerkung}
    \newtheorem{konvention}[theorem]{Konvention}
    \newtheorem{regeln}[theorem]{Regeln}
    \newtheorem{axiom}[theorem]{Axiom}
    \newtheorem{beispiel}[theorem]{Beispiel}
\theoremstyle{nonumberbreak}
\theoremstyle{nonumberplain}
\theoremsymbol{\ensuremath{□}}
    \newtheorem{beweis}{Beweis}

\usepackage{cleveref}

\usepackage{makeidx}

\usepackage{hott}
\setenumerate[1]{label=(\alph*),topsep=0pt}
\setenumerate[2]{label=(\roman*),topsep=0pt}

\title{Vorlesungsskript zur Homotopietypentheorie}
\author{Felix Cherubini}

\makeindex

\begin{document}

\maketitle

Dieses Skript entsteht als Begleitmaterial zur Vorlesung ``Homotopietypentheorie'' (HoTT), die ich im Sommersemester 2021 an der Universität Augsburg halte.
Zweck dieses Skripts ist es, den Zuhörern und mir selbst zur Erinnerung an die Vorlesungsinhalte zu dienen --
bei der Beschäftigung mit dem Thema ist es hilfreich in Lehrbücher zu schauen.
Das sogenannte \href{https://homotopytypetheory.org/book/}{``HoTT-Book''} ist sicher eine gute Quelle.

Wer Fehler findet und diese korrigieren oder darauf aufmerksam machen will, kann das auf der github seite dieses Skripts machen:
\href{https://github.com/felixwellen/HoTT-Vorlesung}{https://github.com/felixwellen/HoTT-Vorlesung}.
Dort gibt es auch die Möglichkeit, sogenannte ``Issues'' anzulegen.
Hier könnten sie etwa darüber informieren, wenn sie eine Passage nicht verstehen oder einen Fehler gefunden haben.
Sie haben über sogenannte ``Pull requests'' die Möglichkeit, Fehler auch selbst zu korrigieren.

Die Homotopietypentheorie ist eine eigenständige Art Mathematik zu betreiben und basiert auf einer abhängigen Typentheorie.
Das bringt mit sich, dass wir zunächst Erlernen werden, wie man in Homotopietypentheorie Objekte konstruiert, Aussagen formuliert und Beweise führt.
Nach den Grundlagen werden wir uns in Richtung Homotopietheorie orientieren, einem Teilgebiet der Mathematik, in dem einige Vorzüge der Ho\-mo\-to\-pie\-ty\-pen\-theo\-rie zur Geltung kommen.

Im Folgenden werden wir nach und nach \begriff{Regeln} einführen (oder zumindest erwähnen), die schließlich zusammen eine Typentheorie ergeben.
Diese werden wir noch um das sogenannte \begriff{Univalenzaxiom} erweitern.

\section*{Regeln}
Wir werden zunächst nur Regeln kennenlernen, die Teil einer abhängigen Typentheorie sind.
Regeln einer (abhängigen) Typentheorie können etwa so aussehen:
\begin{mathpar}
\inferrule*{\Gamma \yields f : A\to B \and \Gamma \yields t : A}{\Gamma \yields f(t) : B}
\end{mathpar}
Über dem waagrechten Strich stehen die Voraussetzungen und darunter, was aus den Voraussetzungen geschlossen werden darf.
Dabei kann man zum Beispiel ``$\Gamma \yields t : A$'' lesen als ``Im Kontext $\Gamma$ gibt es einen Term $t$ des Typs $A$''.
Wir werden nur anfangs mit Regeln arbeiten, um ein Verständnis für Typentheorie zu erlangen.
Irgendwann werden wir Regeln wie die obige wieder, wie in der Mathematik üblich, sprachlich formulieren,
etwa so
\begin{center}
  Für $f : A\to B$ und $t : A$ gibt es ein $f(t) : B$.
\end{center}
Wie wir später sehen werden, können diese Regeln zu Herleitungsbäumen kombiniert werden.
Dieses Kombinieren ist der vollständig formale Weg Beweise in der Homotopietypentheorie zu führen.

Ein Kontext wie ``$\Gamma$'' darf man sich als Liste von Variablen zusammen mit ihren Typen vorstellen. Also etwa so:
\begin{mathpar}
  x_1 : A_1, \cdots ,x_n : A_n
\end{mathpar}
Dabei dürfen die Variablen nach ihrer Einführung verwendet werden.
So könnte etwa in der Konstruktion des Typs $A_2$ die Variable $x_1$ verwendet werden.
Dass der Kontext eine solche Liste ist, wird üblicherweise durch die strukturellen Regeln einer abhängigen Typentheorie festgelegt.
\begin{table}
  \centering
  \begin{tabular}{ll}
    Urteil                        & Bedeutung (evtl. im Kontext $\Gamma$) \\
    \hline
    $\Gamma\yields t : A$         & $t$ ist ein Term vom Typ $A$ \\
    $\Gamma\yields A$ Typ         & $A$ ist ein Typ \\
    $\Gamma\yields A\equiv B$     & $A$ und $B$ sind (urteils-)gleiche Typen \\
    $\Gamma\yields t\equiv s : A$ & $t$ und $s$ sind (urteils-)gleiche Terme des Typs $A$ \\
    $\Gamma$ Kontext              & $\Gamma$ ist ein Kontext
  \end{tabular}
  \caption{Urteile}
  \label{tab:urteile}
\end{table}

Ein Block der Form ``$\Gamma \yields t : A$''  ist ein spezielles \begriff{Urteil}.
Insgesamt gibt es die Urteile in \cref{tab:urteile}.

Eine Regel ist im Allgemeinen Fall nun von dieser Form:
\begin{mathpar}
\inferrule{\mathcal U_1 \and \dots \and \mathcal U_n}{\mathcal U_0}{\mathrm{Name}}
\end{mathpar}
Für $n\in\mathbb N=\{0,1,\dots\}$ und Urteile $\mathcal U_0,\dots,\mathcal U_n$.

\subsection*{Strukturregeln}

Neben den Regeln für einzelne Typen, die wir in den folgenden Abschnitten kennenlernen, gibt es sogenannte \begriff{strukturelle Regeln} oder \begriff{Strukturregeln}.
Diese legen fest, wie Grundsätzliches funktioniert, etwa wie Kontexte geformt werden dürfen und was man mit Gleichheitsurteilen anfangen darf.
Hier ist ein Beispiel, die sogenannte ``Weakening''-Regel oder \begriff{Abschwächungsregel}:
\begin{mathpar}
\inferrule{\Gamma \yields \mathcal U \and \Gamma \yields A \text{ Typ}}{\Gamma, x : A \yields \mathcal U}{\Weak}
\end{mathpar}
Das gilt für alles was man durch andere Regeln an der Stelle von $\mathcal U$ bekommen könnte.
Die folgende \begriff{Variablenregel} erlaubt es Variablen aus dem Kontext zu benutzen:
\begin{mathpar}
  \inferrule{\Gamma, x:A\text{ Kontext}}{\Gamma, x:A\yields x:A }{\mathrm{Var}}
\end{mathpar}
Die Regeln für die Urteilsgleichheit legen fest, dass diese eine Äquivalenzrelation auf Termen und Typen ist.
Außerdem gibt es Strukturregeln und sogenannte \begriff{Kongruenzregeln}, die es letztendlich erlauben, Terme und Typen durch Urteilsgleiches zu ersetzen.
Wir erlauben es uns einfach zu Ersetzen und führen diese Regeln nicht aus.

Weiter sind Typentheorien typischerweise so aufgebaut, dass wenn es möglich ist $t:A$ herzuleiten, es auch immer möglich ist, $A\text{ Typ}$ herzuleiten,
in welchem Fall es wieder möglich ist, herzuleiten, dass der Kontext in dem das gilt ein Kontext ist.
Allgemeiner erlauben wir uns stets notwendige Voraussetzungen für vorliegende Urteile zu verwenden.
Also etwa der Schluss von einem Urteil, in dem der Typ ``$A\to B$'' vorkommt, zum Urteil ``$A$ Typ''.
Wir wollen diese Tatsachen frei verwenden und wie Regeln einsetzen, die wir zusammenfassend mit ``$\mathrm{Str}$'' bezeichnen.

Diese Regeln führen wir hier nicht auf, eine gute Quelle, um die genauen Regeln im Bedarfsfall anzuschauen,
ist das (noch nicht erschienene) Lehrbuch von Egbert Rijke oder Anhang A.2 des HoTT-Books.

\section{Abhängige Typentheorie}
\subsection{Abhängige Typen und Abhängige Produkte}

Von einem \begriff{Abhängigen Typen} spricht man im Fall eine Urteils
\begin{mathpar}
  \Gamma, x : A\yields B(x)\text{ Typ}
\end{mathpar}
Der Kontext besteht also aus mindestens einer Variablen $x$, die im abhängigen Typen $B(x)$ vorkommen darf.
Wir verwenden die Schreibweise ``$B(x)$'' um die Abhängigkeit klar zu machen --  in der Typentheorie ist es eher üblich hier nur ``$B$'' zu schreiben.
Ein Beispiel, das wir später mit unserer Typentheorie konstruieren könnten, ist der Typ der Listen der Länge $n$, wobei $n$ eine Variable des Typs $\mathbb N$ ist.

Eine wichtige Besonderheit der abhängigen Typentheorie ist es, dass der Typ der Werte einer Funktion variieren darf.
Diese allgemeineren Funktionen sind in sogenannten \begriff{abhängigen Produkten} oder \begriff{abhängigen Funktionstypen} enthalten.
Die folgende Regel erlaubt es uns, diesen Typ zu formen:
\begin{mathpar}
  \inferrule{\Gamma,x : A \yields B(x)\text{ Typ}}{\Gamma\yields\prod_{x:A}B(x)\text{ Typ}}{\PiForm}
\end{mathpar}
Abhängige Funktionen, die Elemente des abhängigen Produkts, können mit dieser Regel konstruiert werden:
\begin{mathpar}
  \inferrule{\Gamma,x : A \yields t(x) : B(x)}{\Gamma\yields x\mapsto t(x) : \prod_{x:A} B(x)}{\PiIntro}
\end{mathpar}
Der Term ``$x\mapsto t(x)$'' wird in der Typentheorie und allgemeiner in der Informatik geschrieben als ``$\lambda x.t(x)$''.
Wir schreiben auch manchmal $(x:A)\mapsto t(x)$, wenn der Typ der Variablen nicht klar ist.
Auch bei abhängigen Termen ist es in der Typentheorie eigentlich üblich nur ``$t:B$'' zu schreiben.
Das zusätzliche ``$(x)$'' steht hier nur zum besseren Verständnis durch Ähnlichkeit zu mathematischen Konventionen.
Die nächste Regel erlaubt es uns, abhängige Funktionen anzuwenden:
\begin{mathpar}
  \inferrule{\Gamma\yields f : \prod_{x:A}B(x) \and \Gamma\yields a : A}{\Gamma\yields f(a):B(a)}{\PiElim}
\end{mathpar}
Damit ist allerdings noch nicht gesagt, wie das Einsetzen eines Wertes in eine Funktion funktioniert.
Dafür müssen alle Vorkommen einer Variablen in einem Funktionsterm durch den eingesetzten Term ersetzt werden.
Diesen Vorgang nennt man Substitution und wir verwenden dafür die Notation $t(a)$ statt dem in der Informatik üblichen ``$t[a/x]$''.
Die folgende Regel sagt uns, dass wir durch Einsetzen von $a:A$ den Wert der Funktion $(x:A)\mapsto t(x)$, berechnen dürfen:
\begin{mathpar}
  \inferrule{\Gamma,x:A\yields t(x):B(x) \and \Gamma\yields a:A}{\Gamma\yields (x\mapsto t(x))(a)\equiv t(a) : B(a)}{\PiBeta}
\end{mathpar}
Eine Besonderheit der abhängigen Produkte ist es, dass man folgende Urteilsgleichheit noch zusätzlich fordert:
\begin{mathpar}
  \inferrule{\Gamma\yields f :\prod_{x:A}B(x)}{\Gamma\yields f\equiv (x\mapsto f(x)) : \prod_{x:A}B(x)}{\PiEta}
\end{mathpar}
Für alle weitere Typen, die wir einführen werden, wird sich ein ähnliches Schema ergeben.
Es gibt stets eine Regel, die es erlaubt den Typ zu formen, eine oder mehrere für die Konstruktion von Elementen und wieder eine oder mehrere, die festlegen, wie die Elemente des Typs verwendet werden dürfen.

Wenn $B(x)$ eigentlich gar nicht von $x:A$ abhängt, also $x$ nicht in $B$ vorkommt,
kann der Typ der abhängigen Funktionen, $\prod_{x:A}B(x)$, spezialisiert werden zum üblichen Funktionstyp $A\to B$:

Damit haben wir für beliebige Typen $A,B$ in einem Kontext $\Gamma$ den Typ der Funktionen von $A$ nach $B$:

\begin{definition}
  \begin{enumerate}
  \item Für Typen $A$ und $B$ gibt es stets den \begriff{Typ der Funktionen} $A\to B$, der mit der folgenden Herleitung geformt werden kann:
    \begin{mathpar}
      \inferrule{
        \inferrule{
          \Gamma\yields B\text{ Typ}\and \Gamma\yields A\text{ Typ}
        }{
          \Gamma,x:A\yields B\text{ Typ}
        }{
          \Weak
        }
      }{
        \Gamma\yields A\to B\text{ Typ}
      }{
        \PiForm
      }
    \end{mathpar}
    Die Terme dieses Typs nennen wir \begriff{Funktionen}.
  \item Unter der \begriff{Identität} $\id_A$ auf einem Typ $A$ verstehen wir die folgende Konstruktion:
    \begin{mathpar}
      \inferrule{
        \inferrule{
          \inferrule{
            \inferrule{
              \Gamma\yields A\text{ Typ}\and \Gamma\yields A\text{ Typ}
            }{
              \Gamma,x:A\yields A\text{ Typ}
            }{
              \Weak
            }
          }{
            \Gamma,x:A\text{ Kontext}
          }{
            \mathrm{Str}
          }
        }{
          \Gamma,x:A\yields x:A
        }{
          \Var
        }
      }{
        \Gamma\yields x\mapsto x : A\to A
      }{
        \PiIntro
      }
    \end{mathpar}
    Zusammengefasst: $\id_A:\equiv (x : A)\mapsto x$.
  \item Für Typen $A,B,C$ und Funktionen $f:A\to B$, $g:B\to C$ bezeichnen wir mit $g\circ f$ deren \begriff{Komposition}.
    Ganz genau ist die Komposition der durch die folgende Herleitung gegebene Term:
    \begin{mathpar}
      \inferrule{
        \inferrule{
          \inferrule{
            \inferrule{
              \Gamma\yields f:A\to B
            }{
              \Gamma\yields A\text{ Typ}
            }{
              \Str
            }
          }{
            \Gamma,x:A\yields x:A
          }{
            \Weak,\Var
          } \and \Gamma\yields f:A\to B}{
          \Gamma, x:A\yields f(x):B
        }{
          \PiElim} \and
        \inferrule{
          \Gamma\yields g:B\to C\and \Gamma\yields A\text{ Typ}
        }{
          \Gamma, x:A\yields g:B\to C
        }{
          \Weak
        }
      }{
        \inferrule{
          \Gamma, x : A\yields g(f(x)) : C
        }{
          \Gamma\yields x\mapsto g(f(x)) : A\to C
        }{
          \PiIntro
        }
      }{
        \PiElim
      }
    \end{mathpar}
    In Zukunft werden wir solche Sachverhalte auch einfach durch ``$f\circ g:\equiv x\mapsto f(g(x))$'' ausdrücken.
  \end{enumerate}
\end{definition}


\subsection{Natürliche Zahlen}
Im Gegensatz zum abhängigen Produkt ist der Typ der \begriff{Natürlichen Zahlen} nicht von anderen Typen abhängig.
Dementsprechend ist die Formierungsregel etwas einfacher:
\begin{mathpar}
  \inferrule{\Gamma\text{ Kontext} }{\Gamma\yields\N}{\N\mathrm{F}}
\end{mathpar}
Eine Neuheit ist, dass es zwei Regeln für die Konstruktion von Termen gibt:
\begin{mathpar}
  \inferrule{
    \Gamma\text{ Kontext}
  }{
    \Gamma\yields 0_{\N}:\N}{\N\mathrm{I1}
  }
  \quad
  \inferrule{
    \Gamma\yields n:\N
  }{
    \Gamma\yields\mathrm{succ}_{\N}(n):\N
  }{
    \N\mathrm{I2}
  }
\end{mathpar}
Soweit heißt das nur, dass man stets die Natürlichen Zahlen verwenden darf, es ein Element $0_{\N}$ und zu jeder natürlichen Zahl einen Nachfolger gibt.
Den Index ``$_{\N}$'' soll Verwechslungen verhindern und wird gelegentlich wegegelassen.
\begin{definition}
  Wir verwenden die übliche Schreibweise für natürliche Zahlen:
  \begin{mathpar}
    0:\equiv 0_{\N}, 1:\equiv \mathrm{succ}_{\N}(0), 2:\equiv \mathrm{succ}_{\N}(1),\dots
  \end{mathpar}
\end{definition}
Die nächste Regel wird es uns erlauben, per Induktion Aussagen über die natürlichen Zahlen zu zeigen, aber auch Funktionen auf den natürlichen Zahlen zu konstruieren:
\begin{mathpar}
  \inferrule{
    \Gamma,n:\N \yields P(n)\text{ Typ}
    \and \Gamma\yields \mathrm{IA} : P(0)
    \and \Gamma,n:\N,\mathrm{IH}:P(n)\yields \mathrm{IS}(n,\mathrm{IH}):P(\mathrm{succ}(n))
  }{
    \Gamma\yields\mathrm{ind}_{\N} (P,\mathrm{IA},\mathrm{IS}) : \prod_{n:\N}P(n)
  }{
    \N\mathrm{E}
  }
\end{mathpar}
Um die Regel mit bekannten Vorstellungen von Induktion zusammenzubringen, stellt man sich $P(n)$ als Aussage über die Zahl $n$ vor.
Wenn man es nun schafft, einen Term $p:P(n)$ zu konstruieren, bedeutet das, dass man die Aussage $P(n)$ bewiesen hat.
In dieser Lesart ist das abhängige Produkt $\prod_{n:\N}P(n)$ nichts anderes als ``$\forall n\in \N$ gilt $P(n)$''.
Nun muss man, um per Induktion eine Aussage zu zeigen, den Induktionsanfang (\textbf{IA}) zeigen und den Induktionsschritt (\textbf{IS}) aus der Induktionshypothese (\textbf{IH}) folgern.
Die zu diesen Einzelteilen passenden Terme sind in der Regel oben entsprechend benannt.

\begin{bemerkung}
  Wir werden später die Möglichkeit haben, mittels abhängigen Typen Aussagen über natürliche Zahlen zu konstruieren, wie z.B.
  \begin{mathpar}
    P(n):\equiv\text{ ``$n(n+1)=2\cdot (n + (n-1) + \dots + 1)$'' }
  \end{mathpar}
  Dazu fehlen uns momentan allerdings noch Typen für die zweite Art von Gleichheit ``$=$''.
  Bis wir diese einführen können, müssen wir uns noch mit konstanter Abhängigkeit begnügen.
\end{bemerkung}
Der wichtige Spezialfall der Regel $\N\mathrm{E}$ für (nicht-abhängige) Funktionen, heißt Rekursion:
\begin{definition}
  \label{def:rekursion}
  Sei $A$ ein Typ. Dann ist für $f_0:A$ und $f_s:\N\to(A\to A)$ durch $\N\mathrm{E}$ eine Funktion
  \begin{mathpar}
    \ind{\N}(n:\N\yields A,f_0,f_s):\equiv\rec{\N}(A,f_0,f_s):\N\to A
  \end{mathpar}
  gegeben. Diese Art Funktionen (auf $\N$) zu definieren nennt man ($\N$-)\begriff{Rekursion}.
\end{definition}
\begin{beispiel}
  \label{bsp:verdopplung}
  Sei $d:\N\to\N$ gegeben durch
  \begin{mathpar}
    d:\equiv \rec{\N}(\N, 0, n \mapsto (k \mapsto \sucN(\sucN(k))))
  \end{mathpar}
  das entspricht einer rekursiven Definition durch die Gleichungen
  \begin{align*}
    d(0)   &:\equiv 0 \\
    d(n+1) &:\equiv d(n)+2
  \end{align*}
  -- also einer Funktion, die ihr Argument verdoppelt.
\end{beispiel}

Noch haben wir keine Möglichkeit, eine durch Rekursion oder Induktion definierte Funktion für ein Argument auszuwerten.
Dazu brauchen wir $\beta$-Regeln, die nichts anderes sagen, als dass eine durch Induktion definierte Funktion die durch Induktionsanfang und Schritt gegebenen Werte auch annimmt.
Es sollen also für mit $\N\mathrm{E}$ definierte Funktionen gelten:
\begin{mathpar}
  \ind{\N}(P,\mathrm{IA},\mathrm{IS})(0_{\N})\equiv \mathrm{IA} \\
  \text{(Für $n:\N$) } \ind{\N}(P,\mathrm{IA},\mathrm{IS})(\sucN(n))\equiv \mathrm{IS}(n,\ind{\N}(P,\mathrm{IA},\mathrm{IS})(n))
\end{mathpar}
und damit für die Rekursion mit den Bezeichnern aus \cref{def:rekursion}:
\begin{mathpar}
  \rec{\N}(A,f_0,f_s)(0)\equiv f_0 \\
  \rec{\N}(A,f_0,f_s)(\sucN(n))\equiv f_s(n, \rec{\N}(A,f_0,f_s)(n))
\end{mathpar}
Die vollständigen $\beta$-Regeln sind wie folgt:
\begin{mathpar}
  \inferrule{
    \Gamma,n:\N \yields P(n)\text{ Typ}
    \and \Gamma\yields \mathrm{IA} : P(0)
    \and \Gamma,n:\N,\mathrm{IH}:P(n)\yields \mathrm{IS}(n,\mathrm{IH}):P(\mathrm{succ}(n))
  }{
    \Gamma\yields\mathrm{ind}_{\N} (P,\mathrm{IA},\mathrm{IS})(0_{\N})\equiv\mathrm{IA} : P(0_{\N})
  }{
    \N\beta_1
  } \\
  \inferrule{
    \Gamma,n:\N \yields P(n)\text{ Typ} 
    \and \Gamma\yields \mathrm{IA} : P(0) \\
    \and \Gamma,n:\N,\mathrm{IH}:P(n)\yields \mathrm{IS}(n,\mathrm{IH}):P(\mathrm{succ}(n)) \\
    \and \Gamma\yields k:\N
  }{
    \Gamma\yields\ind{\N} (P,\mathrm{IA},\mathrm{IS})(\sucN(k))\equiv\mathrm{IS}(k,\ind{\N} (P,\mathrm{IA},\mathrm{IS})(k)) : P(\sucN(k))
  }{
    \N\beta_2
  } 
\end{mathpar}
Damit können wir Werte der Funktion aus Beispiel \labelcref{bsp:verdopplung} berechnen:
\begin{beispiel}
  Für die Funktion $d:\N\to\N$ aus Beispiel \labelcref{bsp:verdopplung} ergibt sich mit den $\beta$-Regeln nun etwa:
  \begin{align*}
    d(3)&\equiv d(\sucN(2))    & \\
        &\equiv (k \mapsto \sucN(\sucN(k)))(d(2)) & (\N\beta_2) \\
        &\equiv \sucN(\sucN(d(2)))                & (\Pi\beta) \\
        &\equiv \sucN(\sucN(\sucN(\sucN(d(1))))) & (\N\beta_2, \Pi\beta) \\
        &\equiv \sucN(\sucN(\sucN(\sucN(\sucN(\sucN(d(0)) & (\N\beta_2, \Pi\beta) \\
        &\equiv 6 & (\N\beta_1)
  \end{align*}
\end{beispiel}
Folgende Konvention werden wir ab jetzt verwenden:
\begin{konvention}
  \begin{enumerate}[label=(\alph*)]
  \item Wir verwenden die folgenden Klammerungen:
    \begin{mathpar}
      \prod_{x:A}B\to C :\equiv \prod_{x:A}(B\to C)
    \end{mathpar}
    und auch im Allgemeinen, dass $\prod$ als letzter Typ-Former ausgeführt wird.
  \item Weiter klammern wir iterierte Funktionen von rechts:
    \begin{mathpar}
      A_1\to A_2 \to \dots \to A_n :\equiv A_1 \to (A_2 \to (\dots (A_{n-1} \to A_n)\dots)
    \end{mathpar}
  \item Wir erlauben uns etwas Freiheit beim Schreiben von Funktionsanwendungen, also etwa für $f:A\to B\to C$ auch mal $f(a,b)$ statt $f(a)(b)$ zu schreiben oder auch $a f b$, wenn $f$ ein Operator ist.
  \end{enumerate}
\end{konvention}
Zum Abschluss unserer ersten Betrachtung der natürlichen Zahlen werden wir nun die arithmetischen Operationen definieren:
\begin{definition}
  \begin{enumerate}
  \item Die Addition $+:\N\to\N\to\N$ ist gegeben durch die folgenden Urteilsgleichungen:
    \begin{align*}
      0 + k &:\equiv k \\
      \sucN(n) + k &:\equiv \sucN(n + k)
    \end{align*}
    Formal ist $+$ gegeben durch:
    \begin{mathpar}
      +:\equiv\rec{\N}(\N\to\N, k\mapsto k, n \mapsto f \mapsto (k \mapsto \sucN(f(k))))
    \end{mathpar}
  \item Die Multiplikation $\cdot:\N\to\N\to\N$ ist gegeben durch:
    \begin{align*}
      0 \cdot k &:\equiv 0  \\
      \sucN(n) \cdot k &:\equiv (n \cdot k) + k
    \end{align*}
    Bzw.:
    \begin{mathpar}
      \cdot :\equiv \rec{\N}(\N\to\N, k\mapsto 0, n \mapsto f\mapsto (k\mapsto f(k) + k))
    \end{mathpar}
  \end{enumerate}
\end{definition}
\begin{beispiel}
  Wir können nun wie folgt mit natürlichen Zahlen rechnen:
  \begin{align*}
    1+1 & \equiv \sucN(0)+1 \\
        & \equiv +(\sucN(0))(1) \\
        & \equiv (n \mapsto f \mapsto (k \mapsto \sucN(f(k))))(0)(+(0))(1) \\
        & \equiv (f \mapsto (k \mapsto \sucN(f(k))))(l \mapsto l)(1) \\
        & \equiv (k \mapsto \sucN((l \mapsto l)(k)))(1) \\
        & \equiv (k \mapsto \sucN(k))(1) \\
        & \equiv 2 \\
  \end{align*}
\end{beispiel}

\subsection{Induktive Typen}
Der Typ der natürlichen Zahlen ist ein Beispiel für einen sogenannten \begriff{induktiven Typ}.
Wir werden in diesem Abschnitt ein paar weitere Typen dieser Bauart kennenlernen.
Das sich dabei wiederholende Muster ist, dass der Typ jeweils im wesentlichen durch seine Einführungsregeln gegeben ist.
Eine Einführungsregel besteht im Wesentlichen aus einer Funktion in den Induktiven Typ, oder genauer ihrer Signatur.
Diese Funktionen werden wir von nun an \begriff{Konstruktoren} nennen.
Im Fall der natürlichen Zahlen gab es die beiden Konstruktoren $0_{\N}:\N$ und $\sucN:\N\to\N$.

Wir beginnen mit einem Typen, der in noch zu klärendem Sinn genau einen Term hat.
\begin{regeln}
  Der \begriff{Einheitstyp} $\einheit$ ist der Induktive Typ mit Konstruktur $\ast:\einheit$.
  Dadurch ergibt sich der folgende Satz von Regeln:
  \begin{mathpar}
    \inferrule{\Gamma\text{ Kontext} }{\Gamma\yields\einheit}{\einheit\mathrm{F}}
    \quad\quad
    \inferrule{
      \Gamma\text{ Kontext}
    }{
      \Gamma\yields \ast:\einheit}{\einheit\mathrm{I}
    }
    \quad\quad
    \inferrule{
      \Gamma,x:\einheit\yields P(x)\text{ Typ}\and \Gamma\yields p:P(\ast)
    }{
      \Gamma\yields\ind{\einheit}(P,p) : \prod_{x:\einheit}P(x)
    }{
      \einheit\mathrm{E}
    } \\
    \inferrule{
      \Gamma,x:\einheit\yields P(x)\text{ Typ}\and \Gamma\yields p:P(\ast)
    }{
      \Gamma\yields\ind{\einheit}(P,p)(\ast)\equiv p : P(\ast)
    }{
      \einheit\beta
    }
  \end{mathpar}
\end{regeln}
\begin{beispiel}
  Wir können die beiden Funktionen
  \begin{mathpar}
    (x\mapsto 0) : \einheit\to \N\text{ und } \rec{\einheit}(\N, 0) : \einheit\to \N
  \end{mathpar}
  definieren. Es ist allerdings nicht möglich zu zeigen, dass $(x\mapsto 0)\equiv \rec{\einheit}(\N, 0)$ gilt.
  Später werden wir in der Lage sein (mittels Induktion) zu zeigen, dass  Objektgleichheit ``$=$'' zwischen diesen Funktionen gilt.
\end{beispiel}
\begin{regeln}
  Der \begriff{leere Typ} $\leer$ ist der Induktive Typ ohne Konstruktur.
  Dadurch ergibt sich der folgende Satz von Regeln:
  \begin{mathpar}
    \inferrule{\Gamma\text{ Kontext} }{\Gamma\yields\leer}{\leer\mathrm{F}}
    \quad\quad
    \inferrule{
      \Gamma,x:\leer\yields P(x)\text{ Typ}
    }{
      \Gamma\yields\ind{\leer}(P) : \prod_{x:\leer}P(x)
    }{
      \leer\mathrm{E}
    }
  \end{mathpar}
\end{regeln}

\begin{regeln}
  Der \begriff{zweielementige Typ} oder \begriff{Bool} $\zwei$ ist ein Induktiver Typ mit den zwei Konstruktoren
  \begin{mathpar}
    0_{\zwei}:\zwei\quad\quad 1_{\zwei}:\zwei
  \end{mathpar}
  Wir verzichten diesmal auf Angabe der Regeln.
\end{regeln}

Es ist auch möglich, einen Induktiven Typen zu definieren, der von einem oder mehreren \begriff{Parametertypen} abhängt.
Der folgende induktive Typ kann für je zwei Typen geformt werden und ist typentheoretische Version der disjunkten Vereinigung:
\begin{regeln}
  Das \begriff{Koprodukt} zweier Typen $A$ und $B$ ist der induktive Typ $A\amalg B$ mit den Konstruktoren
  \begin{mathpar}
    \iota_1 : A \to A\amalg B\quad\quad \iota_2 : B\to A\amalg B
  \end{mathpar}
  Eine Funktion $f:A\amalg B\to C$ in einen Typen $C$, kann also definiert werden durch Angabe zweier Funktionen $f_1:A\to C$ und $f_2:B\to C$.
\end{regeln}
\begin{beispiel}
  \begin{enumerate}
  \item Das Koprodukt erlaubt eine Alternative Konstruktion des Typs $\zwei$ als $\einheit\amalg\einheit$.
    Wir können zwar noch nicht ausdrücken, dass zwei Typen gleich sind (abgesehen von der Urteilsgleichheit, die uns hier nicht helfen würde), wollen aber trotzdem schonmal die beiden Abbildungen definieren, die uns das später erlauben werden:
    \begin{align*}
      f(0_{\zwei})&:\equiv\iota_1(\ast) &g(\iota_1(\ast)):\equiv 0_{\zwei}\\
      f(1_{\zwei})&:\equiv\iota_2(\ast)&g(\iota_2(\ast)):\equiv 1_{\zwei}
    \end{align*}
  \item Für Typen $A$, $B$ gibt es stets die Abbildung
    \begin{mathpar}
      \ind{\amalg}(\zwei,(a:A)\mapsto 0_{\zwei},(b:B)\mapsto 1_{\zwei}) : A\amalg B\to \zwei.
    \end{mathpar}
  \end{enumerate}
\end{beispiel}

\subsection{Gleichheit}
Da wir uns im Folgenden der Situation nähern die Typentheorie einsetzen zu können, um über mathematische Objekte zu reden,
wollen wir auch weniger syntaktische Sprechweisen bevorzugen und etwa eher von \begriff{Elementen eines Typs} statt Termen sprechen.
Außerdem wollen wir es uns nun erlauben, Verschachtelte $\prod$-Ausdrücke über den gleichen Typen wie folgt abzukürzen:
\begin{mathpar}
  \prod_{x:A}\prod_{y:A}\dots :\equiv\prod_{x,y:A}\dots
\end{mathpar}

In diesem Abschnitt werden wir die \begriff{Gleichheit von Objekten} $x=y$ einführen.
Diese wollen wir im folgenden auch einfach nur \begriff{Gleichheit} nennen.
Im Gegensatz zur klassischen Mathematik ist die Gleichheit zwischen zwei Elementen $x,y:A$ eines Typs
selbst wieder ein vollwertiger Typ $x=_A y$.
Wir werden auch tatsächlich Beispiele von Typen sehen, deren Gleichheitstypen mehrere verschiedene Elemente enthalten.
Dies kann man sich als die Neuheit vorstellen, dass Dinge auf mehrere Arten gleich sein können.
\begin{regeln}
  Für zwei Elemente $x,y$ eines Typs $A$ können wir den Typ $x=_A y$ der \begriff{Gleichheiten} zwischen $x$ und $y$ formen.
  Dieser wird auch \begriff{Identitätstyp} genannt und ist als induktiver Typ durch den Konstruktor
  \begin{mathpar}
    \refl:\prod_{x:A}x=_A x
  \end{mathpar}
  festgelegt. 
  Wir nehmen von nun an die sich daraus ergebenden Regeln an, die wir im folgenden diskutieren werden.
\end{regeln}
Als Formierungs und Einführungsregeln ergeben sich:
\begin{mathpar}
  \inferrule{\Gamma\yields x:A\and \Gamma\yields y:A}{\Gamma\yields x=_A y\text{ Typ}}{=\mathrm{F}}\quad\quad
  \inferrule{\Gamma\yields x:A}{\Gamma\yields \refl_x: x=_A x}{=\mathrm{I}}
\end{mathpar}
Bevor wir weitere Regeln diskutieren, machen wir zunächst Beispiele:

\begin{beispiel}
  \begin{enumerate}
  \item Für $x,y:\einheit$ können wir nun den Typ $x=_{\einheit} y$ formen.
    Weiter können wir mit $\ind{\einheit}$ auch recht deutlich beschreiben, wie dieser Typ aussieht:
    \begin{mathpar}
      \ind{\einheit}(x:\einheit\yields x=_{\einheit} \ast, \refl_{\ast}) : \prod_{x:\einheit}x=\ast
    \end{mathpar}
  \item Für den leeren Typ können wir zeigen, dass je zwei $x,y:\leer$ gleich sind:
    \begin{mathpar}
      \ind{\leer}(x:\leer\yields \prod_{y:\leer}x=y) : \prod_{x,y:\leer}x=y
    \end{mathpar}
  \item Wenig überraschend, ist jedes $x:\zwei$ entweder gleich $0_{\zwei}$ oder $1_{\zwei}$,
    was wir mit dem Koprodukt ausdrücken können:
    \begin{mathpar}
      \ind{\zwei}(x:\zwei\yields(x=0_{\zwei})\amalg(x=1_{\zwei}), \iota_1(\refl_{0_{\zwei}}), \iota_2(\refl_{1_{\zwei}}) ) : \prod_{x:\zwei}(x=0_{\zwei})\amalg(x=1_{\zwei})
    \end{mathpar}
  \end{enumerate}
\end{beispiel}

Die Eliminationsregel, 
bzw die \begriff{Induktion für Gleichheit}, die auch \begriff{Pfadinduktion} genannt wird,
stellt sich als erstaunlich vielseitig heraus.
Sie besagt, dass für einen abhängigen Typen über dem Gleichheitstyp,
also etwa $x:A,y:A,p:x=_A y\yields B(p)$ und eine Vorgabe für $\refl_x$ also ein Element $b_r : \prod_{x:A} B(\refl_x)$ bereits eine abhängige Funktion wie folgt gegeben ist:
\begin{mathpar}
  \ind{=}(B,b_r) : \prod_{x,y:A}\prod_{p:x=_A y}B(p)
\end{mathpar}
Eine wünschenswerte Eigenschaft für Gleichheitsbegriffe ist, dass es sich um Äquivalenzrelationen handelt.
Da es sich bei unserem Gleichheitstyp im Allgemeinen um mehr als eine Relation handelt,
haben statt den Eigenschaften Reflexivität, Symmetrie und Transitivität eine sogenannte \begriff{Gruppoidstruktur}\footnote{Die Gleichungen, die in einem Gruppoid gelten würden, gelten hier nicht strikt.}.
Das bedeutet, dass diese drei Eigenschaften zu Operationen verallgemeinert werden.
Die Reflexivität ist bereits durch den Konstruktor gegeben und erlaubt es uns für jedes $x:X$ eine Gleichheit $x=_X x$ zu \emph{konstruieren}.
Statt der Symmetrie haben wir eine Umkehroperation oder Inversionsoperation von $x=y$ nach $y=x$ und die
Transitivität wird zu einer Verkettungsoperation oder Konkatenation von Gleichheiten:
\begin{definition}
  \begin{enumerate}
  \item Für $p:x=_A y$ bezeichnen wir mit $p^{-1}:y=_A x$ die \begriff{inverse Gleichheit}, also eine Funktion $\_^{-1}:x=_A y\to y=_A x$,
    welche wir durch Vorgabe für ``$\refl_x$'' definieren können:
    \begin{mathpar}
      (\refl_x)^{-1}:\equiv \refl_x
    \end{mathpar}
    bzw durch die folgende Induktion:
    \begin{mathpar}
      \ind{=}(x,y:A,p:x=_A y\yields y=_A x; \refl_{x}) : \prod_{x,y:A}\prod_{p:x=_A y}y=_A x
    \end{mathpar}
  \item Seien $x,y,z:A$. Für zwei Gleichheiten $p:x=_A y$ und $q:y=_A z$ ist die \begriff{Konkatenation} $p\kon q$ gegeben durch:
    \begin{mathpar}
      \refl_x\kon q :\equiv q
    \end{mathpar}
    Der Induktionsterm sieht wie folgt aus:
    \begin{align*}
      &\ind{=}(z,x,y:A,p:x=_A y\yields y=_A z\to x=_A z; \id_{x=_A z}) \\
      &: \prod_{x,y,z:A}(x=_A y)\to (y=_A z)\to (x=_A z)
    \end{align*}
  \end{enumerate}
\end{definition}

Nach diesen Konstruktionen wirkt die Induktionsregel für Gleichheit vielleicht etwas zu stark.
Tatsächlich wenden wir die nötige Arbeit um zu Beweisen zu kommen etwas versteckt beim definieren der abhängigen Typen auf,
auf die wir die Induktionsregel anwenden.
Dass es dabei etwas zu beachten gibt, sieht man an den Grenzen der Induktionsregel:
\begin{bemerkung}
  Das folgende kann nicht mit Induktion (und auch sonst mit keiner Regel der Vorlesung) gezeigt werden\footnote{So etwas lässt sich nicht so einfach formal zeigen. }:
  \begin{mathpar}
    \prod_{x:A} \prod_{p:x=_A x} p=_{x=x}\refl_x
  \end{mathpar}
\end{bemerkung}
Das Problem dabei ist, dass wir keine Möglichkeit haben zu fordern, dass die Endpunkte $x$ und $y$ die gleiche Variable sind.
Der abhängige Typ $x:A,p:x=_A x\yields p=\refl_x$ kann also nicht in die Form gebracht werden, die wir für die Induktionsregel brauchen.
In der Anschauung bedeutet das, dass es wichtig ist, dass wir Wege mit frei-beweglichen Endpunkten haben.

Die Notation der oben definierten Operationen erinnert stark an die einer Gruppe.
Tatsächlich können wir zeigen, dass auch ähnliche Gesetze für die Gleichheit gelten.
Zunächst verhält sich $\refl_x$ ähnlich wie ein Neutralelement:
\begin{bemerkung}
  \label{bem:refl-neutral}
  Seien $A$ ein Typ, $x,y:A$ und $p:x=_A y$. Dann gelten:
  \begin{enumerate}
  \item $\refl_x\kon p= p$
  \item $p\kon\refl_y=p$
  \end{enumerate}
\end{bemerkung}
\begin{beweis}
  \begin{enumerate}
  \item Diese Gleichung gilt bereits urteilsmäßig.
  \item Unser Ziel ist:
    \begin{mathpar}
      \prod_{x,y:A}\prod_{p:x=_A y} p\kon\refl_y=p
    \end{mathpar}
    Mit Induktion reicht es also zu zeigen
    \begin{mathpar}
      \prod_{x:A} \refl_x\kon\refl_x=\refl_x
    \end{mathpar}
    Der Term $\refl_x\kon\refl_x$ ist aber bereits nach Definition urteilsmäßig gleich $\refl_x$.
    Also ist $x\mapsto \refl_{\refl_x}$ ein passender Term.
  \end{enumerate}
\end{beweis}

Wir wollen nun damit fortfahren, den Namen \emph{Inversion} zu rechtfertigen.
Anschaulich, ist für eine Gleichheit $p:x=y$ ihr Inverses $p^{-1}:y=x$ einfach diejenige Gleichheit, die $p$ rückwärts durchläuft.
Der Weg $p\kon p^{-1}$ verläuft also von $x$ nach $y$ und dann auf dem gleichen Weg wieder zurück.
Insgesamt lässt sich der Weg $p\kon p^{-1}$ in Richtung $x$ zusammenziehen zum konstanten Weg $\refl_x:x=x$.

Formal können wir diese Tatsache mit einer Gleichheitsinduktion fassen:
\begin{bemerkung}
  Für einen Typ $A$ und Elemente $x,y:A$ gilt für jedes $p:x=_A y$:
  \begin{mathpar}
    p\kon p^{-1} =_{x=_A x} \refl_x
  \end{mathpar}
\end{bemerkung}
\begin{beweis}
  Wir wollen also etwas in folgendem Typ konstruieren:
  \begin{mathpar}
    \prod_{x,y:A}\prod_{p:x=y}p\kon p^{-1}=\refl_x.
  \end{mathpar}
  Um das mit Induktion zu erledigen, müssen wir das für $p\equiv\refl_x$ zeigen, also einen Term von
  \begin{mathpar}
    \prod_{x:A} \refl_x \kon\refl_x^{-1}=\refl_x
  \end{mathpar}
  angeben. Nach Definition von $\_^{-1}$ gilt $\refl_x^{-1}\equiv \refl_x$,
  also müssen wir für $x:A$ eigentlich nur etwas in $\refl_x\kon\refl_x =\refl_x$ konstruieren.
  Nach Definition von $\_\kon\_$ ist das aber nur $\refl_x=\refl_x$.
  D.h. wir haben mit
  \begin{mathpar}
    (x:A)\mapsto \refl_{\refl_x}
  \end{mathpar}
  den gesuchten Term konstruiert.
\end{beweis}

Bei Beweisen dieser Art ist es wichtig, dass es sich eigentlich um Konstruktionen handelt.
D.h. wir konstruieren Terme, die wir später auch verwenden werden und es kann passieren, dass die spezielle Konstruktion eine Rolle spielt.
In einem Typ $A$ ist kann es auch durchaus mehrere verschiedene Gleichheiten in $\refl_x\kon p=p$ geben.

Als letzte elementare Gleichung für das Rechnen mit Gleichheiten, zeigen wir die Assoziativität von $\_\kon\_$.

\begin{bemerkung}
  \label{bem:assoc}
  Für einen Typ $A$ und $x,y,z,w:A$ gilt:
  \begin{mathpar}
    \prod_{p:x=y}\prod_{q:y=z}\prod_{r:z=w} (p\kon q)\kon r = p \kon (q\kon r)
  \end{mathpar}
\end{bemerkung}
\begin{beweis}
  Durch umsortieren der Abhängigkeiten, was wir nach den Strukturregeln dürfen, können wir Induktion auf den folgenden abhänigen Typen anwenden:
  \begin{mathpar}
    x:A,y:A,p:x=_A y\yields \prod_{z,w:A}\prod_{q:y=z}\prod_{r:z=w}(p\kon q)\kon r = p \kon (q\kon r)
  \end{mathpar}
  Also müssen wir nur noch folgendes zeigen:
  \begin{mathpar}
    \prod_{x:A}\prod_{z,w:A}\prod_{q:x=z}\prod_{r:z=w}(\refl_x\kon q)\kon r = \refl_x \kon (q\kon r)
  \end{mathpar}
  Aber die Gleichung lässt sich nun mit per Definition gegebenen Urteilsgleichheiten reduzieren zu: $q\kon r=q\kon r$,
  was durch $\refl_{q\kon r}$ gegeben ist.
\end{beweis}

Auch die Assoziativität ist eine \emph{spezielle} Gleichheit in $(p\kon q)\kon r = p \kon (q\kon r)$.
In mathematischen Bereich in dem so etwas der Fall ist, wird daher auch manchmal von einem \emph{Assoziator} gesprochen,
weil es sich statt einer Aussage die gilt, eben um eine Operation handel, die Dinge produziert.
Diese neue Vielfalt kann Probleme mit sich bringen und es ist daher üblich, sogenannte \begriff{Kohärenz} zu fordern.
Dabei handelt es sich um natürlichen Gleichungen, die etwa zwischen verschiedenen Assoziatoren gelten sollten. Oder Gleichungen,
die zischen diesen Gleichheiten wieder gelten sollten. Falls Kohärenz gegeben ist, spricht man von \emph{höheren Strukturen}, z.B. von höheren Monoiden, höheren Gruppen oder Ringen.

In der Homotopietypentheorie, die wir in der Vorlesung lernen, gibt es zwar keine bekannte Möglichkeit solche Kohärenz allgemein zu definieren, aber man kann zum Beispiel im Fall der Gleichheitstypen $x=_A y$
und den vorgestellten Operationen erfahrungsgemäß immer alle Kohärenzen konstruieren, die man gerade braucht.
Ein Beispiel für eine Kohärenz, ein Level über der Assoziativität, ist das \begriff{MacLane Pentagon}:
\begin{bemerkung}
  Seien $A$ ein Typ, $x,y,z,w,u:A$.
  Dann gibt es für $p:x=y,q:y=z,r:z=w,s:w=u$ in $((p\kon q)\kon r)\kon s = p \kon (q\kon (r\kon s))$ zwei verschiedene natürliche Terme,
  zwischen denen sich eine Gleichheit konstruieren lässt.
\end{bemerkung}
Wir werden die Mittel erst noch einführen, mit denen diese Terme konstruiert werden können.

Wir wenden uns nun dem Verhalten von Gleichheit unter Abbildung mit Funktionen zu.
Für jeden sinnvollen Begriff von Gleichheit, will man sicher, dass er von Funktionen respektiert wird,
für eine Funktion $f:A\to B$ und $p:x=_A y$ sollte auch $f(x)=f(y)$ gelten bzw. eine Gleichheit in $f(x)=_B f(y)$ kontruierbar sein.
Das ist mit der bekannten Vorgehensweise schnell erledigt:
\begin{definition}
  \label{def:ap}
  Seien $A,B$ Typen, $f:A\to B$ eine Funktion, $x,y:A$ und $p:x=_A y$.
  Es sei $f(p):f(x)=_B f(y)$ das \begriff{Bild der Gleichheit} $p$, das wir auch mit $ap(f,p):f(x)=_B f(y)$ bezeichnen,
  gegeben durch
  \begin{mathpar}
    f(\refl_x):\equiv \refl_x
  \end{mathpar}
\end{definition}
Auch hierfür wollen wir zumindest die grundlegenden Gleichungen erwähnen:
\begin{bemerkung}
  Seien $A,B$ Typen und $f:A\to B$ eine Funktion. 
  \begin{enumerate}
  \item Für $x:A$ gilt $f(\refl_x)=\refl_{f(x)}$.
  \item Für $x,y:A$ und $p:x=_A y$ gilt $f(p^{-1})=f(p)^{-1}$.
  \item Für $x,y,z:A$ und $p:x=_A y, q:y=_A z$ gilt $f(p\kon q)=f(p)\kon f(q)$.
  \end{enumerate}
\end{bemerkung}
Die Beweise folgenen alle dem bekannten Schema.

\subsection{Abhängige Summen}
\subsection{Kontrahierbarkeit und Aussagen}
\subsection{Universen}
\subsection{Gleichungen in den natürlichen Zahlen}

\section{Univalenz}
\subsection{Homotopie von Abbildungen, Funktionsextensionalität}
\subsection{Äquivalenzen}
\subsection{Univalenz}

\section{Homotopietheorie}
\subsection{n-Typen}
\subsection{Höhere Induktive Typen}
\subsection{Überlagerungen}
\subsection{Homotopiegruppen}

\printindex

\end{document}
