% latexmk -pdflatex='xelatex %O %S' -pvc -pdf hott-skript.tex
\documentclass{hott}

\setenumerate[1]{label=(\alph*),topsep=0pt}
\setenumerate[2]{label=(\roman*),topsep=0pt}

\title{Vorlesungsskript zur Homotopietypentheorie}
\author{Felix Cherubini}

\makeindex

\begin{document}

\maketitle

\tableofcontents
 \pagebreak
Dieses Skript entsteht als Begleitmaterial zur Vorlesung ``Homotopietypentheorie'' (HoTT), die ich im Sommersemester 2021 an der Universität Augsburg halte.
Zweck dieses Skripts ist es, den Zuhörern und mir selbst zur Erinnerung an die Vorlesungsinhalte zu dienen --
bei der Beschäftigung mit dem Thema ist es hilfreich in Lehrbücher zu schauen.
Das sogenannte \href{https://homotopytypetheory.org/book/}{``HoTT-Book''} ist sicher eine gute Quelle.

Wer Fehler findet und diese korrigieren oder darauf aufmerksam machen will, kann das auf der github seite dieses Skripts machen:
\href{https://github.com/felixwellen/HoTT-Vorlesung}{https://github.com/felixwellen/HoTT-Vorlesung}.
Dort gibt es auch die Möglichkeit, sogenannte ``Issues'' anzulegen.
Hier könnten sie etwa darüber informieren, wenn sie eine Passage nicht verstehen oder einen Fehler gefunden haben.
Sie haben über sogenannte ``Pull requests'' die Möglichkeit, Fehler auch selbst zu korrigieren.

Die Homotopietypentheorie ist eine eigenständige Art Mathematik zu betreiben und basiert auf einer abhängigen Typentheorie.
Das bringt mit sich, dass wir zunächst Erlernen werden, wie man in Homotopietypentheorie Objekte konstruiert, Aussagen formuliert und Beweise führt.
Nach den Grundlagen werden wir uns in Richtung Homotopietheorie orientieren, einem Teilgebiet der Mathematik, in dem einige Vorzüge der Ho\-mo\-to\-pie\-ty\-pen\-theo\-rie zur Geltung kommen.

Im Folgenden werden wir nach und nach \begriff{Regeln} einführen (oder zumindest erwähnen), die schließlich zusammen eine Typentheorie ergeben.
Diese werden wir noch um das sogenannte \begriff{Univalenzaxiom} erweitern.

\section*{Regeln}
Wir werden zunächst nur Regeln kennenlernen, die Teil einer abhängigen Typentheorie sind.
Regeln einer (abhängigen) Typentheorie können etwa so aussehen:
\begin{mathpar}
\inferrule*{\Gamma \yields f : A\to B \and \Gamma \yields t : A}{\Gamma \yields f(t) : B}
\end{mathpar}
Über dem waagrechten Strich stehen die Voraussetzungen und darunter, was aus den Voraussetzungen geschlossen werden darf.
Dabei kann man zum Beispiel ``$\Gamma \yields t : A$'' lesen als ``Im Kontext $\Gamma$ gibt es einen Term $t$ des Typs $A$''.
Wir werden nur anfangs mit Regeln arbeiten, um ein Verständnis für Typentheorie zu erlangen.
Irgendwann werden wir Regeln wie die obige wieder, wie in der Mathematik üblich, sprachlich formulieren,
etwa so
\begin{center}
  Für $f : A\to B$ und $t : A$ gibt es ein $f(t) : B$.
\end{center}
Wie wir später sehen werden, können diese Regeln zu Herleitungsbäumen kombiniert werden.
Dieses Kombinieren ist der vollständig formale Weg Beweise in der Homotopietypentheorie zu führen.

Ein Kontext wie ``$\Gamma$'' darf man sich als Liste von Variablen zusammen mit ihren Typen vorstellen. Also etwa so:
\begin{mathpar}
  x_1 : A_1, \cdots ,x_n : A_n
\end{mathpar}
Dabei dürfen die Variablen nach ihrer Einführung verwendet werden.
So könnte etwa in der Konstruktion des Typs $A_2$ die Variable $x_1$ verwendet werden.
Dass der Kontext eine solche Liste ist, wird üblicherweise durch die strukturellen Regeln einer abhängigen Typentheorie festgelegt.
\begin{table}
  \centering
  \begin{tabular}{ll}
    Urteil                        & Bedeutung (evtl. im Kontext $\Gamma$) \\
    \hline
    $\Gamma\yields t : A$         & $t$ ist ein Term vom Typ $A$ \\
    $\Gamma\yields A$ Typ         & $A$ ist ein Typ \\
    $\Gamma\yields A\equiv B$     & $A$ und $B$ sind (urteils-)gleiche Typen \\
    $\Gamma\yields t\equiv s : A$ & $t$ und $s$ sind (urteils-)gleiche Terme des Typs $A$ \\
    $\Gamma$ Kontext              & $\Gamma$ ist ein Kontext
  \end{tabular}
  \caption{Urteile}
  \label{tab:urteile}
\end{table}

Ein Block der Form ``$\Gamma \yields t : A$''  ist ein spezielles \begriff{Urteil}.
Insgesamt gibt es die Urteile in \cref{tab:urteile}.

Eine Regel ist im Allgemeinen Fall nun von dieser Form:
\begin{mathpar}
\inferrule{\mathcal U_1 \and \dots \and \mathcal U_n}{\mathcal U_0}{\mathrm{Name}}
\end{mathpar}
Für $n\in\mathbb N=\{0,1,\dots\}$ und Urteile $\mathcal U_0,\dots,\mathcal U_n$.

\subsection*{Strukturregeln}

Neben den Regeln für einzelne Typen, die wir in den folgenden Abschnitten kennenlernen, gibt es sogenannte \begriff{strukturelle Regeln} oder \begriff{Strukturregeln}.
Diese legen fest, wie Grundsätzliches funktioniert, etwa wie Kontexte geformt werden dürfen und was man mit Gleichheitsurteilen anfangen darf.
Hier ist ein Beispiel, die sogenannte ``Weakening''-Regel oder \begriff{Abschwächungsregel}:
\begin{mathpar}
\inferrule{\Gamma \yields \mathcal U \and \Gamma \yields A \text{ Typ}}{\Gamma, x : A \yields \mathcal U}{\Weak}
\end{mathpar}
Das gilt für alles was man durch andere Regeln an der Stelle von $\mathcal U$ bekommen könnte.
Die folgende \begriff{Variablenregel} erlaubt es Variablen aus dem Kontext zu benutzen:
\begin{mathpar}
  \inferrule{\Gamma, x:A\text{ Kontext}}{\Gamma, x:A\yields x:A }{\mathrm{Var}}
\end{mathpar}
Die Regeln für die Urteilsgleichheit legen fest, dass diese eine Äquivalenzrelation auf Termen und Typen ist.
Außerdem gibt es Strukturregeln und sogenannte \begriff{Kongruenzregeln}, die es letztendlich erlauben, Terme und Typen durch Urteilsgleiches zu ersetzen.
Wir erlauben es uns einfach zu Ersetzen und führen diese Regeln nicht aus.

Weiter sind Typentheorien typischerweise so aufgebaut, dass wenn es möglich ist $t:A$ herzuleiten, es auch immer möglich ist, $A\text{ Typ}$ herzuleiten,
in welchem Fall es wieder möglich ist, herzuleiten, dass der Kontext in dem das gilt ein Kontext ist.
Allgemeiner erlauben wir uns stets notwendige Voraussetzungen für vorliegende Urteile zu verwenden.
Also etwa der Schluss von einem Urteil, in dem der Typ ``$A\to B$'' vorkommt, zum Urteil ``$A$ Typ''.
Wir wollen diese Tatsachen frei verwenden und wie Regeln einsetzen, die wir zusammenfassend mit ``$\mathrm{Str}$'' bezeichnen.

Diese Regeln führen wir hier nicht auf, eine gute Quelle, um die genauen Regeln im Bedarfsfall anzuschauen,
ist das (noch nicht erschienene) Lehrbuch von Egbert Rijke oder Anhang A.2 des HoTT-Books.

\section{Abhängige Typentheorie}
\subsection{Abhängige Typen und Abhängige Produkte}

Von einem \begriff{Abhängigen Typen} spricht man im Fall eine Urteils
\begin{mathpar}
  \Gamma, x : A\yields B(x)\text{ Typ}
\end{mathpar}
Der Kontext besteht also aus mindestens einer Variablen $x$, die im abhängigen Typen $B(x)$ vorkommen darf.
Wir verwenden die Schreibweise ``$B(x)$'' um die Abhängigkeit klar zu machen --  in der Typentheorie ist es eher üblich hier nur ``$B$'' zu schreiben.
Ein Beispiel, das wir später mit unserer Typentheorie konstruieren könnten, ist der Typ der Listen der Länge $n$, wobei $n$ eine Variable des Typs $\mathbb N$ ist.

Eine wichtige Besonderheit der abhängigen Typentheorie ist es, dass der Typ der Werte einer Funktion variieren darf.
Diese allgemeineren Funktionen sind in sogenannten \begriff{abhängigen Produkten} oder \begriff{abhängigen Funktionstypen} enthalten.
Die folgende Regel erlaubt es uns, diesen Typ zu formen:
\begin{mathpar}
  \inferrule{\Gamma,x : A \yields B(x)\text{ Typ}}{\Gamma\yields\prod_{x:A}B(x)\text{ Typ}}{\PiForm}
\end{mathpar}
Abhängige Funktionen, die Elemente des abhängigen Produkts, können mit dieser Regel konstruiert werden:
\begin{mathpar}
  \inferrule{\Gamma,x : A \yields t(x) : B(x)}{\Gamma\yields x\mapsto t(x) : \prod_{x:A} B(x)}{\PiIntro}
\end{mathpar}
Der Term ``$x\mapsto t(x)$'' wird in der Typentheorie und allgemeiner in der Informatik geschrieben als ``$\lambda x.t(x)$''.
Wir schreiben auch manchmal $(x:A)\mapsto t(x)$, wenn der Typ der Variablen nicht klar ist.
Auch bei abhängigen Termen ist es in der Typentheorie eigentlich üblich nur ``$t:B$'' zu schreiben.
Das zusätzliche ``$(x)$'' steht hier nur zum besseren Verständnis durch Ähnlichkeit zu mathematischen Konventionen.
Die nächste Regel erlaubt es uns, abhängige Funktionen anzuwenden:
\begin{mathpar}
  \inferrule{\Gamma\yields f : \prod_{x:A}B(x) \and \Gamma\yields a : A}{\Gamma\yields f(a):B(a)}{\PiElim}
\end{mathpar}
Damit ist allerdings noch nicht gesagt, wie das Einsetzen eines Wertes in eine Funktion funktioniert.
Dafür müssen alle Vorkommen einer Variablen in einem Funktionsterm durch den eingesetzten Term ersetzt werden.
Diesen Vorgang nennt man Substitution und wir verwenden dafür die Notation $t(a)$ statt dem in der Informatik üblichen ``$t[a/x]$''.
Die folgende Regel sagt uns, dass wir durch Einsetzen von $a:A$ den Wert der Funktion $(x:A)\mapsto t(x)$, berechnen dürfen:
\begin{mathpar}
  \inferrule{\Gamma,x:A\yields t(x):B(x) \and \Gamma\yields a:A}{\Gamma\yields (x\mapsto t(x))(a)\equiv t(a) : B(a)}{\PiBeta}
\end{mathpar}
Eine Besonderheit der abhängigen Produkte ist es, dass man folgende Urteilsgleichheit noch zusätzlich fordert:
\begin{mathpar}
  \inferrule{\Gamma\yields f :\prod_{x:A}B(x)}{\Gamma\yields f\equiv (x\mapsto f(x)) : \prod_{x:A}B(x)}{\PiEta}
\end{mathpar}
Für alle weitere Typen, die wir einführen werden, wird sich ein ähnliches Schema ergeben.
Es gibt stets eine Regel, die es erlaubt den Typ zu formen, eine oder mehrere für die Konstruktion von Elementen und wieder eine oder mehrere, die festlegen, wie die Elemente des Typs verwendet werden dürfen.

Wenn $B(x)$ eigentlich gar nicht von $x:A$ abhängt, also $x$ nicht in $B$ vorkommt,
kann der Typ der abhängigen Funktionen, $\prod_{x:A}B(x)$, spezialisiert werden zum üblichen Funktionstyp $A\to B$:

Damit haben wir für beliebige Typen $A,B$ in einem Kontext $\Gamma$ den Typ der Funktionen von $A$ nach $B$:

\begin{definition}
  \begin{enumerate}
  \item Für Typen $A$ und $B$ gibt es stets den \begriff{Typ der Funktionen} $A\to B$, der mit der folgenden Herleitung geformt werden kann:
    \begin{mathpar}
      \inferrule{
        \inferrule{
          \Gamma\yields B\text{ Typ}\and \Gamma\yields A\text{ Typ}
        }{
          \Gamma,x:A\yields B\text{ Typ}
        }{
          \Weak
        }
      }{
        \Gamma\yields A\to B\text{ Typ}
      }{
        \PiForm
      }
    \end{mathpar}
    Die Terme dieses Typs nennen wir \begriff{Funktionen}.
  \item Unter der \begriff{Identität} $\id_A$ auf einem Typ $A$ verstehen wir die folgende Konstruktion:
    \begin{mathpar}
      \inferrule{
        \inferrule{
          \inferrule{
            \inferrule{
              \Gamma\yields A\text{ Typ}\and \Gamma\yields A\text{ Typ}
            }{
              \Gamma,x:A\yields A\text{ Typ}
            }{
              \Weak
            }
          }{
            \Gamma,x:A\text{ Kontext}
          }{
            \mathrm{Str}
          }
        }{
          \Gamma,x:A\yields x:A
        }{
          \Var
        }
      }{
        \Gamma\yields x\mapsto x : A\to A
      }{
        \PiIntro
      }
    \end{mathpar}
    Zusammengefasst: $\id_A\colonequiv (x : A)\mapsto x$.
  \item Für Typen $A,B,C$ und Funktionen $f:A\to B$, $g:B\to C$ bezeichnen wir mit $g\circ f$ deren \begriff{Komposition}\index{$\circ$}.
    Ganz genau ist die Komposition der durch die folgende Herleitung gegebene Term:
    \begin{mathpar}
      \inferrule{
        \inferrule{
          \inferrule{
            \inferrule{
              \Gamma\yields f:A\to B
            }{
              \Gamma\yields A\text{ Typ}
            }{
              \Str
            }
          }{
            \Gamma,x:A\yields x:A
          }{
            \Weak,\Var
          } \and \Gamma\yields f:A\to B}{
          \Gamma, x:A\yields f(x):B
        }{
          \PiElim} \and
        \inferrule{
          \Gamma\yields g:B\to C\and \Gamma\yields A\text{ Typ}
        }{
          \Gamma, x:A\yields g:B\to C
        }{
          \Weak
        }
      }{
        \inferrule{
          \Gamma, x : A\yields g(f(x)) : C
        }{
          \Gamma\yields x\mapsto g(f(x)) : A\to C
        }{
          \PiIntro
        }
      }{
        \PiElim
      }
    \end{mathpar}
    In Zukunft werden wir solche Sachverhalte auch einfach durch ``$f\circ g\colonequiv x\mapsto f(g(x))$'' ausdrücken.
  \end{enumerate}
\end{definition}


\subsection{Natürliche Zahlen}
Im Gegensatz zum abhängigen Produkt ist der Typ der \begriff{Natürlichen Zahlen} nicht von anderen Typen abhängig.
Dementsprechend ist die Formierungsregel etwas einfacher:
\begin{mathpar}
  \inferrule{\Gamma\text{ Kontext} }{\Gamma\yields\N}{\N\mathrm{F}}
\end{mathpar}
Eine Neuheit ist, dass es zwei Regeln für die Konstruktion von Termen gibt:
\begin{mathpar}
  \inferrule{
    \Gamma\text{ Kontext}
  }{
    \Gamma\yields 0_{\N}:\N}{\N\mathrm{I1}
  }
  \quad
  \inferrule{
    \Gamma\yields n:\N
  }{
    \Gamma\yields\mathrm{succ}_{\N}(n):\N
  }{
    \N\mathrm{I2}
  }
\end{mathpar}
Soweit heißt das nur, dass man stets die Natürlichen Zahlen verwenden darf, es ein Element $0_{\N}$ und zu jeder natürlichen Zahl einen Nachfolger gibt.
Den Index ``$_{\N}$'' soll Verwechslungen verhindern und wird gelegentlich wegegelassen.
\begin{definition}
  Wir verwenden die übliche Schreibweise für natürliche Zahlen:
  \begin{mathpar}
    0\colonequiv 0_{\N}, 1\colonequiv \mathrm{succ}_{\N}(0), 2\colonequiv \mathrm{succ}_{\N}(1),\dots
  \end{mathpar}
\end{definition}
Die nächste Regel wird es uns erlauben, per Induktion Aussagen über die natürlichen Zahlen zu zeigen, aber auch Funktionen auf den natürlichen Zahlen zu konstruieren:
\begin{mathpar}
  \inferrule{
    \Gamma,n:\N \yields P(n)\text{ Typ}
    \and \Gamma\yields \mathrm{IA} : P(0)
    \and \Gamma,n:\N,\mathrm{IH}:P(n)\yields \mathrm{IS}(n,\mathrm{IH}):P(\mathrm{succ}(n))
  }{
    \Gamma\yields\mathrm{ind}_{\N} (P,\mathrm{IA},\mathrm{IS}) : \prod_{n:\N}P(n)
  }{
    \N\mathrm{E}
  }
\end{mathpar}
Um die Regel mit bekannten Vorstellungen von Induktion zusammenzubringen, stellt man sich $P(n)$ als Aussage über die Zahl $n$ vor.
Wenn man es nun schafft, einen Term $p:P(n)$ zu konstruieren, bedeutet das, dass man die Aussage $P(n)$ bewiesen hat.
In dieser Lesart ist das abhängige Produkt $\prod_{n:\N}P(n)$ nichts anderes als ``$\forall n\in \N$ gilt $P(n)$''.
Nun muss man, um per Induktion eine Aussage zu zeigen, den Induktionsanfang (\textbf{IA}) zeigen und den Induktionsschritt (\textbf{IS}) aus der Induktionshypothese (\textbf{IH}) folgern.
Die zu diesen Einzelteilen passenden Terme sind in der Regel oben entsprechend benannt.

\begin{bemerkung}
  Wir werden später die Möglichkeit haben, mittels abhängigen Typen Aussagen über natürliche Zahlen zu konstruieren, wie z.B.
  \begin{mathpar}
    P(n)\colonequiv\text{ ``$n(n+1)=2\cdot (n + (n-1) + \dots + 1)$'' }
  \end{mathpar}
  Dazu fehlen uns momentan allerdings noch Typen für die zweite Art von Gleichheit ``$=$''.
  Bis wir diese einführen können, müssen wir uns noch mit konstanter Abhängigkeit begnügen.
\end{bemerkung}
Der wichtige Spezialfall der Regel $\N\mathrm{E}$ für (nicht-abhängige) Funktionen, heißt Rekursion:
\begin{definition}
  \label{def:rekursion}
  Sei $A$ ein Typ. Dann ist für $f_0:A$ und $f_s:\N\to(A\to A)$ durch $\N\mathrm{E}$ eine Funktion
  \begin{mathpar}
    \ind{\N}(n:\N\yields A,f_0,f_s)\colonequiv\rec{\N}(A,f_0,f_s):\N\to A
  \end{mathpar}
  gegeben. Diese Art Funktionen (auf $\N$) zu definieren nennt man ($\N$-)\begriff{Rekursion}.
\end{definition}
\begin{beispiel}
  \label{bsp:verdopplung}
  Sei $d:\N\to\N$ gegeben durch
  \begin{mathpar}
    d\colonequiv \rec{\N}(\N, 0, n \mapsto (k \mapsto \sucN(\sucN(k))))
  \end{mathpar}
  das entspricht einer rekursiven Definition durch die Gleichungen
  \begin{align*}
    d(0)   &\colonequiv 0 \\
    d(n+1) &\colonequiv d(n)+2
  \end{align*}
  -- also einer Funktion, die ihr Argument verdoppelt.
\end{beispiel}

Noch haben wir keine Möglichkeit, eine durch Rekursion oder Induktion definierte Funktion für ein Argument auszuwerten.
Dazu brauchen wir $\beta$-Regeln, die nichts anderes sagen, als dass eine durch Induktion definierte Funktion die durch Induktionsanfang und Schritt gegebenen Werte auch annimmt.
Es sollen also für mit $\N\mathrm{E}$ definierte Funktionen gelten:
\begin{mathpar}
  \ind{\N}(P,\mathrm{IA},\mathrm{IS})(0_{\N})\equiv \mathrm{IA} \\
  \text{(Für $n:\N$) } \ind{\N}(P,\mathrm{IA},\mathrm{IS})(\sucN(n))\equiv \mathrm{IS}(n,\ind{\N}(P,\mathrm{IA},\mathrm{IS})(n))
\end{mathpar}
und damit für die Rekursion mit den Bezeichnern aus \cref{def:rekursion}:
\begin{mathpar}
  \rec{\N}(A,f_0,f_s)(0)\equiv f_0 \\
  \rec{\N}(A,f_0,f_s)(\sucN(n))\equiv f_s(n, \rec{\N}(A,f_0,f_s)(n))
\end{mathpar}
Die vollständigen $\beta$-Regeln sind wie folgt:
\begin{mathpar}
  \inferrule{
    \Gamma,n:\N \yields P(n)\text{ Typ}
    \and \Gamma\yields \mathrm{IA} : P(0)
    \and \Gamma,n:\N,\mathrm{IH}:P(n)\yields \mathrm{IS}(n,\mathrm{IH}):P(\mathrm{succ}(n))
  }{
    \Gamma\yields\mathrm{ind}_{\N} (P,\mathrm{IA},\mathrm{IS})(0_{\N})\equiv\mathrm{IA} : P(0_{\N})
  }{
    \N\beta_1
  } \\
  \inferrule{
    \Gamma,n:\N \yields P(n)\text{ Typ} 
    \and \Gamma\yields \mathrm{IA} : P(0) \\
    \and \Gamma,n:\N,\mathrm{IH}:P(n)\yields \mathrm{IS}(n,\mathrm{IH}):P(\mathrm{succ}(n)) \\
    \and \Gamma\yields k:\N
  }{
    \Gamma\yields\ind{\N} (P,\mathrm{IA},\mathrm{IS})(\sucN(k))\equiv\mathrm{IS}(k,\ind{\N} (P,\mathrm{IA},\mathrm{IS})(k)) : P(\sucN(k))
  }{
    \N\beta_2
  } 
\end{mathpar}
Damit können wir Werte der Funktion aus Beispiel \labelcref{bsp:verdopplung} berechnen:
\begin{beispiel}
  Für die Funktion $d:\N\to\N$ aus Beispiel \labelcref{bsp:verdopplung} ergibt sich mit den $\beta$-Regeln nun etwa:
  \begin{align*}
    d(3)&\equiv d(\sucN(2))    & \\
        &\equiv (k \mapsto \sucN(\sucN(k)))(d(2)) & (\N\beta_2) \\
        &\equiv \sucN(\sucN(d(2)))                & (\Pi\beta) \\
        &\equiv \sucN(\sucN(\sucN(\sucN(d(1))))) & (\N\beta_2, \Pi\beta) \\
        &\equiv \sucN(\sucN(\sucN(\sucN(\sucN(\sucN(d(0)) & (\N\beta_2, \Pi\beta) \\
        &\equiv 6 & (\N\beta_1)
  \end{align*}
\end{beispiel}
Folgende Konvention werden wir ab jetzt verwenden:
\begin{konvention}
  \begin{enumerate}[label=(\alph*)]
  \item Wir verwenden die folgenden Klammerungen:
    \begin{mathpar}
      \prod_{x:A}B\to C \colonequiv \prod_{x:A}(B\to C)
    \end{mathpar}
    und auch im Allgemeinen, dass $\prod$ als letzter Typ-Former ausgeführt wird.
  \item Weiter klammern wir iterierte Funktionen von rechts:
    \begin{mathpar}
      A_1\to A_2 \to \dots \to A_n \colonequiv A_1 \to (A_2 \to (\dots (A_{n-1} \to A_n)\dots)
    \end{mathpar}
  \item Wir erlauben uns etwas Freiheit beim Schreiben von Funktionsanwendungen, also etwa für $f:A\to B\to C$ auch mal $f(a,b)$ statt $f(a)(b)$ zu schreiben oder auch $a f b$, wenn $f$ ein Operator ist.
  \end{enumerate}
\end{konvention}
Zum Abschluss unserer ersten Betrachtung der natürlichen Zahlen werden wir nun die arithmetischen Operationen definieren:
\begin{definition}
  \begin{enumerate}
  \item Die Addition $+:\N\to\N\to\N$ ist gegeben durch die folgenden Urteilsgleichungen:
    \begin{align*}
      0 + k &\colonequiv k \\
      \sucN(n) + k &\colonequiv \sucN(n + k)
    \end{align*}
    Formal ist $+$ gegeben durch:
    \begin{mathpar}
      +\colonequiv\rec{\N}(\N\to\N, k\mapsto k, n \mapsto f \mapsto (k \mapsto \sucN(f(k))))
    \end{mathpar}
  \item Die Multiplikation $\cdot:\N\to\N\to\N$ ist gegeben durch:
    \begin{align*}
      0 \cdot k &\colonequiv 0  \\
      \sucN(n) \cdot k &\colonequiv (n \cdot k) + k
    \end{align*}
    Bzw.:
    \begin{mathpar}
      \cdot \colonequiv \rec{\N}(\N\to\N, k\mapsto 0, n \mapsto f\mapsto (k\mapsto f(k) + k))
    \end{mathpar}
  \end{enumerate}
\end{definition}
\begin{beispiel}
  Wir können nun wie folgt mit natürlichen Zahlen rechnen:
  \begin{align*}
    1+1 & \equiv \sucN(0)+1 \\
        & \equiv +(\sucN(0))(1) \\
        & \equiv (n \mapsto f \mapsto (k \mapsto \sucN(f(k))))(0)(+(0))(1) \\
        & \equiv (f \mapsto (k \mapsto \sucN(f(k))))(l \mapsto l)(1) \\
        & \equiv (k \mapsto \sucN((l \mapsto l)(k)))(1) \\
        & \equiv (k \mapsto \sucN(k))(1) \\
        & \equiv 2 \\
  \end{align*}
\end{beispiel}

\subsection{Induktive Typen}
Der Typ der natürlichen Zahlen ist ein Beispiel für einen sogenannten \begriff{induktiven Typ}.
Wir werden in diesem Abschnitt ein paar weitere Typen dieser Bauart kennenlernen.
Das sich dabei wiederholende Muster ist, dass der Typ jeweils im wesentlichen durch seine Einführungsregeln gegeben ist.
Eine Einführungsregel besteht im Wesentlichen aus einer Funktion in den Induktiven Typ, oder genauer ihrer Signatur.
Diese Funktionen werden wir von nun an \begriff{Konstruktoren} nennen.
Im Fall der natürlichen Zahlen gab es die beiden Konstruktoren $0_{\N}:\N$ und $\sucN:\N\to\N$.

Wir beginnen mit einem Typen, der in noch zu klärendem Sinn genau einen Term hat.
\begin{regeln}
  Der \begriff{Einheitstyp} $\einheit$ ist der Induktive Typ mit Konstruktur $\ast:\einheit$.
  Dadurch ergibt sich der folgende Satz von Regeln:
  \begin{mathpar}
    \inferrule{\Gamma\text{ Kontext} }{\Gamma\yields\einheit}{\einheit\mathrm{F}}
    \quad\quad
    \inferrule{
      \Gamma\text{ Kontext}
    }{
      \Gamma\yields \ast:\einheit}{\einheit\mathrm{I}
    }
    \quad\quad
    \inferrule{
      \Gamma,x:\einheit\yields P(x)\text{ Typ}\and \Gamma\yields p:P(\ast)
    }{
      \Gamma\yields\ind{\einheit}(P,p) : \prod_{x:\einheit}P(x)
    }{
      \einheit\mathrm{E}
    } \\
    \inferrule{
      \Gamma,x:\einheit\yields P(x)\text{ Typ}\and \Gamma\yields p:P(\ast)
    }{
      \Gamma\yields\ind{\einheit}(P,p)(\ast)\equiv p : P(\ast)
    }{
      \einheit\beta
    }
  \end{mathpar}
\end{regeln}
\begin{beispiel}
  Wir können die beiden Funktionen
  \begin{mathpar}
    (x\mapsto 0) : \einheit\to \N\text{ und } \rec{\einheit}(\N, 0) : \einheit\to \N
  \end{mathpar}
  definieren. Es ist allerdings nicht möglich zu zeigen, dass $(x\mapsto 0)\equiv \rec{\einheit}(\N, 0)$ gilt.
  Später werden wir in der Lage sein (mittels Induktion) zu zeigen, dass  Objektgleichheit ``$=$'' zwischen diesen Funktionen gilt.
\end{beispiel}
\begin{regeln}
  Der \begriff{leere Typ} $\leer$ ist der Induktive Typ ohne Konstruktur.
  Dadurch ergibt sich der folgende Satz von Regeln:
  \begin{mathpar}
    \inferrule{\Gamma\text{ Kontext} }{\Gamma\yields\leer}{\leer\mathrm{F}}
    \quad\quad
    \inferrule{
      \Gamma,x:\leer\yields P(x)\text{ Typ}
    }{
      \Gamma\yields\ind{\leer}(P) : \prod_{x:\leer}P(x)
    }{
      \leer\mathrm{E}
    }
  \end{mathpar}
\end{regeln}

\begin{regeln}
  Der \begriff{zweielementige Typ} oder \begriff{Bool} $\zwei$ ist ein Induktiver Typ mit den zwei Konstruktoren
  \begin{mathpar}
    0_{\zwei}:\zwei\quad\quad 1_{\zwei}:\zwei
  \end{mathpar}
  Wir verzichten diesmal auf Angabe der Regeln.
\end{regeln}

Es ist auch möglich, einen Induktiven Typen zu definieren, der von einem oder mehreren \begriff{Parametertypen} abhängt.
Der folgende induktive Typ kann für je zwei Typen geformt werden und ist typentheoretische Version der disjunkten Vereinigung:
\begin{regeln}
  Das \begriff{Koprodukt} zweier Typen $A$ und $B$ ist der induktive Typ $A\amalg B$ mit den Konstruktoren
  \begin{mathpar}
    \iota_1 : A \to A\amalg B\quad\quad \iota_2 : B\to A\amalg B
  \end{mathpar}
  Eine Funktion $f:A\amalg B\to C$ in einen Typen $C$, kann also definiert werden durch Angabe zweier Funktionen $f_1:A\to C$ und $f_2:B\to C$.
\end{regeln}
\begin{beispiel}
  \begin{enumerate}
  \item Das Koprodukt erlaubt eine Alternative Konstruktion des Typs $\zwei$ als $\einheit\amalg\einheit$.
    Wir können zwar noch nicht ausdrücken, dass zwei Typen gleich sind (abgesehen von der Urteilsgleichheit, die uns hier nicht helfen würde), wollen aber trotzdem schonmal die beiden Abbildungen definieren, die uns das später erlauben werden:
    \begin{align*}
      f(0_{\zwei})&\colonequiv\iota_1(\ast) &g(\iota_1(\ast))\colonequiv 0_{\zwei}\\
      f(1_{\zwei})&\colonequiv\iota_2(\ast)&g(\iota_2(\ast))\colonequiv 1_{\zwei}
    \end{align*}
  \item Für Typen $A$, $B$ gibt es stets die Abbildung
    \begin{mathpar}
      \ind{\amalg}(\zwei,(a:A)\mapsto 0_{\zwei},(b:B)\mapsto 1_{\zwei}) : A\amalg B\to \zwei.
    \end{mathpar}
  \end{enumerate}
\end{beispiel}

\subsection{Gleichheit}
Da wir uns im Folgenden der Situation nähern die Typentheorie einsetzen zu können, um über mathematische Objekte zu reden,
wollen wir auch weniger syntaktische Sprechweisen bevorzugen und etwa eher von \begriff{Elementen eines Typs} statt Termen sprechen.
Außerdem wollen wir es uns nun erlauben, Verschachtelte $\prod$-Ausdrücke über den gleichen Typen wie folgt abzukürzen:
\begin{mathpar}
  \prod_{x:A}\prod_{y:A}\dots \colonequiv\prod_{x,y:A}\dots
\end{mathpar}

In diesem Abschnitt werden wir die \begriff{Gleichheit von Objekten} $x=y$ einführen.
Diese wollen wir im folgenden auch einfach nur \begriff{Gleichheit} nennen.
Im Gegensatz zur klassischen Mathematik ist die Gleichheit zwischen zwei Elementen $x,y:A$ eines Typs
selbst wieder ein vollwertiger Typ $x=_A y$.
Wir werden auch tatsächlich Beispiele von Typen sehen, deren Gleichheitstypen mehrere verschiedene Elemente enthalten.
Dies kann man sich als die Neuheit vorstellen, dass Dinge auf mehrere Arten gleich sein können.
\begin{regeln}
  Für zwei Elemente $x,y$ eines Typs $A$ können wir den Typ $x=_A y$ der \begriff{Gleichheiten} zwischen $x$ und $y$ formen.
  Dieser wird auch \begriff{Identitätstyp} genannt und ist als induktiver Typ durch den Konstruktor
  \begin{mathpar}
    \refl:\prod_{x:A}x=_A x
  \end{mathpar}
  festgelegt. 
  Wir nehmen von nun an die sich daraus ergebenden Regeln an, die wir im folgenden diskutieren werden.
\end{regeln}
Als Formierungs und Einführungsregeln ergeben sich:
\begin{mathpar}
  \inferrule{\Gamma\yields x:A\and \Gamma\yields y:A}{\Gamma\yields x=_A y\text{ Typ}}{=\mathrm{F}}\quad\quad
  \inferrule{\Gamma\yields x:A}{\Gamma\yields \refl_x: x=_A x}{=\mathrm{I}}
\end{mathpar}
Bevor wir weitere Regeln diskutieren, machen wir zunächst Beispiele:

\begin{beispiel}
  \label{bsp:einheit-kontrahierbar} 
  \begin{enumerate}
  \item Für $x,y:\einheit$ können wir nun den Typ $x=_{\einheit} y$ formen.
    Weiter können wir mit $\ind{\einheit}$ auch recht deutlich beschreiben, wie dieser Typ aussieht:
    \begin{mathpar}
      \ind{\einheit}(x:\einheit\yields x=_{\einheit} \ast, \refl_{\ast}) : \prod_{x:\einheit}x=\ast
    \end{mathpar}
  \item Für den leeren Typ können wir zeigen, dass je zwei $x,y:\leer$ gleich sind:
    \begin{mathpar}
      \ind{\leer}(x:\leer\yields \prod_{y:\leer}x=y) : \prod_{x,y:\leer}x=y
    \end{mathpar}
  \item Wenig überraschend, ist jedes $x:\zwei$ entweder gleich $0_{\zwei}$ oder $1_{\zwei}$,
    was wir mit dem Koprodukt ausdrücken können:
    \begin{mathpar}
      \ind{\zwei}(x:\zwei\yields(x=0_{\zwei})\amalg(x=1_{\zwei}), \iota_1(\refl_{0_{\zwei}}), \iota_2(\refl_{1_{\zwei}}) ) : \prod_{x:\zwei}(x=0_{\zwei})\amalg(x=1_{\zwei})
    \end{mathpar}
  \end{enumerate}
\end{beispiel}

Die Eliminationsregel, 
bzw die \begriff{Induktion für Gleichheit}, die auch \begriff{Pfadinduktion} genannt wird,
stellt sich als erstaunlich vielseitig heraus.
Sie besagt, dass für einen abhängigen Typen über dem Gleichheitstyp,
also etwa $x:A,y:A,p:x=_A y\yields B(p)$ und eine Vorgabe für $\refl_x$ also ein Element $b_r : \prod_{x:A} B(\refl_x)$ bereits eine abhängige Funktion wie folgt gegeben ist:
\begin{mathpar}
  \ind{=}(B,b_r) : \prod_{x,y:A}\prod_{p:x=_A y}B(p)
\end{mathpar}
Eine wünschenswerte Eigenschaft für Gleichheitsbegriffe ist, dass es sich um Äquivalenzrelationen handelt.
Da es sich bei unserem Gleichheitstyp im Allgemeinen um mehr als eine Relation handelt,
haben statt den Eigenschaften Reflexivität, Symmetrie und Transitivität eine sogenannte \begriff{Gruppoidstruktur}\footnote{Die Gleichungen, die in einem Gruppoid gelten würden, gelten hier nicht strikt.}.
Das bedeutet, dass diese drei Eigenschaften zu Operationen verallgemeinert werden.
Die Reflexivität ist bereits durch den Konstruktor gegeben und erlaubt es uns für jedes $x:X$ eine Gleichheit $x=_X x$ zu \emph{konstruieren}.
Statt der Symmetrie haben wir eine Umkehroperation oder Inversionsoperation von $x=y$ nach $y=x$ und die
Transitivität wird zu einer Verkettungsoperation oder Konkatenation von Gleichheiten:
\begin{definition}
  \begin{enumerate}
  \item Für $p:x=_A y$ bezeichnen wir mit $p^{-1}:y=_A x$ die \begriff{inverse Gleichheit}, also eine Funktion $\_^{-1}:x=_A y\to y=_A x$,
    welche wir durch Vorgabe für ``$\refl_x$'' definieren können:
    \begin{mathpar}
      (\refl_x)^{-1}\colonequiv \refl_x
    \end{mathpar}
    bzw durch die folgende Induktion:
    \begin{mathpar}
      \ind{=}(x,y:A,p:x=_A y\yields y=_A x; \refl_{x}) : \prod_{x,y:A}\prod_{p:x=_A y}y=_A x
    \end{mathpar}
  \item Seien $x,y,z:A$. Für zwei Gleichheiten $p:x=_A y$ und $q:y=_A z$ ist die \begriff{Konkatenation} $p\kon q$ gegeben durch:
    \begin{mathpar}
      \refl_x\kon q \colonequiv q
    \end{mathpar}
    Der Induktionsterm sieht für $z:A$ wie folgt aus:
    \begin{align*}
      &\ind{=}(x,y:A,p:x=_A y\yields y=_A z\to x=_A z; \id_{x=_A z}) \\
      &: \prod_{x,y:A}(x=_A y)\to (y=_A z)\to (x=_A z)
    \end{align*}
  \end{enumerate}
\end{definition}

\begin{beispiel}
  Nach Beispiel \labelcref{bsp:einheit-kontrahierbar} gibt es einen Term
  \begin{mathpar}
    \prod_{x:\einheit} x=\ast
  \end{mathpar}
  Damit können wir nun auch zeigen, dass alles in $\einheit$ paarweise gleich ist:
  \begin{mathpar}
    (x,y:\einheit)\mapsto k(x)\kon k(y)^{-1}:\prod_{x,y:\einheit}x=y
  \end{mathpar}
\end{beispiel}

Nach diesen Konstruktionen wirkt die Induktionsregel für Gleichheit vielleicht etwas zu stark.
Tatsächlich wenden wir die nötige Arbeit um zu Beweisen zu kommen etwas versteckt beim definieren der abhängigen Typen auf,
auf die wir die Induktionsregel anwenden.
Dass es dabei etwas zu beachten gibt, sieht man an den Grenzen der Induktionsregel:
\begin{bemerkung}
  Das folgende kann nicht mit Induktion (und auch sonst mit keiner Regel der Vorlesung) gezeigt werden\footnote{So etwas lässt sich nicht so einfach formal zeigen. }:
  \begin{mathpar}
    \prod_{x:A} \prod_{p:x=_A x} p=_{x=x}\refl_x
  \end{mathpar}
\end{bemerkung}
Das Problem dabei ist, dass wir keine Möglichkeit haben zu fordern, dass die Endpunkte $x$ und $y$ die gleiche Variable sind.
Der abhängige Typ $x:A,p:x=_A x\yields p=\refl_x$ kann also nicht in die Form gebracht werden, die wir für die Induktionsregel brauchen.
In der Anschauung bedeutet das, dass es wichtig ist, dass wir Wege mit frei-beweglichen Endpunkten haben.

Die Notation der oben definierten Operationen erinnert stark an die einer Gruppe.
Tatsächlich können wir zeigen, dass auch ähnliche Gesetze für die Gleichheit gelten.
Zunächst verhält sich $\refl_x$ ähnlich wie ein Neutralelement:
\begin{bemerkung}
  \label{bem:refl-neutral}
  Seien $A$ ein Typ, $x,y:A$ und $p:x=_A y$. Dann gelten:
  \begin{enumerate}
  \item $\refl_x\kon p= p$
  \item $p\kon\refl_y=p$
  \end{enumerate}
\end{bemerkung}
\begin{beweis}
  \begin{enumerate}
  \item Diese Gleichung gilt bereits urteilsmäßig.
  \item Unser Ziel ist:
    \begin{mathpar}
      \prod_{x,y:A}\prod_{p:x=_A y} p\kon\refl_y=p
    \end{mathpar}
    Mit Induktion reicht es also zu zeigen
    \begin{mathpar}
      \prod_{x:A} \refl_x\kon\refl_x=\refl_x
    \end{mathpar}
    Der Term $\refl_x\kon\refl_x$ ist aber bereits nach Definition urteilsmäßig gleich $\refl_x$.
    Also ist $x\mapsto \refl_{\refl_x}$ ein passender Term.
  \end{enumerate}
\end{beweis}

Wir wollen nun damit fortfahren, den Namen \emph{Inversion} zu rechtfertigen.
Anschaulich, ist für eine Gleichheit $p:x=y$ ihr Inverses $p^{-1}:y=x$ einfach diejenige Gleichheit, die $p$ rückwärts durchläuft.
Der Weg $p\kon p^{-1}$ verläuft also von $x$ nach $y$ und dann auf dem gleichen Weg wieder zurück.
Insgesamt lässt sich der Weg $p\kon p^{-1}$ in Richtung $x$ zusammenziehen zum konstanten Weg $\refl_x:x=x$.

Formal können wir diese Tatsache mit einer Gleichheitsinduktion fassen:
\begin{bemerkung}
  Für einen Typ $A$ und Elemente $x,y:A$ gilt für jedes $p:x=_A y$:
  \begin{mathpar}
    p\kon p^{-1} =_{x=_A x} \refl_x
  \end{mathpar}
\end{bemerkung}
\begin{beweis}
  Wir wollen also etwas in folgendem Typ konstruieren:
  \begin{mathpar}
    \prod_{x,y:A}\prod_{p:x=y}p\kon p^{-1}=\refl_x.
  \end{mathpar}
  Um das mit Induktion zu erledigen, müssen wir das für $p\equiv\refl_x$ zeigen, also einen Term von
  \begin{mathpar}
    \prod_{x:A} \refl_x \kon\refl_x^{-1}=\refl_x
  \end{mathpar}
  angeben. Nach Definition von $\_^{-1}$ gilt $\refl_x^{-1}\equiv \refl_x$,
  also müssen wir für $x:A$ eigentlich nur etwas in $\refl_x\kon\refl_x =\refl_x$ konstruieren.
  Nach Definition von $\_\kon\_$ ist das aber nur $\refl_x=\refl_x$.
  D.h. wir haben mit
  \begin{mathpar}
    (x:A)\mapsto \refl_{\refl_x}
  \end{mathpar}
  den gesuchten Term konstruiert.
\end{beweis}

Bei Beweisen dieser Art ist es wichtig, dass es sich eigentlich um Konstruktionen handelt.
D.h. wir konstruieren Terme, die wir später auch verwenden werden und es kann passieren, dass die spezielle Konstruktion eine Rolle spielt.
In einem Typ $A$ kann es auch durchaus mehrere verschiedene Gleichheiten in $\refl_x\kon p=p$ geben.

Als letzte elementare Gleichung für das Rechnen mit Gleichheiten, zeigen wir die Assoziativität von $\_\kon\_$.

\begin{bemerkung}
  \label{bem:assoc}
  Für einen Typ $A$ und $x,y,z,w:A$ gilt:
  \begin{mathpar}
    \prod_{p:x=y}\prod_{q:y=z}\prod_{r:z=w} (p\kon q)\kon r = p \kon (q\kon r)
  \end{mathpar}
\end{bemerkung}
\begin{beweis}
  Durch umsortieren der Abhängigkeiten, was wir nach den Strukturregeln dürfen, können wir Induktion auf den folgenden abhänigen Typen anwenden:
  \begin{mathpar}
    x:A,y:A,p:x=_A y\yields \prod_{z,w:A}\prod_{q:y=z}\prod_{r:z=w}(p\kon q)\kon r = p \kon (q\kon r)
  \end{mathpar}
  Also müssen wir nur noch folgendes zeigen:
  \begin{mathpar}
    \prod_{x:A}\prod_{z,w:A}\prod_{q:x=z}\prod_{r:z=w}(\refl_x\kon q)\kon r = \refl_x \kon (q\kon r)
  \end{mathpar}
  Aber die Gleichung lässt sich nun mit per Definition gegebenen Urteilsgleichheiten reduzieren zu: $q\kon r=q\kon r$,
  was durch $\refl_{q\kon r}$ gegeben ist.
\end{beweis}

\begin{bemerkung}
  Für einen beliebigen Typen $A$ und ein Element $x:A$ erfüllt der Typ $x=_A x$ die naheliegenden Übersetzungen der Axiome einer Gruppe.
  Allerdings werden wir später noch mehr fordern, damit wir einen Typ eine Gruppe\index{Gruppe} nennen.
\end{bemerkung}

Auch die Assoziativität ist eine \emph{spezielle} Gleichheit in $(p\kon q)\kon r = p \kon (q\kon r)$.
In mathematischen Bereichen, in denen so etwas der Fall ist, wird daher auch manchmal von einem \emph{Assoziator} gesprochen,
weil es sich statt einer Aussage die gilt, eben um eine Operation handelt, die ein Datum produziert.
Diese neue Vielfalt kann Probleme mit sich bringen und es ist daher üblich, sogenannte \begriff{Kohärenz} zu fordern.
Dabei handelt es sich um natürlichen Gleichungen, die etwa zwischen verschiedenen Assoziatoren gelten sollten. Oder Gleichungen,
die zwischen diesen Gleichheiten wieder gelten sollten. Falls Kohärenz gegeben ist, spricht man von \emph{höheren Strukturen}, z.B. von höheren Monoiden, höheren Gruppen oder Ringen.

In der Homotopietypentheorie, die wir in der Vorlesung lernen, gibt es zwar keine bekannte Möglichkeit solche Kohärenz allgemein zu definieren, aber man kann zum Beispiel im Fall der Gleichheitstypen $x=_A y$
und den vorgestellten Operationen erfahrungsgemäß immer alle Kohärenzen konstruieren, die man gerade braucht.
Ein Beispiel für eine Kohärenz, ein Level über der Assoziativität, ist das \begriff{MacLane Pentagon}:
\begin{bemerkung}
  Seien $A$ ein Typ, $x,y,z,w,u:A$.
  Dann gibt es für $p:x=y,q:y=z,r:z=w,s:w=u$ in $((p\kon q)\kon r)\kon s = p \kon (q\kon (r\kon s))$ zwei verschiedene natürliche Terme,
  zwischen denen sich eine Gleichheit konstruieren lässt.
  \begin{figure}
    \begin{equation}
      \begin{tikzcd}[column sep={between origins,1.5cm},row sep={between origins,2.2cm}]
        & (p \kon (q \kon r)) \kon s
          \arrow[rr,equal]
        && p \kon ((q \kon r) \kon s)
          \arrow[dr,equal]
        &
        \\
        ((p \kon q) \kon r) \kon s
          \arrow[ur,equal]
          \arrow[drr,equal]
        &&&& p \kon (q \kon (r \kon s))
        \\
        && (p \kon q) \kon (r \kon s)
          \arrow[urr,equal]
        &&
      \end{tikzcd}
    \end{equation}
    \caption{MacLane-Pentagon}
  \end{figure}
\end{bemerkung}
Wir werden die Mittel erst noch einführen, mit denen diese Terme konstruiert werden können.

Wir wenden uns nun dem Verhalten von Gleichheit unter Abbildung mit Funktionen zu.
Für jeden sinnvollen Begriff von Gleichheit, will man sicher, dass er von Funktionen respektiert wird.
Für eine Funktion $f:A\to B$ und $p:x=_A y$ sollte auch $f(x)=f(y)$ gelten bzw. eine Gleichheit in $f(x)=_B f(y)$ kontruierbar sein.
Das ist mit der bekannten Vorgehensweise schnell erledigt:
\begin{definition}
  \label{def:ap}
  Seien $A,B$ Typen, $f:A\to B$ eine Funktion, $x,y:A$ und $p:x=_A y$.
  Es sei $f(p):f(x)=_B f(y)$ das \begriff{Bild der Gleichheit} $p$, das wir auch mit $ap(f,p):f(x)=_B f(y)$ bezeichnen,
  gegeben durch
  \begin{mathpar}
    f(\refl_x)\colonequiv \refl_{f(x)}
  \end{mathpar}
\end{definition}
Auch hierfür wollen wir zumindest die grundlegenden Gleichungen erwähnen:
\begin{bemerkung}
  Seien $A,B$ Typen und $f:A\to B$ eine Funktion. 
  \begin{enumerate}
  \item Für $x:A$ gilt $f(\refl_x)=\refl_{f(x)}$.
  \item Für $x,y:A$ und $p:x=_A y$ gilt $f(p^{-1})=f(p)^{-1}$.
  \item Für $x,y,z:A$ und $p:x=_A y, q:y=_A z$ gilt $f(p\kon q)=f(p)\kon f(q)$.
  \end{enumerate}
\end{bemerkung}
Die Beweise folgen alle dem bekannten Schema.

Eine weitere entscheidende Eigenschaft, die bei Gleichheit erwarten würde, ist, dass sich gleiche Dinge auch in allen Eigenschaften gleichen.
In leichter Abwandlung, könnte man auch sagen, wenn man eine Aussage $P(x)$ hat und zwei gleiche Objekte $x=y$, dann sollten $P(x)$ und $P(y)$ äquivalent sein.
Dabei würde es wegen der Symmetrie auch schon reichen, zu verlangen, dass im Fall der Gleichheit $P(y)$ aus $P(x)$ folgt.

Für unsere Gleichheit bekommen wir für einen abhängigen Typen $B$ sogar eine Abbildung $B(x)\to B(y)$ statt einer Implikation:
\begin{definition}
  Seien $A$ ein Typ und $x:A\yields B(x)$ ein abhängiger Typ über $A$. Dann sei für $x,y:A$ und $p:x=_A y$ die Abbildung
  \begin{mathpar}
    \mathrm{tr}_B(p):B(x)\to B(y)
  \end{mathpar}
  gegeben durch $\mathrm{tr}(\refl_x)\colonequiv \id_{B(x)}$.
  Die Abbildung $\mathrm{tr}_B(p)$ heißt \begriff{Transport} in $B$ entlang von $p$.
\end{definition}
Transport kann man für spezielle Typen konkretisieren.
\begin{lemma}
  \label{lem:transp-lpath}
  Seien $A$ ein Typ und $a:A$. Für den von $x:A$ abhängigen Typ $B(x)\colonequiv (x=a)$ kann der Transport für $x,x':A$ und $p:x=x'$ berechnet werden:
  \begin{mathpar}
    ((q:x=a)\mapsto p^{-1}\kon q) = \mathrm{tr}_B(p) : B(x) \to B(x')
  \end{mathpar}
\end{lemma}
\begin{beweis}
  Die Behauptung folgt aus:
  \begin{mathpar}
    (q:x=a)\mapsto \refl_x^{-1}\kon q = \id_{x=a} 
  \end{mathpar}
\end{beweis}

Außerdem verträgt sich der Transport mit der Konkatenation:
\begin{lemma}
  Seien $A$ ein Typ und $x:A\yields B(x)$. Für $x,y,z:A$ gilt:
  \begin{mathpar}
     \prod_{p:x=y}\prod_{q:y=z} \mathrm{tr}_B(q)\circ\mathrm{tr}_B(p)=\mathrm{tr}_B(p\kon q)
  \end{mathpar}
\end{lemma}
\begin{beweis}
  Induktion über $p$.
\end{beweis}

\subsection{Abhängige Summen}
Die abhängige Summe ist ein Typ, der die folgenden Konstruktionen und Aussagen in sich vereint:
\begin{align*}
  \exists x\in M: P(x) & & A\times B & & \coprod_{i\in I} A_i
\end{align*}
In der topologischen Anschauung entspricht die abhängige Summe dem Totalraum einer Faserung.
Ähnlich wie $\prod_{x:A}B(x)$ den Funktionstyp $A\to B$ verallgemeinert,
verallgemeinert die abhängige Summe das kartesische Produkt $A\times B$, dadurch, dass der rechte Faktor abhängig von $x:A$ variieren darf.


\begin{regeln}
  \begin{itemize}
  \item Für einen Typ $A$ und $x:A\yields B(x)$, kann die \begriff{abhängige Summe} $\sum_{x:A}B(x)$ gebildet werden.
    Die abhängige Summe wird auch \begriff{abhängiger Paartyp} oder \begriff{Sigmatyp} genannt und alternativ mit $(x:A)\times B(x)$ bezeichnet.
  \item Für $x:A$ und $b(x):B(x)$ gibt es ein \begriff{Paar}, also ein Element $(x,b(x)) : \sum_{x:A}B(x)$.
  \item Für einen abhängigen Typ $y:\sum_{x:A}B(x)\yields C(y)$ und einen abhängigen Term $x:A,b(x):B\yields c((x,b(x))) : C((x,b(x)))$ gibt es eine abhängige Funktion
    \begin{mathpar}
      \ind{\sum}(C, c):\prod_{y:\sum_{x:A}B(x)}C(y)
    \end{mathpar}
  \item Für auf diese Art definierte Funktionen gilt für $a:A, b:B(a)$ die Urteilsgleichheit
    \begin{mathpar}
      \ind{\sum}(C, c)((a,b))\equiv c((a,b)) : C((a,b))
    \end{mathpar}
  \end{itemize}
\end{regeln}

Wenn keine Verwechslungsgefahr besteht, wollen wir etwa für ``$c((a,b))$'' auch einfach ``$c(a,b)$'' schreiben.
Die Induktionsregel, also den dritten Punkt oben, hätten wir auch wie folgt formulieren können:
Für $c:\prod_{x:A}\prod_{b:B(x)}C(a,b)$ gibt es $\ind{\sum}(C,c):\prod_{y:\sum_{x:A}B(x)}C(y)$.
Und wir wollen auch hier wieder Funktionen durch ihre definierende Gleichung in folgender Form angeben:
\begin{mathpar}
  g(a,b)\colonequiv c(a,b)
\end{mathpar}
Es gibt Projektionen auf die Faktoren einer abhängigen Summe:
\begin{definition}
  Seien $A$ ein Typ und $x:A\yields B(x)$ abhängiger Typ über $A$.
  \begin{enumerate}
  \item Die Funktion $\pi_1:\left(\sum_{x:A}B(x)\right)\to A$ gegeben durch
      \begin{mathpar}
        \pi_1(a,b)\colonequiv a
      \end{mathpar}
      heißt \begriff{Projektion} auf die Basis oder Projektion auf den ersten Faktor.
    \item Die abhängige Funktion $\pi_2:\left(y:\sum_{x:A}B(x)\right)\to B(\pi_1(y))$ gegeben durch
      \begin{mathpar}
                \pi_2(a,b)\colonequiv b
      \end{mathpar}
      heißt zweite \begriff{Projektion} oder Projektion auf den zweiten Faktor.
  \end{enumerate}
\end{definition}

Wie bereits bei den Funktionen verwenden wir auch hier die übliche Notation, wenn keine echte Abhängigkeit vorliegt:
\begin{definition}
  Für zwei Typen $A$ und $B$ schreiben wir auch $A\times B$ statt $\sum_{x:A}B(x)$ und
  sprechen vom \begriff{Produkt}\footnote{Die übliche Terminologie ist hier leider etwas verwirrend...} von $A$ und $B$.
\end{definition}

Mit Produkten lassen sich Konjuntionen ausdrücken.
Ein Beispiel dafür ist die folgenden wichtigen Definitionen, die uns von nun an begleiten werden:
\begin{definition}
  Seien $A,B$ Typen.
  \begin{enumerate}
  \item Zwei Funktionen $f:A\to B$ und $g:B\to A$ sind \begriff{zueinander invers},
    wenn
    \begin{mathpar}
      \left(\prod_{x:A} g(f(x))=x\right)\times \left(\prod_{y:B}f(g(y))=y\right)
    \end{mathpar}
  \item Sei $f:A\to B$ eine Funktion. Wir sagen, dass $f$ eine \begriff{Quasi-Inverse} oder \begriff{Inverse} hat,
    wenn der Typ
    \begin{mathpar}
      \mathrm{qinv(f)}\colonequiv\sum_{g:B\to A}\left(\left(\prod_{x:A}g(f(x))=x\right) \times \left(\prod_{y:B}f(g(y))=y\right)\right)
      \end{mathpar}
      einen Term hat.
  \end{enumerate}
\end{definition}

Mit Produkten können wir nun sogenanntes \begriff{Currying} formal fassen:
\begin{definition}
  \label{def:currying}
  Seien $A,B,C$ Typen. Die Abbildung
  \begin{mathpar}
    \mathrm{curry}: ((A\times B) \to C) \to (A\to (B\to C))
  \end{mathpar}
  ist gegeben durch:
  \begin{mathpar}
    \mathrm{curry}(f)\colonequiv (x\mapsto (y\mapsto f(x,y)))
  \end{mathpar}
  Analog lässt sich auch \begriff{Uncurrying} definieren:
  \begin{align*}
    &\mathrm{uncurry}: (A\to (B\to C)) \to ((A\times B) \to C) \\
    &\mathrm{uncurry}(f)\colonequiv x\mapsto f(\pi_1(x),\pi_2(x))
  \end{align*}
\end{definition}

\begin{bemerkung}
  Die Funktionen $\mathrm{curry}$ und $\mathrm{uncurry}$ sind zueinander invers.
  Allerdings können wir das und viele andere Aussagen dieser Form über Funktionen noch nicht mit der soweit eingeführten Typentheorie beweisen.
\end{bemerkung}

Mit abhängigen Summen haben wir die Möglichkeit, Existenzaussagen zu formulieren:
\begin{definition}
  Seien $a,d:\N$. Die Phrase $d$ \begriff{teilt} $a$ steht für den folgenden Typen:
  \begin{mathpar}
    \sum_{c:\N} c\cdot d = a
  \end{mathpar}
\end{definition}
Gleichungen in den natürlichen Zahlen werden wir uns später noch zuwenden.
Zunächst wollen wir uns damit beschäftigen, wie sich für abhängige Summen oder speziell Produkte der Gleichheitstyp verhält.
\begin{lemma}
  \label{lem:produkt-gleich}
  Seien $A,B$ Typen.
  \begin{enumerate}
  \item Für $x:A\times B$ gilt $x=(\pi_1(x),\pi_2(x))$.
  \item Seien $(a,b),(a',b'):A\times B$, dann gibt es zueinander inverse Funktionen:
    \begin{mathpar}
      \pair_{=}: ((a=_A a')\times (b=_B b')) \to (a,b)=_{A\times B} (a',b')
    \end{mathpar}
    und
    \begin{mathpar}
      \pair_{=}^{-1}: (a,b)=_{A\times B} (a',b') \to ((a=_A a')\times (b=_B b'))
    \end{mathpar}
  \end{enumerate}
\end{lemma}
\begin{beweis}
  \begin{enumerate}
  \item Ziel ist es, einen Term in
    \begin{mathpar}
      \prod_{x:A\times B} x=(\pi_1(x),\pi_2(x))
    \end{mathpar}
    zu konstruieren. Mit $\sum$-Induktion folgt dieser aus:
    \begin{mathpar}
      a\mapsto b \mapsto \refl_{(a,b)}:\prod_{a : A}\prod_{b : B} (a,b)=(\pi_1(a,b),\pi_2(a,b))
    \end{mathpar}
    Zur Verwendung in Teil (b), geben wir den damit konstruierten Term den Namen $u$.
  \item Wir definieren $\mathrm{pair}_=$ durch doppelte Gleichheitsinduktion:
    \begin{mathpar}
      \pair_=(\refl_a,\refl_b)\colonequiv \refl_{(a,b)}
    \end{mathpar}
    und $\mathrm{pair}_=^{-1}$ definieren wir zunächst etwas zu allgemein durch Bilder einer Gleichheit $p:x=y$ unter den Projektionen:
    \begin{mathpar}
      \pair_=^{-1'}(p)\colonequiv (\pi_1(p),\pi_2(p))
    \end{mathpar}
    und setzen $\pair_=^{-1}(p:(a,a')=(b,b'))\colonequiv\pair_=^{-1'}(p)$.
    Damit können wir mit Gleichheitsinduktion zeigen, dass $\pair_=$ und $\pair_=^{-1}$ zueinander invers sind.
    Ein Teil ist sofort erledigt:
    \begin{mathpar}
      \refl_{(\refl_a,\refl_b)}:\pair_=^{-1}(\pair_=(\refl_a,\refl_b))=(\refl_a,\refl_b)
    \end{mathpar}
    Für den anderen bekommen konstruieren wir erstmal einen Term
    \begin{mathpar}
      t:\prod_{x,y:A\times B}\prod_{p:x=y}\pair_=(\pair_=^{-1'})(p)=u(\pi_1(x),\pi_2(x))^{-1}\kon p\kon u(\pi_1(y),\pi_2(y))
    \end{mathpar}
    durch Gleichheits- und $\sum$-Induktion -- wir dürfen also $\refl_{(a,b)}$ für $p$ einsetzen:
    \begin{mathpar}
      \pair_=(\pair_=^{-1'})(\refl_{(a,b)})=\refl_{(a,b)}^{-1}\kon \refl_{(a,b)}\kon \refl_{(a,b)}
    \end{mathpar}
    Linke und rechte Seite sind per Definition gleich $\refl_{(a,b)}$, also müssen wir nur noch den somit konstruierten Term $t$ entsprechend anpassen.
    Für $p:(a,b)=(a',b')$ lassen sich dazu folgende Gleichheiten konstruieren:
    \begin{align*}
      \pair_=(\pair_=^{-1})(p)&\equiv \pair_=(\pair_=^{-1'})(p)& & t_{(a,b),(a',b'),p} \\
                              & =u(a,b)^{-1}\kon p\kon u(a',b') & & \text{Def.} \\
                              & \equiv \refl_{(a,b)}^{-1}\kon p\kon \refl_{(a',b')} & & \text{Def.} \\
                              & \equiv p\kon\refl_{(a',b')}& & \text{Bemerkung \labelcref{bem:refl-neutral}}\\
                              & = p & &
    \end{align*}
  \end{enumerate}
\end{beweis}

Für allgemeine abhängige Summen gibt es eine ähnliche Möglichkeit, Gleichheiten zu erzeugen.
Hier ist allerdings eine Schwierigkeit, dass zwei Elemente im zweiten Faktor, also etwa $b_x:B(x)$ und $b_y:B(y)$ im Allgemeinen nicht vom selben Typ sind.
Also ergibt es keinen Sinn, nach einer Gleichheit $q:b_x=b_y$ zu fragen.
Um $b_x$ mit $b_y$ zu vergleichen, können wir es entlang einer Gleichheit $p:x=y$ transportieren, also nach $\mathrm{tr}_B(p)(b_x)=b_y$ fragen.
\begin{lemma}
  Seien $A$ ein Typ und $x:A\yields B(x)$ abhängig über $A$.
  Für $x,y:A$ und $b_x:B(x)$, $b'_y:B(y)$ gibt es eine Funktion
  \begin{mathpar}
    \sum_=:\prod_{p:x=y} \mathrm{tr}_B(p)(b_x)=b'_y \to (x,b_x)=(y,b'_y)
  \end{mathpar}
\end{lemma}
\begin{beweis}
  Mit Induktion über $p$ reicht es, eine Funktion folgenden Typs anzugeben:
  \begin{mathpar}
    b_x=b'_x \to (x,b_x)=(x,b'_x)
  \end{mathpar}
  Nun sind $b_x,b'_x:B(x)$ noch frei wählbar, also kann wieder Gleichheitsinduktion angewandt und der gesuchte Term auf $\refl_{(x,b_x)}$ festgelegt werden.
\end{beweis}
Für die Gleichheit in abhängigen Summen gibt es auch eine Aussage wie \cref{lem:produkt-gleich}, der wir uns jetzt aber erstmal nicht zuwenden.

\subsection{Kontrahierbarkeit und Aussagen}
Wir beschäftigen uns zunächst mit Gleichheit von Funktionen.
In verschiedenen Zusammenhängen ist bereits die punkweise Gleichheit von Funktionen aufgetreten, der wir nun einen Namen geben wollen:
\begin{definition}
  Seien $A,B$ Typen und $f,g:A\to B$ Funktionen. Wir nennen $f$ und $g$ \begriff{homotop} oder \begriff{punktweise gleich}, wenn der folgenden Typ einen Term hat
  \begin{mathpar}
    f \sim g \colonequiv \prod_{x:A} f(x)=g(x)
  \end{mathpar}
  Die Elemente von $f\sim g$ heißen \begriff{Homotopien} oder \begriff{punktweise Gleichheiten}.
\end{definition}
Wir werden später das sogenannte \begriff{Univalenzaxiom} und ein \begriff{Intervall} als höheren induktiven Typen einführen.
Aus beidem kann jeweils gefolgert werden, dass punktweise Gleichheiten bereits die Gleichheit von Funktionen zur Folge hat.
Letztere Aussage hat einen eigenen Namen und wird von uns im Folgenden als Axiom verwendet:
\begin{axiom}[Funktionsextensionalität]
  Unter \begriff{Funktionsextensionalität} versteht man einen Term, der für Typen $A,B$ und Funktionen $f,g:A\to B$ wie folgt gegeben ist:
  \begin{mathpar}
    \mathrm{FunExt}_{f,g}:\left(\prod_{x:A}f(x)=g(x)\right)\to f=g
  \end{mathpar}
\end{axiom}
(Genauer wollen wir fordern, dass $\mathrm{FunExt}_{f,g}$ und $\mathrm{ap}((p:x=y)\mapsto x f\mapsto f(x)):(f=g)\to f\sim g$ invers zueinander sind, aber das brauchen wir nicht, bis wir $\mathrm{FunExt}$ sowieso nochmal auf eine andere Art einführen.)
Wir werden uns jeweils merken, für welche Aussagen wir dieses Axiom brauchen.

\begin{bemerkung}
  Mit $\mathrm{FunExt}$ sind die Funktionen $\mathrm{curry}$ und $\mathrm{uncurry}$ aus \cref{def:currying} zueinander invers.
\end{bemerkung}

Was wir bereits über Gleichheit wissen und mit Gleichheiten machen können, lässt sich leicht auf Homotopien jeweils punktweise übertragen:
\begin{bemerkung}
  Seien $A,B$ Typen und $f,g:A\to B$ Funktionen.
  \begin{enumerate}
  \item Es gibt stets den folgenden Term:
    \begin{mathpar}
      (x:A)\mapsto \refl_{f(x)}: f\sim f
    \end{mathpar}
  \item Es gibt eine Operation
    \begin{mathpar}
      H\mapsto (x\mapsto H(x))^{-1}): f\sim g\to g\sim f
    \end{mathpar}
  \item Für eine weitere Funktion $h:A\to B$ gibt es eine Operation
    \begin{mathpar}
      H \mapsto H'\mapsto (x \mapsto H(x)\kon H'(x)) : f\sim g \to g\sim h \to f\sim h 
    \end{mathpar}
  \end{enumerate}
\end{bemerkung}

Ziel dieses Abschnitts ist es, die ersten beiden Stufen einer Hierarchie auf allen Typen einzuführen und zu untersuchen.
Diese Hierarchie der sogenannten \begriff{n-Typen} ist nicht total und bezieht sich auf die Komplexität der Gleichheiten in Typen.
In der niedrigsten Stufe sind alle Elemente eines Typs gleich einem fest gewählten, wir werden sehen, dass eine Konsequenz davon ist, dass auch Gleichheiten zwischen Gleichheiten keine neue komplexität aufweisen.
Wir nennen diese einfachsten Typen kontrahierbar und wollen gleich die nächsten beiden Stufen benennen:

\begin{definition}
  Sei $A$ ein Typ.
  \begin{enumerate}
  \item $A$ heißt \begriff{kontrahierbar} oder \begriff{$-2$-Typ}, wenn
    \begin{mathpar}
      \isContr(A)\colonequiv \sum_{c : A} \prod_{x : A} x=c
    \end{mathpar}
    (einen Term hat). 
  \item $A$ heißt \begriff{Aussage} oder \begriff{$-1$-Typ}, wenn
    \begin{mathpar}
      \isProp(A)\colonequiv \prod_{x,y : A}x=y
    \end{mathpar}
  \item $A$ heißt \begriff{$0$-Typ} oder \begriff{Menge}, wenn
    \begin{mathpar}
      \isSet(A)\colonequiv \prod_{x,y : A}\prod_{p,q : x=y}p=q
    \end{mathpar}
  \end{enumerate}
\end{definition}

\begin{beispiel}
  \begin{enumerate}
  \item $\einheit$ ist kontrahierbar.
  \item $\leer$ ist eine Aussage.
  \end{enumerate}
\end{beispiel}

Für die kontrahierbaren Typen stellt sich zusätzlich zum bereits Gesagten heraus, dass jeder kontrahierbare Typ bereits mehr oder weniger der Einheitstyp ist:
\begin{bemerkung}
  Sei $A$ ein kontrahierbarer Typ. Es gilt:
  \begin{enumerate}
  \item Für $x,y:A$ ist $x=_Ay$ kontrahierbar.
  \item Es gibt Funktionen $f:A\to \einheit$ und $g:\einheit  \to A$, die zueinander invers sind.
  \item $A$ ist eine Aussage.
  \end{enumerate}
\end{bemerkung}
\begin{beweis}
(a), (b) In den Übungen. \\
(c) Wir haben
\begin{mathpar}
  k:\isContr(A)\equiv \sum_{c:A}\prod_{x:A}x=c
\end{mathpar}
und damit:
\begin{mathpar}
  x \mapsto y \mapsto k_x\kon k_y^{-1}:\prod_{x,y:A}x=y
\end{mathpar}
\end{beweis}

Mit der folgenden Bemerkung scheinen auch Aussagen wenig Vielfalt zuzulassen:
\begin{bemerkung}
  Sei $P$ eine Aussage und $t:P$. Dann ist $P$ kontrahierbar.
\end{bemerkung}
\begin{beweis}
  Es gibt
  \begin{mathpar}
    a:\prod_{x,y:P}x=y
  \end{mathpar}
  und damit
  \begin{mathpar}
    (t,x\mapsto a_{x,t}):\isContr(P)\equiv\sum_{c:P}\prod_{x:P}x=c
  \end{mathpar}
\end{beweis}

Es gibt einen überraschenderweise kontrahierbaren Typen, der uns noch begleiten wird.
\begin{lemma}
  Seien $A$ ein Typ und $x:A\yields B(x)$. Dann ist für $y:A$ der Typ
  \begin{mathpar}
    \sum_{x:A}x=y
  \end{mathpar}
  kontrahierbar.
\end{lemma}
\begin{beweis}
  Wegen $(y,\refl_y):\sum_{x:A}x=y$ reicht es zu zeigen, dass der Typ eine Aussage ist, also je zwei Elemente gleich sind.
  Durch $\sum$-Induktion, reicht es zu zeigen, dass je zwei paare
  \begin{mathpar}
    (x,q),(x',q'):\sum_{x:A}x=y
  \end{mathpar}
  gleich sind. Es ist $q\kon q'^{-1}:x=x'$ und damit können wir $\sum_=$ verwenden:
  \begin{mathpar}
    \Sigma_=:\prod_{p:x=x'}\mathrm{tr}_{x:A\yields x=y}(p)(q)=q' \to (x,q)=(x',q')
  \end{mathpar}
  Den Transport haben wir in \cref{lem:transp-lpath} berechnet und können einsetzen:
  \begin{mathpar}
    (q\kon q'^{-1})^{-1} \kon q=q' \to (x,q)=(x',q')
  \end{mathpar}
  Mit Induktion kann berechnet werden: $(q\kon q'^{-1})^{-1}=q'\kon q^{-1}$ und damit mit den Rechengesetzen für Gleichheiten der Beweis beendet werden.
\end{beweis}

Es gibt einige Konstruktionen, die die Eigenschaften ``Aussage''  erhalten (allgemeiner auch für ``n-Typ'').
\begin{lemma}
  Seien $P,Q$ Aussagen und $A$ ein beliebiger Typ.
  \begin{enumerate}
  \item Mit $\FunExt$ gilt: Der Typ $A\to P$ ist eine Aussage.
  \item $P\times Q$ ist eine Aussage.
  \end{enumerate}
\end{lemma}

\begin{beweis}
  \begin{enumerate}
  \item Sei $t:\isProp(P)$, dann ist
    \begin{mathpar}
      \FunExt_{f,g}((x:A)\mapsto t_{(f(x),g(x))}):\isProp(A\to P)\equiv\prod_{f,g:A\to P}f=g
    \end{mathpar}
  \item Seien $t:\isProp(P)$ und $s:\isProp(Q)$. Per doppelter $\sum$-Induktion reicht es für $p,p':P$ und $q,q':Q$ zu zeigen:
    \begin{mathpar}
      (p,q)=(p',q')
    \end{mathpar}
    was durch $\pair_=(t_{p,p'},s_{q,q'})$ gegeben ist.
  \end{enumerate}
\end{beweis}

Es ist möglich, Typen universell in eine Aussage zu verwandeln. Dafür werden wir zunächst nur eine Formierungs- und Einführungsregel kennenlernen:
\begin{regeln}[-1-Truncation, teilweise]
  Für jeden Typ $A$ gibt es eine Aussage $\|A\|$. Weiter gibt es für jedes $a:A$ ein $|a|:\|A\|$.
  Der Typ $\|A\|$ heißt \begriff{-1-Abschneidung} oder \begriff{-1-Truncation}.
  Mit den weiteren Regeln wird sich rausstellen, dass $|\_|:A\to \|A\|$ genau dann eine Inverse hat,
  wenn $A$ bereits eine Aussage war.
\end{regeln}

Damit können wir alle üblichen Logikkonstrukte für Aussagen definieren:
\begin{definition}
  Seien $P$ und $Q$ Aussagen.
  \begin{enumerate}
  \item $P\Rightarrow Q\colonequiv P\to Q$
  \item $P\wedge Q\colonequiv P\times Q$
  \item $P\vee Q\colonequiv \|P\amalg Q\|$
  \item $\neg P\colonequiv P\to \leer$
  \end{enumerate}
  Sei nun $A$ ein Typ und $P(x)$ eine Aussage für $x:A$.
  \begin{enumerate}
  \item $\forall x:A \text{ gilt } P(x) \colonequiv \prod_{x:A}P(x)$
  \item $\exists x:A \text{ mit } P(x)\colonequiv \|\sum_{x:A}P(x)\|$
  \end{enumerate}
\end{definition}
Bei dieser Gelegenheit sollte festgehalten werden, dass es möglich ist, nicht konstruktive Axiome anzunehmen, um unsere Typentheorie bei Bedarf zu spezialisieren.
Um diese zu formulieren brauchen wir aber noch manche der folgenden, sowieso wichtigen, Begriffe:
\begin{definition}
  Seien $A,B$ Typen und $f:A\to B$ eine Funktion.
  \begin{enumerate}
  \item Für $b:B$ ist die \begriff{Faser} von $f$ über $b$ gegeben durch:
    \begin{mathpar}
      \mathrm{fib}_f^{-1}(b)\colonequiv f^{-1}(b)\colonequiv \sum_{x:A}f(x)=b
    \end{mathpar}
  \item $f$ heißt \begriff{injektiv}, wenn
    \begin{mathpar}
      \prod_{y:B}\isProp(f^{-1}(y))
    \end{mathpar}
  \item $f$ heißt \begriff{surjektiv}, wenn
    \begin{mathpar}
      \prod_{y:B}\|f^{-1}(y)\|
    \end{mathpar}
  \item $f$ heißt \begriff{Äquivalenz}, wenn
    \begin{mathpar}
      \isEquiv(f)\colonequiv\prod_{y:B}\isContr(f^{-1}(y))
    \end{mathpar}
  \end{enumerate}
\end{definition}
\begin{bemerkung}
  Es ist möglich, bei Bedarf anzunehmen, dass die folgenden klassischen Axiome gelten
  \begin{enumerate}
  \item Das Gesetz vom \begriff{ausgeschlossenen Dritten}: Für jede Aussage gilt $P\vee \neg P$
  \item Das Auswahlaxiom: Für jede surjektive Funktion $f:A\to B$ zwischen Mengen $A$ und $B$ gibt es $s:B\to A$ mit $f\circ s\sim \id_B$.
  \end{enumerate}
\end{bemerkung}
Wir werden noch sehen, dass es eine gute Idee ist, das Auswahlaxiom auf Abbildungen zwischen Mengen zu beschränken.
Jetzt wollen wir noch den Abschnitt mit zwei Bemerkungen zur Äquivalenz beenden:
\begin{bemerkung}
  Seien $A,B$ Typen und $f:A\to B$.
  Wenn $f$ surjektiv und injektiv ist, dann ist $f$ eine Äquivalenz.
\end{bemerkung}
In \cref{sub:aequivalenzen} werden wir beweisen, dass jede Funktion mit einer beidseitigen Inversen auch eine Äquivalenz ist.

\subsection{Universen}
Ein \begriff{Universum} kann man sich erstmal als Typ aller Typen vorstellen.
Problematisch ist dabei, wie in der Mengenlehre, dass das zu Widersprüchen führt.
Eine einfach Lösung, die wir hier verwenden werden ist die leichte Abwandlung zu sagen, dass jeder Typ in \emph{einem} Universum liegt und Universen unter möglichst vielen Konstruktionen abgeschlossen sind.
Genauer fordern wir eine abzählbare Hierarchie von Universen:
\begin{mathpar}
  \mU_0, \mU_1, \dots
\end{mathpar}
Dabei sind die Indizes allerdings nicht unsere natürlichen Zahlen, sondern sogenannte \emph{Universenlevel}.
Dabei handelt es sich um eine Variante der natürlichen Zahlen, die implizit durch Regeln gegeben ist.
Das verhindert zum Beispiel die Konstruktion von aufsteigenden Folgen von Universen.

Da es mit Universen möglich ist, auszudrücken, dass etwas ein Typ ist, können wir von nun auf dieses Urteil verzichten.
Wir verwenden also in Zukunft ``$A:\mU_i$'' synonym mit ``$A$ ist ein Typ''.

\begin{regeln}
  Wir können nun in allen Regeln Urteile der ``$A$ Typ'' ersetzen durch ``$A:\mU_i$''.
  Bei der Regel $\Pi\mathrm{F}$ bedeutet das etwa:
  \begin{mathpar}
    \inferrule{\Gamma\yields A:\mU_i\and\Gamma,x:A\yields B(x):\mU_i}{\Gamma\yields \prod_{x:A}B(x):\mU_i}{\Pi\mathrm{F}}
  \end{mathpar}
  Dabei haben wir die Regel etwas ausgebaut, um fordern zu können, dass $A$ und die $B(x)$ im gleichen Universum liegen.
  Der Index $i$ ist dabei $0$ oder $j+1$ für einen erlaubten Index $j$.
  Die Universen gibt es jetzt auch einfach so als Typen:
  \begin{mathpar}
    \inferrule{\Gamma\text{ Kontext}}{\Gamma\yields\mU_i:\mU_{i+1}}{\mU\mathrm{F}}
  \end{mathpar}
  Insbesondere können wir nun abhängige Typen auch immer äquivalent als Funktionen in ein Universum ausdrücken:
  \begin{mathpar}
    \inferrule*{\Gamma\yields A:\mU_i\and\Gamma,x:A\yields B(x):U_i}{\Gamma\yields x\mapsto B(x):A\to \mU_i}
  \end{mathpar}
  Grundsätzlich kann es vorkommen, dass wir auch mal Typen aus Bestandteilen konstruieren wollen, die in unterschiedlichen Universen liegen.
  Dazu können wir mit der folgenden Regel alles in ein passendes Universum schieben:
  \begin{mathpar}
    \inferrule*{\Gamma\yields A:\mU_i}{\Gamma\yields A:\mU_{i+1}}
  \end{mathpar}
\end{regeln}
Den Rest dieses Abschnitts verbringen wir damit, Neuerungen zu erwähnen, die sich durch die Verwendung von Universen ergeben.
Interessanterweise haben wir erst durch Universen die Möglichkeit, manche Gleichheitstypen zu charakterisieren,
was wir aber erst im nächsten Abschnitt ausführlich angehen werden.
\begin{bemerkung}
  Mit Universen können wir Induktion als abhängige Funktion umschreiben, etwa für $\N$:
  \begin{mathpar}
    \ind{\N}:\prod_{P:\N\to \mU_i}P(0_{\N})\to \left(\prod_{n:\N}P(n)\to P(\sucN(n))\right)\to \left(\prod_{n:\N}P(n)\right)
  \end{mathpar}
\end{bemerkung}
\begin{konvention}
  Meistens werden wir den Index der Universen weglassen, also etwa nur $A:\mU$ schreiben.
  Situationen in denen die Universenlevel wichtig sind, werden eher selten sein, kommen aber vor.
\end{konvention}
\begin{beispiel}
  Dank Universen können wir nun abhängige Typen über Rekursion definieren:
  \begin{align*}
    B&:\zwei\to\mU \\
    B(0_{\zwei})&\colonequiv \leer \\
    B(1_{\zwei})&\colonequiv \einheit
  \end{align*}
\end{beispiel}


\section{Univalenz}
\subsection{Äquivalenzen}
\label{sub:aequivalenzen}

In diesem Abschnitt werden wir drei verschiedene Definitionen von Äquivalenzen einführen und zeigen,
dass es sich um den selben Begriff handelt. Einen haben wir bereits eingeführt - Funktionen mit kontrahierbaren Fasern heißen Äquivalenz.
Von einem Äquivalenzbegriff erwarten wir, dass es sich beim entsprechenden Typ $\isEquiv(f)$ um eine Aussage handelt.
Das hat zur Folge, dass wir es als eine Eigenschaft von Funktionen anssehen können eine Äquivalenz zu sein.
Damit ist dann auch der Typ der Äquivalenzen zwischen $A$ und $B$ eine Untertyp von $A\to B$, d.h. die Vergiß-Abbildung
\begin{mathpar}
  \pi_1:\left(\sum_{f:A\to B}\isEquiv(f)\right)\to (A\to B)
\end{mathpar}
ist injektiv.

Zur Vorbereitung beschäftigen wir uns noch etwas mit Homotopien.
\begin{bemerkung}
  Seien $A,B:\mU$ und $f,g:A\to B$.
  \begin{enumerate}
  \item Sei $H:f\sim g$. Für $\varphi:A'\to A$ gibt es eine Homotopie $H_{\varphi(\_)}:f\circ \varphi\sim g\circ \varphi$ und für $\psi:B\to B'$ gibt es eine Homotopie $\psi(H):\psi\circ f\sim \psi\circ g$. Diese Operationen nennt man \begriff{whiskering}.
  \item Sei $H:f\sim g$. Homotopien sind natürlich in folgendem Sinn: Für $p:x=_A y$ gilt:
    \begin{mathpar}
      H_x\kon g(p) = f(p)\kon H_{y}
    \end{mathpar}
  \item Für eine Homotopie $H:f\sim\id$ gilt $f(H_x)=H_{f(x)}$.
  \end{enumerate}
\end{bemerkung}


Wir beginnen mit einer scheinbar unbedeutenden Variation des Begriffs Quasi-Inverse und legen dabei mehr Notation für Äquivalenzen fest:

\begin{definition}
  Seien $A,B:\mU$ und $f:A\to B$.
  \begin{enumerate}
  \item $f$ hat eine \begriff{Linksinverse}, wenn es ein $g:B\to A$ gibt und $g\circ f\sim\id_A$.
  \item $f$ hat eine \begriff{Rechtsinverse} oder einen \begriff{Schnitt}, wenn es ein $h:B\to A$ gibt und $f\circ h\sim \id_B$.
  \item $f$ ist eine \begriff{Äquivalenz} oder eine Funktion mit \begriff{Links- und Rechtsinversen}, wenn
    \begin{mathpar}
      \isEquiv(f)\colonequiv\mathrm{LRInv}(f)\colonequiv  \left(\sum_{g:B\to A}g\circ f\sim\id_A\right)\times\left(\sum_{h:B\to A}f\circ h\sim\id_B\right)
    \end{mathpar}
  \item Wenn es eine Äquivanz zwischen $A$ und $B$ gibt, dann sagen wir $A$ ist \begriff{äquivalent} zu $B$.
  \item Für den Typ der Äquivalenzen zwischen $A$ und $B$ schreiben wir:
    \begin{mathpar}
      A\simeq B\colonequiv\sum_{f:A\to B}\isEquiv(f)
    \end{mathpar}
  \end{enumerate}
\end{definition}

Es wird sich herausstellen, dass $\mathrm{LRInv}(f)$ und $\mathrm{qinv}(f)$ für manche Funktionen keine äquivalenten Typen sind.
Insbesondere werden wir noch sehen, dass $\qinv(f)$ immer eine Aussage ist, $\mathrm{LRInv}(f)$ aber keine Aussage mehr sein muss, wenn $A$ und $B$ komplizierte Gleichheitstypen haben.
Die beiden Begriffe sind aber logisch äquivalent, d.h. es gibt für jedes $f:A\to B$ Abbildungen $\mathrm{LRInv}(f)\to \qinv(f)$ und $\qinv(f)\to\mathrm{LRInv}(f)$.
Zunächst halten wir die Vokabel ``logisch äquivalent'' fest:

\begin{definition}
  Zwei Typen $A$ und $B$ heißen \begriff{logisch äquivalent}, wenn es Funktionen $f:A\to B$ und $g:B\to A$ gibt.
\end{definition}

Bei Aussagen reicht die logische Äquivalenz bereits, damit die Typen äquivalent sind.
Damit werden die verschiedenen Varianten des Typs ``$\isEquiv(f)$'', die wir in diesem Abschnitt kennenlernen, äquivalente Typen sein,
wenn wir logische Äquivalenz gezeigt haben und dass es sich jeweils um Aussagen handelt. Letzteres werden wir allerdings noch Aufschieben.

\begin{bemerkung}
  \label{bem:lrinv-qinv}
  Seien $A,B:\mU$ und $f:A\to B$. Die Typen $\mathrm{LRInv}(f)$ und $\qinv(f)$ sind logisch äquivalent.
\end{bemerkung}
\begin{beweis}
  Nehmen wir zünachst an, es gibt eine Quasi-Inverse $g:B\to A$ mit $H:g\circ f\sim\id_A$ und $K:f\circ g\sim\id_B$. Dann ist
  \begin{mathpar}
    ((g,H),(g,K)):\mathrm{LRInv}(f)
  \end{mathpar}
  Seien nun andererseits $g,h:B\to A$ links- und rechtsinvers zu $f$. Wir zeigen, dass $g$ und $h$ homotop sind. Damit können wir dann zeigen, dass $g$ auch rechtsinvers ist.
  Durch whiskering erhalten wir:
  \begin{mathpar}
    g\sim g\circ (f\circ h) \sim (g\circ f)\circ h  \sim h
  \end{mathpar}
  Also ist $g$ rechtsinvers:
  \begin{mathpar}
    f\circ g\sim f\circ h\sim \id
  \end{mathpar}
\end{beweis}

Wenn wir also zu einer Funktion $f:A\to B$ eine beidseitige Inverse konstruieren, dann ist $f$ eine Äquivalenz (im Sinn einer Funktion mit Links- und Rechtsinversen).
Äquivalenzen haben die Operationen, die wir bereits von Gleichheiten kennen:

\begin{bemerkung}
  \begin{enumerate}
  \item Die Identität ist eine Äquivalenz.
  \item Eine Inverse einer Äquivalenz ist eine Äquivalenz.
  \item Seien $A,B,C:\mU$. Wenn $f:A\to B$ und $g:B\to C$ Äquivalenzen sind, dann ist $g\circ f:A\to C$ eine Äquivalenz.
  \end{enumerate}
\end{bemerkung}
\begin{beweis}
  Wir zeigen die Aussagen für den Äquivalenzbegriff der Funktion mit Links- und Rechtsinversen.
  Mit \cref{thm:aequivalenzen} gilt damit das gleiche für die anderen Äquivalenzbegriffe.
  \begin{enumerate}
  \item Die Identität ist ihre eigene Links- und Rechtsinverse. Die nötigen Homotopien gelten schon als urteilsmäßige von Funktionen.
  \item Wenn $f:A\to B$ eine Linksinverse $g:B\to A$ und eine Rechtsinverse $h:B\to A$ hat, dann ist bekommen wir mit Bemerkung \labelcref{bem:lrinv-qinv} eine Quasi-Inverse $f^{-1}:B\to A$.
    Und $f^{-1}$ ist eine Äquivalenz mit Linksinverser $f$ und Rechtsinverser $f$.
  \item Auf Übungsblatt 4 wird das für Quasi-Inversen gezeigt. Zusammen mit Bemerkung \labelcref{bem:lrinv-qinv} gilt das also auch für Äquivalenzen.
  \end{enumerate}
\end{beweis}

\begin{beispiel}[Transport ist Äquivalenz]
  Für $A:\mU$, $B:A\to\mU$, $x,y:A$ und jedes $p:x=y$ ist $\transp_B(p):B(x)\to B(y)$ eine Äquivalenz mit Inverser $\transp_B(p^{-1}):B(y)\to B(x)$.
\end{beispiel}

Wir wollen nun den Äquivalenzbegriff der Links- und Rechtsinvertierbarkeit mit dem der kontrahierbaren Fasern in Zusammenhang bringen.
Wir werden allerdings erstmal eine Implikation klären und für die zweite einen dritten Äquivalenzbegriff einführen.

\begin{bemerkung}
  \label{bem:isContr-lrinv}
  Seien $A,B:\mU$ und $f:A\to B$. Wenn alle Fasern von $f$ kontrahierbar sind, dann hat $f$ Links- und Rechtsinverse, es gibt also eine Funktion:
  \begin{mathpar}
    \left(\prod_{y:B}\isContr(f^{-1}(y))\right) \to \mathrm{LRInv}(f)
  \end{mathpar}
\end{bemerkung}

\begin{beweis}
  Sei $k:\prod_{y:B}\isContr(f^{-1}(y))$.
  Wir konstruieren eine beidseitige Inverse $g:B\to A$ indem wir $y:B$ auf das Kontraktionszentrum der Faser $f^{-1}(y)$ abbilden:
  Für $\pi_1(k_y)$ ist ein Element von $f^{-1}(y)$, besteht also aus $x:A$ und $p:f(x)=y$, also können wir festlegen
  \begin{mathpar}
    g(y)\colonequiv x
  \end{mathpar}
  Dann ist $f(g(y))=f(x)=y$, also $g$ Rechtsinverse von $f$. Für $x:A$ sei $x'\colonequiv g(f(x))$.
  Es müssen $x:A$ und $x':A$ beide in $f^{-1}(f(x))$ liegen und da diese Faser kontrahierbar ist, gibt es eine Gleichheit $q:x=x'=g(f(x))$.
  Genauer haben wir durch die Kontrahierbarkeit eine Gleichheit $q':(x,\refl_{f(x)})=(x',p')$ in der Faser $f^{-1}(f(x))$.
  Diese Gleichheit können wir mit $\pi_1:f^{-1}(f(x))\to A$ abbilden, also $q\colonequiv \pi_1(q')$ setzen.
\end{beweis}

Die Umkehrung dieser Aussage ist komplizierter zu zeigen und wir werden zunächst zeigen, dass sich Links- Rechtsinverse in eine sogenannte kohärente Inverse überstzen lassen.
Kohärente Inverse $g:B\to A$ einer Funktion $f:A\to B$ haben eine Kompatiblität zwischen den beiden Homotopien $f\circ g\sim \id$ und $g\circ f\sim \id$.
Für eine Funktion $f:A\to B$ mit Inverser $g:B\to A$ besagt diese Kohärenz, dass die beiden Möglichkeiten eine Homotopie $f\circ g\circ f\sim f$ zu konstruieren punktweise gleich sind.

\begin{definition}
  Seien $A,B:\mU$ und $f:A\to B$.
  Eine Funktion $g:B\to A$ heißt \begriff{kohärente Inverse} von $f$, wenn $f$ und $g$ es Homotopien $H:g\circ f\sim \id$ und $K:f\circ g \sim \id$ gibt und
  \begin{mathpar}
    \mathrm{koh} : \prod_{x:A}f(H_x)=K_{f(x)}
  \end{mathpar}
  Wir schreiben $\mathrm{CohInv}(f)$ für den Typ der \begriff{kohärenten Inversen} von $f$.
\end{definition}

Wir wollen direkt einsehen, dass wir von dieser Sorte Äquivalenz die Kontrahierbarkeit der Fasern beweisen können:

\begin{bemerkung}
  \label{bem:qinv-equiv}
  Seien $A,B:\mU$ und $f:A\to B$. Wenn $f$ eine kohärente Inverse hat, dann sind die Fasern von $f$ kontrahierbar.
\end{bemerkung}
Vor dem Beweis noch ein Hilfslemma, das wir auch sonst noch wiederverwenden können:
\begin{lemma}
  \label{lem:gleichheit-in-faser}
  Seien $A,B$ Typen, $f:A\to B$ und $y:B$. Für $(x,q),(x',q'):f^{-1}(y)$ gibt es eine Funktion:
  \begin{mathpar}
    \prod_{p:x=_A x'}f(p)^{-1}\kon q=q'\to (x,q)=(x',q')
  \end{mathpar}
\end{lemma}
\begin{beweis}[von \cref{lem:gleichheit-in-faser}]
  Induktion über $p$ und $\sum_=$.
\end{beweis}

\begin{beweis}[von \labelcref{bem:qinv-equiv}]
  Habe also $f:A\to B$ eine kohärente Inverse, gebe es also $g:B\to A$, $H:g\circ f\sim \id$, $K:f\circ g \sim \id$ und $\mathrm{koh} : \prod_{x:A}f(H_x)=K_{f(x)}$.
  Wir müssen nun für jede Faser von $f$ eine Kontraktion angeben.
  Als Kontraktionszentrum für die Faser über $y:B$ wählen wir
  \begin{mathpar}
    k_y\colonequiv (g(y), K_y) : f^{-1}(y)
  \end{mathpar}
  Seien nun also $(x,q),(x',q'):f^{-1}(y)$. Damit haben wir auch $q\kon q'^{-1}:f(x)=f(x')$ und damit:
  \begin{mathpar}
    H_x^{-1}\kon g(q\kon q'^{-1}) \kon H_x':x=x'
  \end{mathpar}
  Darauf wenden wir jetzt $f$ an:
  \begin{mathpar}
    f(H_x^{-1}\kon g(q\kon q'^{-1}) \kon H_x'):f(x)=f(x')
  \end{mathpar}
  und berechnen mit natürlichkeit von Homotopien, der Kohärenz und Gruppoidgesetzen:
  \begin{align*}
    f(H_x^{-1}\kon g(q\kon q'^{-1}) \kon H_x')&=f(H_x^{-1})\kon f(g(q\kon q'^{-1})) \kon f(H_x') \\
                                              &=f(H_x^{-1})\kon K_{f(x)}\kon q\kon q'^{-1}\kon K_{f(x')}^{-1} \kon f(H_x') \\
                                              &=q\kon q'^{-1}
  \end{align*}
  Mit dem Lemma haben wir also die gewünschte Gleichheit.
\end{beweis}

\begin{bemerkung}
  Seien $A,B:\mU$ und $f:A\to B$ habe eine beidseitige Inverse $g:B\to A$.
  Dann ist $g$ auch eine kohärente Inverse von $f$.
\end{bemerkung}
\begin{beweis}
  Seien $g,h:B\to A$ und $H:g\circ f\sim\id$, $K:f\circ g\sim \id$. Setzte für $y:B$:
  \begin{mathpar}
    K'\colonequiv K_{f(g(y))}^{-1}\kon f(H_{g(y)})\kon K_{y}
  \end{mathpar}
  und rechne nach dass für $x:A$ gilt: $f(H_x)=K'_{f(x)}$.
\end{beweis}

\begin{theorem}
  \label{thm:aequivalenzen}
  Seien $A,B:\mU$ und $f:A\to B$, dann sind die folgenden Äquivalenzbegriffe logisch äquivalent:
  \begin{enumerate}
  \item Alle Fasern von $f$ sind kontrahierbar:
    \begin{mathpar}
      \isEquiv(f)\colonequiv\prod_{y:B}\isContr(f^{-1}(y))
    \end{mathpar}
  \item $f$ hat eine Linksinverse und eine Rechtsinverse:
    \begin{mathpar}
      \isEquiv(f)\colonequiv\mathrm{LRInv}\equiv  \left(\sum_{g:B\to A}g\circ f\sim\id_A\right)\times\left(\sum_{h:B\to A}f\circ h\sim\id_B\right)
    \end{mathpar}
  \item $f$ hat eine kohärente Inverse:
    \begin{mathpar}
      \isEquiv(f)\colonequiv\mathrm{CohInv}(f)\colonequiv \sum_{g:B\to A} \sum_{H:g\circ f\sim\id}\sum_{K:f\circ g\sim\id} \prod_{x:A}f(H_x)=K_{f(x)}
    \end{mathpar}
  \end{enumerate}
  Wir schreiben für alle drei Begriffe $\isEquiv(f)$, weil sich noch rausstellen wird, dass alle diese Typen Aussagen sind und damit alle drei Typen äquivalent sind.
\end{theorem}
\begin{beweis}
  Die Bemerkungen dieses Abschnitts beweisen per Ringschluss die logische Äquivalenz.
\end{beweis}

\subsection{Univalenz}
In diesem Abschnitt werden wir uns mit den Universen und ihren Gleichheitstypen beschäftigen.
Eine historisch wichtige Idee von Vladimir Voevodsky ist das \begriff{Univalenzaxiom},
das die Gleichheitstypen im Universum mit den Äquivalenzen von Typen identifiziert.
Dieses Axiom werden wir kennenlernen und Konsequenzen daraus ziehen.
Davor wollen wir aber noch allgemeine Konsequenzen aus der Existenz von Universen ziehen.

Mit Universen sind wir in der Lage Ungleichheit von Elementen eines Typs zu beweisen.
Diese definieren wir zunächst als Negation der Gleichheit:
\begin{definition}
  Seien $A:\mU$ und $x,y:A$. Dann ist $x$ \begriff{ungleich} $y$, wenn
  \begin{mathpar}
    x\not= y\colonequiv (x=y\to \leer)
  \end{mathpar}
\end{definition}
Man beachte, dass es sich bei diesem Typ stets um eine Aussage handelt.
Es sind also in $x\not= y$ keine so interessanten Dinge zu finden, wie im Gleichheitstyp und wir werden uns auch wenig mit Ungleichheiten beschäftigen.
\begin{bemerkung}
  Es gilt $1_\zwei \not= 0_\zwei$.
\end{bemerkung}
\begin{beweis}
  Per Rekursion können wir uns den folgenden abhängigen Typen definieren:
  \begin{align*}
    B&:\zwei\to\mU \\
    B(0_\zwei)&\colonequiv \leer \\
    B(1_\zwei)&\colonequiv \eins
  \end{align*}
  Um die Ungleichheit zu zeigen, dürfen wir $p:1_\zwei = 0_\zwei$ annehmen und müssen ein Element in $\leer$ konstruieren.
  Sei also $p:1_\zwei = 0_\zwei$. Damit haben wir auch eine Abbildung:
  \begin{mathpar}
    \transp_B(p):B(1_\zwei)\to B(0_\zwei)
  \end{mathpar}
  Und wegen $\ast:B(1_\zwei)\equiv \eins$ haben wir auch ein Element, das wir in diese Abbildung einsetzen können.
  Es ist also $\transp_B(p)(\ast):B(0_\zwei)\equiv \leer$.
\end{beweis}
Dieser Trick lässt sich auf alle Elemente induktiver Typen übertragen, für die wir ``verschiedene'' Werte vorgeben können.
Für einzelne natürliche Zahlen etwa:
\begin{bemerkung}
  Es gilt $0_{\N}\not= 1_{\N}\colonequiv \sucN(0_{\N})$.
\end{bemerkung}
\begin{beweis}
  Sei
  \begin{align*}
    B&:\N\to \mU \\
    B(0_{\N})&\colonequiv \leer \\
    B(1_{\N})&\colonequiv \eins
  \end{align*}
  womit für $p:0_{\N}=1_{\N}$ ein Element $\transp_B(p^{-1})(\ast):\leer$ gegeben ist.
\end{beweis}
Typischerweise interessiert man sich für eine vollständige Charakterisierung der Gleichheitstypen eines Typs.
Für die natürlichen Zahlen wäre das ein in $n,k:\N$ abhängiger Typ $B(n,k)$ sodass $B(n,k)\simeq (n=_\N k)$.
Das wird unser Ziel in \cref{sec:zahlen-gleichheit} sein.

Ohne Weiteres können wir bereits für $A,B:\mU_i$ den Typ $A=_{\mU_i}B$ der Gleichheiten zwischen $A$ und $B$ formen.
Dieser liegt allerdings im nächsthöheren Universum $\mU_{i+1}$, da wir in der Formierungsregel für Gleichheitstypen ``X ist ein Typ'' durch ``$X : \mU_i$'' ersetzen und dafür nur ``$\mU_i : \mU_{i+1}$'' in Frage kommt:
\begin{mathpar}
  \inferrule{\Gamma\yields \mU_i:\mU_{i+1}\and \Gamma\yields A,B:\mU_i}{\Gamma\yields A=_{\mU_i}B:\mU_{i+1}}{=\mathrm{F}}
\end{mathpar}

\subsection{Gleichheit in den natürlichen Zahlen}
\label{sec:zahlen-gleichheit}
\begin{definition}
  $\Eq{\N}:\N\to\N\to\mU$ definieren wir durch doppelte Rekursion wie folgt:
  \begin{align*}
    &\Eq{\N}(0_\N,    &0_\N)    &\colonequiv\einheit \\
    &\Eq{\N}(0_\N,    &\sucN(k))&\colonequiv\leer \\
    &\Eq{\N}(\sucN(n),&0_\N)    &\colonequiv\leer \\
    &\Eq{\N}(\sucN(n),&\sucN(k))&\colonequiv\Eq{\N}(n,k) 
  \end{align*}
\end{definition}

\section{Homotopietheorie}
\subsection{n-Typen}
\subsection{Höhere Induktive Typen}
\subsection{Überlagerungen}
\subsection{Homotopiegruppen}

\printindex

\end{document}
